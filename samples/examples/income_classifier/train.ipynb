{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aba8156",
   "metadata": {},
   "source": [
    "## Train a tabular income classification model with monitoring and explanations\n",
    "\n",
    "These steps are extracted from various Seldon Alibi notebooks\n",
    "\n",
    " * [Income data preparation and classifier](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_clf_adult.html)\n",
    " * [Drift detector](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n",
    " * [Outlier detector](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/od_vae_adult.html)\n",
    " * [Explainer](https://docs.seldon.io/projects/alibi/en/stable/examples/anchor_tabular_adult.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff674c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 16:19:18.893973: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-27 16:19:18.894005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-08-27 16:19:21.016894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libnvidia-fatbinaryloader.so.396.37: cannot open shared object file: No such file or directory\n",
      "2022-08-27 16:19:21.016917: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-27 16:19:21.016936: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (clive-T470p): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from alibi.explainers import AnchorTabular\n",
    "\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi_detect.cd import ChiSquareDrift, TabularDrift\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "\n",
    "from alibi_detect.od import OutlierVAE\n",
    "from alibi_detect.utils.perturbation import inject_outlier_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128055d",
   "metadata": {},
   "source": [
    "## Fetch and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0ae007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch adult dataset\n",
    "adult = fetch_adult()\n",
    "\n",
    "# separate columns in numerical and categorical.\n",
    "categorical_names = [adult.feature_names[i] for i in adult.category_map.keys()]\n",
    "categorical_ids = list(adult.category_map.keys())\n",
    "\n",
    "numerical_names = [name for i, name in enumerate(adult.feature_names) if i not in adult.category_map.keys()]\n",
    "numerical_ids = [i for i in range(len(adult.feature_names)) if i not in adult.category_map.keys()]\n",
    "\n",
    "X = adult.data\n",
    "Y = adult.target\n",
    "\n",
    "feature_names = adult.feature_names\n",
    "category_map = adult.category_map\n",
    "\n",
    "labels = ['No!', 'Yes!']\n",
    "\n",
    "def print_preds(preds: dict, preds_name: str) -> None:\n",
    "    print(preds_name)\n",
    "    print('Drift? {}'.format(labels[preds['data']['is_drift']]))\n",
    "    print(f'p-value: {preds[\"data\"][\"p_val\"]:.3f}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd430437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Associates', 'Bachelors', 'Doctorate', 'Dropout', 'High School grad', 'Masters', 'Prof-School']\n",
      "Low education: ['Dropout', 'High School grad', 'Bachelors']\n",
      "High education: ['Bachelors', 'Masters', 'Doctorate']\n"
     ]
    }
   ],
   "source": [
    "education_col = adult.feature_names.index('Education')\n",
    "education = adult.category_map[education_col]\n",
    "print(education)\n",
    "# define low education\n",
    "low_education = [\n",
    "    education.index('Dropout'),\n",
    "    education.index('High School grad'),\n",
    "    education.index('Bachelors')\n",
    "    \n",
    "]\n",
    "# define high education\n",
    "high_education = [\n",
    "    education.index('Bachelors'),\n",
    "    education.index('Masters'),\n",
    "    education.index('Doctorate')\n",
    "]\n",
    "print(\"Low education:\", [education[i] for i in low_education])\n",
    "print(\"High education:\", [education[i] for i in high_education])\n",
    "# select instances for low and high education\n",
    "low_education_mask = pd.Series(X[:, education_col]).isin(low_education).to_numpy()\n",
    "high_education_mask = pd.Series(X[:, education_col]).isin(high_education).to_numpy()\n",
    "X_low, X_high, Y_low, Y_high = X[low_education_mask], X[high_education_mask], Y[low_education_mask], Y[high_education_mask]\n",
    "size = 1000\n",
    "np.random.seed(0)\n",
    "\n",
    "# define reference and H0 dataset\n",
    "#idx_hgh = np.random.choice(np.arange(X_high.shape[0]), size=2*size, replace=False)\n",
    "x_ref, x_h0, y_ref, y_h0 = train_test_split(X_high, Y_high, test_size=0.4, random_state=5, shuffle=True)\n",
    "\n",
    "# define reference and H1 dataset\n",
    "#idx_low = np.random.choice(np.arange(X_low.shape[0]), size=size, replace=False)\n",
    "x_h1 = X_low\n",
    "y_h1 = Y_low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f670aac2",
   "metadata": {},
   "source": [
    "## Drift Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075a434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_per_feature = {f: None for f in list(category_map.keys())}\n",
    "cd = TabularDrift(x_ref, p_val=.05, categories_per_feature=categories_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb58fb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? No!\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(x_h0)\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5188ae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? Yes!\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(x_h1)\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671ee7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.utils.saving import save_detector\n",
    "save_detector(cd, \"./drift-detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22106b54",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e970837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(sparse_threshold=0,\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [0, 8, 9, 10]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [1, 2, 3, 4, 5, 6, 7, 11])])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(n_estimators=50))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(sparse_threshold=0,\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [0, 8, 9, 10]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [1, 2, 3, 4, 5, 6, 7, 11])])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(n_estimators=50))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=0,\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [0, 8, 9, 10]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [1, 2, 3, 4, 5, 6, 7, 11])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[0, 8, 9, 10]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[1, 2, 3, 4, 5, 6, 7, 11]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(sparse_threshold=0,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [0, 8, 9, 10]),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  [1, 2, 3, 4, 5, 6, 7, 11])])),\n",
       "                ('classifier', RandomForestClassifier(n_estimators=50))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_features = [x for x in range(len(feature_names)) if x not in list(category_map.keys())]\n",
    "ordinal_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                      ('scaler', StandardScaler())])\n",
    "categorical_features = list(category_map.keys())\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', ordinal_transformer, ordinal_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features)],\n",
    "                                sparse_threshold=0)\n",
    "np.random.seed(0)\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "train_pipeline = Pipeline(steps=[('preprocessor',preprocessor),('classifier',clf)])\n",
    "train_pipeline.fit(x_ref, y_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a3ab640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.983756119270138\n",
      "Test accuracy:  0.7774441107774441\n"
     ]
    }
   ],
   "source": [
    "predict_fn = lambda x: train_pipeline.predict(x)\n",
    "print('Train accuracy: ', accuracy_score(y_ref, predict_fn(x_ref)))\n",
    "print('Test accuracy: ', accuracy_score(y_h0, predict_fn(x_h0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0828f18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./classifier/model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "os.makedirs(\"./classifier\", exist_ok=True)\n",
    "dump(train_pipeline, './classifier/model.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b088f",
   "metadata": {},
   "source": [
    "## Outlier Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76369666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./preprocessor/model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"./preprocessor\", exist_ok=True)\n",
    "dump(preprocessor, './preprocessor/model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d178b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.transform(x_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "654b70ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No threshold level set. Need to infer threshold using `infer_threshold`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [=] - 1s 16ms/step - loss_ma: 0.3319\n",
      "71/71 [=] - 1s 16ms/step - loss_ma: 0.1736\n",
      "71/71 [=] - 1s 16ms/step - loss_ma: 0.1604\n",
      "71/71 [=] - 1s 16ms/step - loss_ma: 0.1561\n",
      "71/71 [=] - 1s 16ms/step - loss_ma: 0.1541\n"
     ]
    }
   ],
   "source": [
    "n_features = X_train.shape[1]\n",
    "latent_dim = 2\n",
    "\n",
    "encoder_net = tf.keras.Sequential(\n",
    "    [\n",
    "        InputLayer(input_shape=(n_features,)),\n",
    "        Dense(25, activation=tf.nn.relu),\n",
    "         Dense(10, activation=tf.nn.relu),\n",
    "        Dense(5, activation=tf.nn.relu)\n",
    "    ])\n",
    "\n",
    "decoder_net = tf.keras.Sequential(\n",
    "    [\n",
    "        InputLayer(input_shape=(latent_dim,)),\n",
    "        Dense(5, activation=tf.nn.relu),\n",
    "        Dense(10, activation=tf.nn.relu),\n",
    "        Dense(25, activation=tf.nn.relu),\n",
    "        Dense(n_features, activation=None)\n",
    "    ])\n",
    "\n",
    "# initialize outlier detector\n",
    "od = OutlierVAE(threshold=None,  # threshold for outlier score\n",
    "                score_type='mse',  # use MSE of reconstruction error for outlier detection\n",
    "                encoder_net=encoder_net,  # can also pass VAE model instead\n",
    "                decoder_net=decoder_net,  # of separate encoder and decoder\n",
    "                latent_dim=latent_dim,\n",
    "                samples=5)\n",
    "\n",
    "# train\n",
    "od.fit(X_train,\n",
    "        loss_fn=tf.keras.losses.mse,\n",
    "         epochs=5,\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7fb683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 11] [0, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "cat_cols = list(category_map.keys())\n",
    "num_cols = [col for col in range(x_ref.shape[1]) if col not in cat_cols]\n",
    "print(cat_cols, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4542f3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.57% outliers\n"
     ]
    }
   ],
   "source": [
    "perc_outlier = 10\n",
    "data = inject_outlier_tabular(x_ref, num_cols, perc_outlier, n_std=8., min_std=6.)\n",
    "X_threshold, y_threshold = data.data, data.target\n",
    "X_threshold_, y_threshold_ = X_threshold.copy(), y_threshold.copy()  # store for comparison later\n",
    "outlier_perc = 100 * y_threshold.sum() / len(y_threshold)\n",
    "print('{:.2f}% outliers'.format(outlier_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c15a0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_outlier = 100\n",
    "data = inject_outlier_tabular(x_ref, num_cols, perc_outlier, n_std=8., min_std=6.)\n",
    "X_outliers, y_outliers = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "973169df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New threshold: 0.7029458038525345\n"
     ]
    }
   ],
   "source": [
    "v = np.c_[preprocessor.transform(X_threshold)]\n",
    "od.infer_threshold(v, threshold_perc=100-outlier_perc, outlier_perc=100)\n",
    "print('New threshold: {}'.format(od.threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db79b91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "save_detector(od, \"./outlier-detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd1e66",
   "metadata": {},
   "source": [
    "## Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07c26e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnchorTabular(meta={\n",
       "  'name': 'AnchorTabular',\n",
       "  'type': ['blackbox'],\n",
       "  'explanations': ['local'],\n",
       "  'params': {'seed': 1, 'disc_perc': [25, 50, 75]},\n",
       "  'version': '0.7.0'}\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_fn = lambda x: train_pipeline.predict(x)\n",
    "explainer = AnchorTabular(predict_fn, feature_names, categorical_names=category_map, seed=1)\n",
    "explainer.fit(x_ref, disc_perc=[25, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8c76dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  <=50K\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "class_names = adult.target_names\n",
    "print('Prediction: ', class_names[explainer.predictor(x_h0[idx].reshape(1, -1))[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00b94f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find an result satisfying the 0.95 precision constraint. Now returning the best non-eligible result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: Age <= 31.00 AND Hours per week <= 40.00 AND Capital Gain <= 0.00 AND Education = Bachelors AND Capital Loss <= 0.00 AND Workclass = Private AND Country = United-States\n",
      "Precision: 0.88\n",
      "Coverage: 0.10\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer.explain(x_h0[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f37844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.saving import save_explainer\n",
    "save_explainer(explainer,\"./explainer/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c89dcd",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20c9b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./infer-data\", exist_ok=True)\n",
    "with open('./infer-data/test.npy', 'wb') as f:\n",
    "    np.save(f,x_ref)\n",
    "    np.save(f,x_h1)\n",
    "    np.save(f,y_ref)\n",
    "    np.save(f,X_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8e5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
