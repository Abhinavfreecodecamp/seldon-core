{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lesbian-springer",
   "metadata": {},
   "source": [
    "## Huggingface Speech to Sentiment Pipeline Example\n",
    "\n",
    "In this example we create a Pipeline to chain two huggingface models to allow speech to sentiment functionalityand add an explainer to understand the result.\n",
    "\n",
    "This example requires ffmpeg package to be installed locally. run `make install-requirements` for Python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3154774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "import torchaudio\n",
    "from IPython.display import Audio\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeef0f7",
   "metadata": {},
   "source": [
    "Create a method to load speech from recorder; transform into mp3 and send at base64 data. On return of the result extract and show the text and sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526b0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "reqJson = json.loads('{\"inputs\":[{\"name\":\"args\", \"parameters\": {\"content_type\": \"base64\"}, \"data\":[],\"datatype\":\"BYTES\",\"shape\":[1]}]}')\n",
    "url = \"http://0.0.0.0:9000/v2/models/model/infer\"\n",
    "def infer(resource: str):\n",
    "    with open('recording.webm', 'wb') as f:\n",
    "        f.write(recorder.audio.value)\n",
    "    !ffmpeg -i recording.webm -vn -ab 128k -ar 44100 file.mp3 -y -hide_banner -loglevel panic\n",
    "    with open(\"file.mp3\", mode='rb') as file:\n",
    "        fileContent = file.read()\n",
    "        encoded = base64.b64encode(fileContent)\n",
    "        base64_message = encoded.decode('utf-8')\n",
    "    reqJson[\"inputs\"][0][\"data\"] = [str(base64_message)]\n",
    "    headers = {\"Content-Type\": \"application/json\", \"seldon-model\": resource}\n",
    "    response_raw = requests.post(url, json=reqJson, headers=headers)\n",
    "    j = response_raw.json()\n",
    "    predictionEncoded = j[\"outputs\"][0][\"data\"][0]\n",
    "    decodedSentiment = base64.b64decode(predictionEncoded)\n",
    "    textEncoded = j[\"outputs\"][1][\"data\"][0]\n",
    "    decodedText = base64.b64decode(textEncoded)\n",
    "    reqId = response_raw.headers[\"x-request-id\"]\n",
    "    print(reqId)\n",
    "    os.environ[\"REQUEST_ID\"]=reqId\n",
    "    print(decodedText)\n",
    "    print(decodedSentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026afc59",
   "metadata": {},
   "source": [
    "### Load Huggingface Models\n",
    "\n",
    "We will load two Huggingface models for speech to text and text to sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b7a0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: mlops.seldon.io/v1alpha1\n",
      "kind: Model\n",
      "metadata:\n",
      "  name: whisper\n",
      "spec:\n",
      "  storageUri: \"gs://seldon-models/mlserver/huggingface/whisper\"\n",
      "  requirements:\n",
      "  - huggingface\n",
      "---\n",
      "apiVersion: mlops.seldon.io/v1alpha1\n",
      "kind: Model\n",
      "metadata:\n",
      "  name: sentiment\n",
      "spec:\n",
      "  storageUri: \"gs://seldon-models/mlserver/huggingface/sentiment\"\n",
      "  requirements:\n",
      "  - huggingface\n"
     ]
    }
   ],
   "source": [
    "!cat ../../models/hf-whisper.yaml\n",
    "!echo \"---\"\n",
    "!cat ../../models/hf-sentiment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aacd53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "!seldon model load -f ../../models/hf-whisper.yaml\n",
    "!seldon model load -f ../../models/hf-sentiment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13a6082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "!seldon model status whisper -w ModelAvailable | jq -M .\n",
    "!seldon model status sentiment -w ModelAvailable | jq -M ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4149096",
   "metadata": {},
   "source": [
    "### Create Explain Pipeline\n",
    "\n",
    "To allow Alibi-Explain to more easily explain the sentiment we will explain a Pipeline that transforms the raw JSON output of the Huggingface sentiment model into a binary classifier to allow the AnchorText model to more easily work on the sentiment value.\n",
    "\n",
    "The python sentiment-transform model will convert JSON to a simple 1,0 result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251ae9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from mlserver import MLModel\r\n",
      "from mlserver.types import InferenceRequest, InferenceResponse, ResponseOutput\r\n",
      "from mlserver.codecs import StringCodec, Base64Codec, NumpyRequestCodec\r\n",
      "from mlserver.codecs.string import StringRequestCodec\r\n",
      "from mlserver.codecs.numpy import NumpyRequestCodec\r\n",
      "import base64\r\n",
      "from mlserver.logging import logger\r\n",
      "import numpy as np\r\n",
      "import json\r\n",
      "\r\n",
      "class SentimentTransformRuntime(MLModel):\r\n",
      "\r\n",
      "  async def load(self) -> bool:\r\n",
      "    return self.ready\r\n",
      "\r\n",
      "  async def predict(self, payload: InferenceRequest) -> InferenceResponse:\r\n",
      "    res_list = self.decode_request(payload, default_codec=StringRequestCodec)\r\n",
      "    scores = []\r\n",
      "    for res in res_list:\r\n",
      "      logger.debug(\"decoded data: %s\",res)\r\n",
      "      sentiment = json.loads(res)\r\n",
      "      if sentiment[\"label\"] == \"POSITIVE\":\r\n",
      "        scores.append(1)\r\n",
      "      else:\r\n",
      "        scores.append(0)\r\n",
      "    return NumpyRequestCodec.encode_response(\r\n",
      "      model_name=\"sentiments\",\r\n",
      "      payload=np.array(scores)\r\n",
      "    )\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./sentiment-transform/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd20062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: mlops.seldon.io/v1alpha1\r\n",
      "kind: Model\r\n",
      "metadata:\r\n",
      "  name: sentiment-transform\r\n",
      "spec:\r\n",
      "  storageUri: \"gs://seldon-models/scv2/examples/huggingface/sentiment-transform\"\r\n",
      "  requirements:\r\n",
      "  - mlserver\r\n",
      "  - python\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../../models/hf-sentiment-explainer-transform.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b8240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\r\n"
     ]
    }
   ],
   "source": [
    "!seldon model load -f ../../models/hf-sentiment-explainer-transform.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d02d017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\r\n"
     ]
    }
   ],
   "source": [
    "!seldon model status sentiment-transform -w ModelAvailable | jq -M ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff58083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: mlops.seldon.io/v1alpha1\r\n",
      "kind: Pipeline\r\n",
      "metadata:\r\n",
      "  name: sentiment-explain\r\n",
      "spec:\r\n",
      "  steps:\r\n",
      "    - name: sentiment\r\n",
      "      tensorMap:\r\n",
      "        sentiment-explain.inputs.predict: args\r\n",
      "    - name: sentiment-transform\r\n",
      "      inputs:\r\n",
      "      - sentiment\r\n",
      "  output:\r\n",
      "    steps:\r\n",
      "    - sentiment-transform\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../../pipelines/sentiment-explain.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "830d6bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\r\n"
     ]
    }
   ],
   "source": [
    "!seldon pipeline load -f ../../pipelines/sentiment-explain.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95fa2faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"pipelineName\": \"sentiment-explain\",\r\n",
      "  \"versions\": [\r\n",
      "    {\r\n",
      "      \"pipeline\": {\r\n",
      "        \"name\": \"sentiment-explain\",\r\n",
      "        \"uid\": \"cdcni240uk9s73avbnhg\",\r\n",
      "        \"version\": 2,\r\n",
      "        \"steps\": [\r\n",
      "          {\r\n",
      "            \"name\": \"sentiment\",\r\n",
      "            \"tensorMap\": {\r\n",
      "              \"sentiment-explain.inputs.predict\": \"args\"\r\n",
      "            }\r\n",
      "          },\r\n",
      "          {\r\n",
      "            \"name\": \"sentiment-transform\",\r\n",
      "            \"inputs\": [\r\n",
      "              \"sentiment.outputs\"\r\n",
      "            ]\r\n",
      "          }\r\n",
      "        ],\r\n",
      "        \"output\": {\r\n",
      "          \"steps\": [\r\n",
      "            \"sentiment-transform.outputs\"\r\n",
      "          ]\r\n",
      "        },\r\n",
      "        \"kubernetesMeta\": {}\r\n",
      "      },\r\n",
      "      \"state\": {\r\n",
      "        \"pipelineVersion\": 2,\r\n",
      "        \"status\": \"PipelineReady\",\r\n",
      "        \"reason\": \"created pipeline\",\r\n",
      "        \"lastChangeTimestamp\": \"2022-10-26T18:14:32.540457111Z\"\r\n",
      "      }\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!seldon pipeline status sentiment-explain -w PipelineReady| jq -M ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "229c61af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: mlops.seldon.io/v1alpha1\r\n",
      "kind: Model\r\n",
      "metadata:\r\n",
      "  name: sentiment-explainer\r\n",
      "spec:\r\n",
      "  storageUri: \"gs://seldon-models/scv2/examples/huggingface/speech-sentiment/explainer\"\r\n",
      "  explainer:\r\n",
      "    type: anchor_text\r\n",
      "    pipelineRef: sentiment-explain\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../../models/hf-sentiment-explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ba179b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\r\n"
     ]
    }
   ],
   "source": [
    "!seldon model load -f ../../models/hf-sentiment-explainer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1efedc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\r\n"
     ]
    }
   ],
   "source": [
    "!seldon model status sentiment-explainer -w ModelAvailable | jq -M ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddb4c53",
   "metadata": {},
   "source": [
    "### Speech to Sentiment Pipeline with Explanation\n",
    "\n",
    "We can now create the final pipeline that will take speech and generate sentiment alongwith an explanation of why that sentiment was predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d787e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: mlops.seldon.io/v1alpha1\r\n",
      "kind: Pipeline\r\n",
      "metadata:\r\n",
      "  name: speech-to-sentiment\r\n",
      "spec:\r\n",
      "  steps:\r\n",
      "    - name: whisper\r\n",
      "    - name: sentiment\r\n",
      "      inputs:\r\n",
      "      - whisper\r\n",
      "      tensorMap:\r\n",
      "        whisper.outputs.output: args\r\n",
      "    - name: sentiment-explainer\r\n",
      "      inputs:\r\n",
      "      - whisper\r\n",
      "  output:\r\n",
      "    steps:\r\n",
      "    - sentiment\r\n",
      "    - whisper\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../../pipelines/speech-to-sentiment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22d5997a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\r\n"
     ]
    }
   ],
   "source": [
    "!seldon pipeline load -f ../../pipelines/speech-to-sentiment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bad7972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"pipelineName\": \"speech-to-sentiment\",\r\n",
      "  \"versions\": [\r\n",
      "    {\r\n",
      "      \"pipeline\": {\r\n",
      "        \"name\": \"speech-to-sentiment\",\r\n",
      "        \"uid\": \"cdcnibk0uk9s73avbni0\",\r\n",
      "        \"version\": 2,\r\n",
      "        \"steps\": [\r\n",
      "          {\r\n",
      "            \"name\": \"sentiment\",\r\n",
      "            \"inputs\": [\r\n",
      "              \"whisper.outputs\"\r\n",
      "            ],\r\n",
      "            \"tensorMap\": {\r\n",
      "              \"whisper.outputs.output\": \"args\"\r\n",
      "            }\r\n",
      "          },\r\n",
      "          {\r\n",
      "            \"name\": \"sentiment-explainer\",\r\n",
      "            \"inputs\": [\r\n",
      "              \"whisper.outputs\"\r\n",
      "            ]\r\n",
      "          },\r\n",
      "          {\r\n",
      "            \"name\": \"whisper\"\r\n",
      "          }\r\n",
      "        ],\r\n",
      "        \"output\": {\r\n",
      "          \"steps\": [\r\n",
      "            \"sentiment.outputs\",\r\n",
      "            \"whisper.outputs\"\r\n",
      "          ]\r\n",
      "        },\r\n",
      "        \"kubernetesMeta\": {}\r\n",
      "      },\r\n",
      "      \"state\": {\r\n",
      "        \"pipelineVersion\": 2,\r\n",
      "        \"status\": \"PipelineReady\",\r\n",
      "        \"reason\": \"created pipeline\",\r\n",
      "        \"lastChangeTimestamp\": \"2022-10-26T18:15:10.325370389Z\"\r\n",
      "      }\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!seldon pipeline status speech-to-sentiment -w PipelineReady| jq -M ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0800c8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85884fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e089c4439542eab9cd5fbcf41e9d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera = CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b8984ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdcnm5mjnkrs73f2p0jg\n",
      "b'{\"text\": \" The film was interesting and exciting.\"}'\n",
      "b'{\"label\": \"POSITIVE\", \"score\": 0.9997865557670593}'\n"
     ]
    }
   ],
   "source": [
    "infer(\"speech-to-sentiment.pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d36a92",
   "metadata": {},
   "source": [
    "We will wait for the explanation which is run asynchronously to the functional output from the Pipeline above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81107af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........\n",
      "Explanation anchors: ['exciting']\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    base64Res = !seldon pipeline inspect speech-to-sentiment.sentiment-explainer.outputs --format json \\\n",
    "          --request-id ${REQUEST_ID}\n",
    "    j = json.loads(base64Res[0])\n",
    "    if j[\"topics\"][0][\"msgs\"] is not None:\n",
    "        expBase64 = j[\"topics\"][0][\"msgs\"][0][\"value\"][\"outputs\"][0][\"contents\"][\"bytesContents\"][0]\n",
    "        expRaw = base64.b64decode(expBase64)\n",
    "        exp = json.loads(expRaw)\n",
    "        print(\"\")\n",
    "        print(\"Explanation anchors:\",exp[\"data\"][\"anchor\"])\n",
    "        break\n",
    "    else:\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264570be",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e401645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "!seldon pipeline unload speech-to-sentiment\n",
    "!seldon pipeline unload sentiment-explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dd63ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "!seldon model unload whisper\n",
    "!seldon model unload sentiment\n",
    "!seldon model unload sentiment-explainer\n",
    "!seldon model unload sentiment-transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff17194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
