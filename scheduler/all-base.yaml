version: "3.9"

services:

  agent-mlserver:
    build:
      dockerfile: ./Dockerfile.agent
      context: .
    image: "${AGENT_IMAGE_AND_TAG}"
    command:
      - "/bin/agent"
      - "--log-level"
      - "debug"
      - "--config-path"
      - "/mnt/config"
      - "--rclone-host"
      - "rclone-mlserver"
      - "--inference-host"
      - "mlserver"
      - "--agent-host"
      - "agent-mlserver"
      - "--server-name"
      - "mlserver"
    environment:
      - SELDON_OVERCOMMIT_PERCENTAGE=${AGENT_OVERCOMMIT_PERCENTAGE}
      - SELDON_REVERSE_PROXY_HTTP_PORT=${SELDON_MLSERVER_REVERSE_PROXY_HTTP_PORT}
      - SELDON_REVERSE_PROXY_GRPC_PORT=${SELDON_MLSERVER_REVERSE_PROXY_GRPC_PORT}
      - SELDON_SERVER_HTTP_PORT=${SERVER_MLSERVER_HTTP_PORT}
      - SELDON_SERVER_GRPC_PORT=${SERVER_MLSERVER_GRPC_PORT}
      - SELDON_DEBUG_GRPC_PORT=${AGENT_MLSERVER_DEBUG_PORT}
      - SELDON_SCHEDULER_HOST=scheduler
      - SELDON_SCHEDULER_PORT=${SCHEDULER_AGENT_PORT}
      - MEMORY_REQUEST=${AGENT_MEMORY_REQUEST}
      - SELDON_SERVER_TYPE=mlserver
      - SELDON_SERVER_CAPABILITIES=lightgbm,mlflow,python,sklearn,spark-mlib,xgboost

  agent-triton:
    build:
      dockerfile: ./Dockerfile.agent
      context: .
    image: "${AGENT_IMAGE_AND_TAG}"
    command:
      - "/bin/agent"
      - "--log-level"
      - "debug"
      - "--config-path"
      - "/mnt/config"
      - "--rclone-host"
      - "rclone-triton"
      - "--rclone-port"
      - ${RCLONE_TRITON_HTTP_PORT}
      - "--inference-host"
      - "triton"
      - "--agent-host"
      - "agent-triton"
      - "--server-name"
      - "triton"
    environment:
      - SELDON_OVERCOMMIT_PERCENTAGE=${AGENT_OVERCOMMIT_PERCENTAGE}
      - SELDON_REVERSE_PROXY_HTTP_PORT=${SELDON_TRITON_REVERSE_PROXY_HTTP_PORT}
      - SELDON_REVERSE_PROXY_GRPC_PORT=${SELDON_TRITON_REVERSE_PROXY_GRPC_PORT}
      - SELDON_SERVER_HTTP_PORT=${SERVER_TRITON_HTTP_PORT}
      - SELDON_SERVER_GRPC_PORT=${SERVER_TRITON_GRPC_PORT}
      - SELDON_DEBUG_GRPC_PORT=${AGENT_TRITON_DEBUG_PORT}
      - SELDON_SCHEDULER_HOST=scheduler
      - SELDON_SCHEDULER_PORT=${SCHEDULER_AGENT_PORT}
      - MEMORY_REQUEST=${AGENT_MEMORY_REQUEST}
      - SELDON_SERVER_TYPE=triton
      - SELDON_SERVER_CAPABILITIES=dali,fil,onnx,openvino,pytorch,tensorflow,tensorrt,triton-python
      
  dataflow:
    build:
      dockerfile: ./Dockerfile.dataflow
      context: .
    image: "${DATAFLOW_IMAGE_AND_TAG}"
    environment:
      - SELDON_UPSTREAM_PORT=${SCHEDULER_DATAFLOW_PORT}
      - SELDON_KAFKA_BOOTSTRAP_SERVERS=kafka:${KAFKA_BROKER_INTERNAL_PORT}
      - SELDON_CORES_COUNT=4

  envoy:
    build:
      dockerfile: ./Dockerfile.envoy-local
      context: .
    image: "${ENVOY_IMAGE_AND_TAG}"

  rclone-mlserver:
    build:
      dockerfile: ./Dockerfile.rclone
      context: .
    image: "${RCLONE_IMAGE_AND_TAG}"
    
  rclone-triton:
    build:
      dockerfile: ./Dockerfile.rclone
      context: .
    image: "${RCLONE_IMAGE_AND_TAG}"
    command:
      - "rcd"
      - "--rc-no-auth"
      - "--config=/rclone/rclone.conf"
      - "--rc-addr=0.0.0.0:${RCLONE_TRITON_HTTP_PORT}"
      - "--verbose"

  scheduler:
    build:
      dockerfile: ./Dockerfile.scheduler
      context: .
    image: "${SCHEDULER_IMAGE_AND_TAG}"

  mlserver:
    image: "${SERVER_MLSERVER_IMAGE_AND_TAG}"
    command:
      - "mlserver"
      - "start"
      - "/mnt/agent/models"
    environment:
      - MLSERVER_LOAD_MODELS_AT_STARTUP=${MLSERVER_LOAD_MODELS_AT_STARTUP}
    
  triton:
    image: "${SERVER_TRITON_IMAGE_AND_TAG}"
    command:
      - "/opt/tritonserver/bin/tritonserver"
      - "--model-repository=/mnt/agent/models"
      - "--http-port=${SERVER_TRITON_HTTP_PORT}"
      - "--grpc-port=${SERVER_TRITON_GRPC_PORT}"
      - "--model-control-mode=explicit"
      - "--log-verbose=${TRITON_LOG_LEVEL:-0}"
    shm_size: 1g
    ulimits:
      memlock: "-1"
      stack: 67108864

  modelgateway:
    build:
      dockerfile: ./Dockerfile.modelgateway
      context: .
    image: "${MODELGATEWAY_IMAGE_AND_TAG}"
    command:
      - "/bin/modelgateway"
      - "--log-level"
      - "debug"
      - "--config-path"
      - "/mnt/config"
      - "--scheduler-host"
      - "scheduler"
      - "--scheduler-port"
      - ${SCHEDULER_SERVER_PORT}
      - "--envoy-host"
      - "envoy"
      - "--envoy-port"
      - ${ENVOY_DATA_PORT}

  pipelinegateway:
    build:
      dockerfile: ./Dockerfile.pipelinegateway
      context: .
    image: "${PIPELINEGATEWAY_IMAGE_AND_TAG}"
    command:
      - "/bin/pipelinegateway"
      - "--log-level"
      - "debug"
      - "--config-path"
      - "/mnt/config"
      - "--http-port"
      - ${PIPELINEGATEWAY_HTTP_PORT}
      - "--grpc-port"
      - ${PIPELINEGATEWAY_GRPC_PORT}
      
  kafka:
    image: "${KAFKA_IMAGE_AND_TAG}"
    command: [
      "sh", "-c",
      "./bin/kafka-storage.sh format -t $$(./bin/kafka-storage.sh random-uuid) -c ./config/kraft/server.properties && ./bin/kafka-server-start.sh ./config/kraft/server.properties"
    ]
    ports:
    - "${KAFKA_BROKER_INTERNAL_PORT}:${KAFKA_BROKER_INTERNAL_PORT}"
    - "${KAFKA_BROKER_EXTERNAL_PORT}:${KAFKA_BROKER_EXTERNAL_PORT}"    
    environment:
      LOG_DIR: "/tmp/logs"

