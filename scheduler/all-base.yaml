version: "3.9"

volumes:
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local

services:

  agent-mlserver:
    build:
      dockerfile: ./Dockerfile.agent
      context: .
    image: "${AGENT_IMAGE_AND_TAG}"
    environment:
      - SELDON_OVERCOMMIT_PERCENTAGE=${AGENT_OVERCOMMIT_PERCENTAGE}
      - SELDON_REVERSE_PROXY_HTTP_PORT=${SELDON_MLSERVER_REVERSE_PROXY_HTTP_PORT}
      - SELDON_REVERSE_PROXY_GRPC_PORT=${SELDON_MLSERVER_REVERSE_PROXY_GRPC_PORT}
      - SELDON_SERVER_HTTP_PORT=${SERVER_MLSERVER_HTTP_PORT}
      - SELDON_SERVER_GRPC_PORT=${SERVER_MLSERVER_GRPC_PORT}
      - SELDON_DEBUG_GRPC_PORT=${AGENT_MLSERVER_DEBUG_PORT}
      - SELDON_SCHEDULER_HOST=scheduler
      - SELDON_SCHEDULER_PORT=${SCHEDULER_AGENT_PORT}
      - MEMORY_REQUEST=${AGENT_MEMORY_REQUEST}
      - SELDON_ENVOY_HOST=envoy
      - SELDON_ENVOY_PORT=${ENVOY_DATA_PORT}
      - SELDON_SERVER_TYPE=mlserver
      - SELDON_SERVER_CAPABILITIES=mlserver,alibi-detect,alibi-explain,lightgbm,mlflow,python,sklearn,spark-mlib,xgboost

  agent-triton:
    build:
      dockerfile: ./Dockerfile.agent
      context: .
    image: "${AGENT_IMAGE_AND_TAG}"
    environment:
      - SELDON_OVERCOMMIT_PERCENTAGE=${AGENT_OVERCOMMIT_PERCENTAGE}
      - SELDON_REVERSE_PROXY_HTTP_PORT=${SELDON_TRITON_REVERSE_PROXY_HTTP_PORT}
      - SELDON_REVERSE_PROXY_GRPC_PORT=${SELDON_TRITON_REVERSE_PROXY_GRPC_PORT}
      - SELDON_SERVER_HTTP_PORT=${SERVER_TRITON_HTTP_PORT}
      - SELDON_SERVER_GRPC_PORT=${SERVER_TRITON_GRPC_PORT}
      - SELDON_DEBUG_GRPC_PORT=${AGENT_TRITON_DEBUG_PORT}
      - SELDON_SCHEDULER_HOST=scheduler
      - SELDON_SCHEDULER_PORT=${SCHEDULER_AGENT_PORT}
      - MEMORY_REQUEST=${AGENT_MEMORY_REQUEST}
      - SELDON_ENVOY_HOST=envoy
      - SELDON_ENVOY_PORT=${ENVOY_DATA_PORT}
      - SELDON_SERVER_TYPE=triton
      - SELDON_SERVER_CAPABILITIES=triton,dali,fil,onnx,openvino,python,pytorch,tensorflow,tensorrt

  dataflow:
    build:
      dockerfile: ./Dockerfile.dataflow
      context: .
    image: "${DATAFLOW_IMAGE_AND_TAG}"
    depends_on:
      - kafka
      - otel-collector

  envoy:
    build:
      dockerfile: ./Dockerfile.envoy
      context: .
    image: "${ENVOY_IMAGE_AND_TAG}"

  grafana:
    image: "${GRAFANA_IMAGE_AND_TAG}"
    ports:
      - 3000:3000

  hodometer:
    build:
      dockerfile: ./../hodometer/Dockerfile.hodometer
      context: ./../hodometer
    image: "${HODOMETER_IMAGE_AND_TAG}"
    environment:
      - LOG_LEVEL=${HODOMETER_LOG_LEVEL}
      - METRICS_LEVEL=${HODOMETER_METRICS_LEVEL}
      - SCHEDULER_PORT=${SCHEDULER_SERVER_PORT}

  hodometer-receiver:
    build:
      dockerfile: ./../hodometer/Dockerfile.receiver
      context: ./../hodometer
    image: "seldonio/hodometer-receiver:latest"
    environment:
      - LISTEN_PORT=${HODOMETER_RECEIVER_PORT}
      - LOG_LEVEL=${HODOMETER_RECEIVER_LOG_LEVEL}
      - RECORD_LEVEL=${HODOMETER_RECEIVER_RECORD_LEVEL}
    profiles:
      - "local_metrics"

  jaeger-all-in-one:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"
      - "14268"
      - "14250"

  kafka:
    image: docker.io/bitnami/kafka:3.1
    volumes:
      - "kafka_data:/bitnami"
    depends_on:
      - zookeeper

  modelgateway:
    build:
      dockerfile: ./Dockerfile.modelgateway
      context: .
    image: "${MODELGATEWAY_IMAGE_AND_TAG}"
    depends_on:
      - kafka
      - otel-collector

  otel-collector:
    image: ${OTELCOL_IMG}
    command: ["--config=/etc/otel-collector-config.yaml", "${OTELCOL_ARGS}"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "1888:1888"   # pprof extension
      #- "8888:8888"   # Prometheus metrics exposed by the collector
      #- "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4317:4317"        # OTLP gRPC receiver
      - "55670:55679" # zpages extension
    depends_on:
      - jaeger-all-in-one

  pipelinegateway:
    build:
      dockerfile: ./Dockerfile.pipelinegateway
      context: .
    image: "${PIPELINEGATEWAY_IMAGE_AND_TAG}"
    depends_on:
      - kafka
      - otel-collector

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"

  rclone-mlserver:
    build:
      dockerfile: ./Dockerfile.rclone
      context: .
    image: "${RCLONE_IMAGE_AND_TAG}"

  rclone-triton:
    build:
      dockerfile: ./Dockerfile.rclone
      context: .
    image: "${RCLONE_IMAGE_AND_TAG}"
    command:
      - "rcd"
      - "--rc-no-auth"
      - "--config=/rclone/rclone.conf"
      - "--rc-addr=0.0.0.0:${RCLONE_TRITON_HTTP_PORT}"
      - "--verbose"

  scheduler:
    user: "1000:1000"
    volumes:
      - type: bind
        source: ./mnt
        target: /mnt/config
    build:
      dockerfile: ./Dockerfile.scheduler
      context: .
    image: "${SCHEDULER_IMAGE_AND_TAG}"

  mlserver:
    image: "${SERVER_MLSERVER_IMAGE_AND_TAG}"
    command:
      - "mlserver"
      - "start"
      - "/mnt/agent/models"
    environment:
      - MLSERVER_LOAD_MODELS_AT_STARTUP=${MLSERVER_LOAD_MODELS_AT_STARTUP}
      - MLSERVER_METRICS_PORT=${SERVER_MLSERVER_METRICS_PORT}


  triton:
    image: "${SERVER_TRITON_IMAGE_AND_TAG}"
    command:
      - "/opt/tritonserver/bin/tritonserver"
      - "--model-repository=/mnt/agent/models"
      - "--http-port=${SERVER_TRITON_HTTP_PORT}"
      - "--grpc-port=${SERVER_TRITON_GRPC_PORT}"
      - "--model-control-mode=explicit"
      - "--log-verbose=${TRITON_LOG_LEVEL:-0}"
    shm_size: 1g
    ulimits:
      memlock: -1
      stack: 67108864

  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    volumes:
      - "zookeeper_data:/bitnami"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
