version: "3.9"

volumes:
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local

services:

  agent-mlserver:
    build:
      dockerfile: ./Dockerfile.agent
      context: .
    image: "${AGENT_IMAGE_AND_TAG}"
    environment:
      - SELDON_OVERCOMMIT_PERCENTAGE=${AGENT_OVERCOMMIT_PERCENTAGE}
      - SELDON_REVERSE_PROXY_HTTP_PORT=${SELDON_MLSERVER_REVERSE_PROXY_HTTP_PORT}
      - SELDON_REVERSE_PROXY_GRPC_PORT=${SELDON_MLSERVER_REVERSE_PROXY_GRPC_PORT}
      - SELDON_SERVER_HTTP_PORT=${SERVER_MLSERVER_HTTP_PORT}
      - SELDON_SERVER_GRPC_PORT=${SERVER_MLSERVER_GRPC_PORT}
      - SELDON_DEBUG_GRPC_PORT=${AGENT_MLSERVER_DEBUG_PORT}
      - SELDON_SCHEDULER_HOST=scheduler
      - SELDON_SCHEDULER_PORT=${SCHEDULER_AGENT_PORT}
      - MEMORY_REQUEST=${AGENT_MEMORY_REQUEST}
      - SELDON_SERVER_TYPE=mlserver
      - SELDON_SERVER_CAPABILITIES=mlserver,alibi-detect,lightgbm,mlflow,python,sklearn,spark-mlib,xgboost

  agent-triton:
    build:
      dockerfile: ./Dockerfile.agent
      context: .
    image: "${AGENT_IMAGE_AND_TAG}"
    environment:
      - SELDON_OVERCOMMIT_PERCENTAGE=${AGENT_OVERCOMMIT_PERCENTAGE}
      - SELDON_REVERSE_PROXY_HTTP_PORT=${SELDON_TRITON_REVERSE_PROXY_HTTP_PORT}
      - SELDON_REVERSE_PROXY_GRPC_PORT=${SELDON_TRITON_REVERSE_PROXY_GRPC_PORT}
      - SELDON_SERVER_HTTP_PORT=${SERVER_TRITON_HTTP_PORT}
      - SELDON_SERVER_GRPC_PORT=${SERVER_TRITON_GRPC_PORT}
      - SELDON_DEBUG_GRPC_PORT=${AGENT_TRITON_DEBUG_PORT}
      - SELDON_SCHEDULER_HOST=scheduler
      - SELDON_SCHEDULER_PORT=${SCHEDULER_AGENT_PORT}
      - MEMORY_REQUEST=${AGENT_MEMORY_REQUEST}
      - SELDON_SERVER_TYPE=triton
      - SELDON_SERVER_CAPABILITIES=triton,dali,fil,onnx,openvino,python,pytorch,tensorflow,tensorrt
      
  dataflow:
    build:
      dockerfile: ./Dockerfile.dataflow
      context: .
    image: "${DATAFLOW_IMAGE_AND_TAG}"
    environment:
      - SELDON_UPSTREAM_PORT=${SCHEDULER_DATAFLOW_PORT}
      - SELDON_KAFKA_BOOTSTRAP_SERVERS=kafka:${KAFKA_BROKER_INTERNAL_PORT}
      - SELDON_CORES_COUNT=4
    depends_on:
      - kafka
      - otel-collector
      
  envoy:
    build:
      dockerfile: ./Dockerfile.envoy
      context: .
    image: "${ENVOY_IMAGE_AND_TAG}"

  rclone-mlserver:
    build:
      dockerfile: ./Dockerfile.rclone
      context: .
    image: "${RCLONE_IMAGE_AND_TAG}"
    
  rclone-triton:
    build:
      dockerfile: ./Dockerfile.rclone
      context: .
    image: "${RCLONE_IMAGE_AND_TAG}"
    command:
      - "rcd"
      - "--rc-no-auth"
      - "--config=/rclone/rclone.conf"
      - "--rc-addr=0.0.0.0:${RCLONE_TRITON_HTTP_PORT}"
      - "--verbose"

  scheduler:
    build:
      dockerfile: ./Dockerfile.scheduler
      context: .
    image: "${SCHEDULER_IMAGE_AND_TAG}"

  mlserver:
    image: "${SERVER_MLSERVER_IMAGE_AND_TAG}"
    command:
      - "mlserver"
      - "start"
      - "/mnt/agent/models"
    environment:
      - MLSERVER_LOAD_MODELS_AT_STARTUP=${MLSERVER_LOAD_MODELS_AT_STARTUP}
    
  triton:
    image: "${SERVER_TRITON_IMAGE_AND_TAG}"
    command:
      - "/opt/tritonserver/bin/tritonserver"
      - "--model-repository=/mnt/agent/models"
      - "--http-port=${SERVER_TRITON_HTTP_PORT}"
      - "--grpc-port=${SERVER_TRITON_GRPC_PORT}"
      - "--model-control-mode=explicit"
      - "--log-verbose=${TRITON_LOG_LEVEL:-0}"
    shm_size: 1g
    ulimits:
      memlock: -1
      stack: 67108864

  modelgateway:
    build:
      dockerfile: ./Dockerfile.modelgateway
      context: .
    image: "${MODELGATEWAY_IMAGE_AND_TAG}"
    command:
      - "/bin/modelgateway"
      - "--log-level"
      - "debug"
      - "--config-path"
      - "/mnt/config"
      - "--scheduler-host"
      - "scheduler"
      - "--scheduler-port"
      - ${SCHEDULER_SERVER_PORT}
      - "--envoy-host"
      - "envoy"
      - "--envoy-port"
      - ${ENVOY_DATA_PORT}
    depends_on:
      - kafka
      - otel-collector

  pipelinegateway:
    build:
      dockerfile: ./Dockerfile.pipelinegateway
      context: .
    image: "${PIPELINEGATEWAY_IMAGE_AND_TAG}"
    command:
      - "/bin/pipelinegateway"
      - "--log-level"
      - "debug"
      - "--config-path"
      - "/mnt/config"
      - "--http-port"
      - ${PIPELINEGATEWAY_HTTP_PORT}
      - "--grpc-port"
      - ${PIPELINEGATEWAY_GRPC_PORT}
    depends_on:
      - kafka
      - otel-collector

  kafka:
    image: docker.io/bitnami/kafka:3.1
    volumes:
      - "kafka_data:/bitnami"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_MESSAGE_MAX_BYTES=1000000000      
    depends_on:
      - zookeeper
      
  jaeger-all-in-one:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"
      - "14268"
      - "14250"

  otel-collector:
    image: ${OTELCOL_IMG}
    command: ["--config=/etc/otel-collector-config.yaml", "${OTELCOL_ARGS}"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "1888:1888"   # pprof extension
      #- "8888:8888"   # Prometheus metrics exposed by the collector
      #- "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4317:4317"        # OTLP gRPC receiver
      - "55670:55679" # zpages extension
    depends_on:
      - jaeger-all-in-one

  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    volumes:
      - "zookeeper_data:/bitnami"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

