{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "biblical-newcastle",
   "metadata": {},
   "source": [
    "# Scheduler Local Test\n",
    "Test the grpc API.\n",
    "\n",
    "## Setup\n",
    "From project root\n",
    " 1. run `make start-local-svcs`. Starts 4 echo servers locally.\n",
    " 2. Build and run scheduler `make start-scheduler`\n",
    " 3. Run Envoy (needs a local envoy downloaded) See README.md `start-envoy_imcremental` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "portuguese-washer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!grpcurl -d '{\"name\":\"test\",\"replicas\":[\\\n",
    "                {\"inferenceSvc\":\"0.0.0.0\",\"inferencePort\":9100,\"agentPort\":9001},\\\n",
    "                {\"inferenceSvc\":\"0.0.0.0\",\"inferencePort\":9101,\"agentPort\":9001},\\\n",
    "                {\"inferenceSvc\":\"0.0.0.0\",\"inferencePort\":9102,\"agentPort\":9001}],\\\n",
    "        \"memory\":1000000,\\\n",
    "        \"capabilities\":[\"sklearn\"]}' \\\n",
    "         -plaintext \\\n",
    "         -proto ../apis/mlops/scheduler/scheduler.proto  0.0.0.0:9004 seldon.mlops.scheduler.Scheduler/AddServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "checked-intelligence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!grpcurl -d '{\"name\":\"model2\",\"requirements\":[\"sklearn\"],\"memory\":100000,\"replicas\":2}' \\\n",
    "         -plaintext \\\n",
    "         -proto ../apis/mlops/scheduler/scheduler.proto  0.0.0.0:9004 seldon.mlops.scheduler.Scheduler/LoadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "reliable-campus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"modelName\": \"model2\",\r\n",
      "  \"serverName\": \"test\",\r\n",
      "  \"assignment\": [\r\n",
      "    1,\r\n",
      "    2\r\n",
      "  ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!grpcurl -d '{\"name\":\"model2\"}' \\\n",
    "         -plaintext \\\n",
    "         -proto ../apis/mlops/scheduler/scheduler.proto  0.0.0.0:9004 seldon.mlops.scheduler.Scheduler/ModelStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "accepted-anderson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"serverName\": \"test\",\r\n",
      "  \"loadedModels\": [\r\n",
      "    \"model2\"\r\n",
      "  ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!grpcurl -d '{\"name\":\"test\"}' \\\n",
    "         -plaintext \\\n",
    "         -proto ../apis/mlops/scheduler/scheduler.proto  0.0.0.0:9004 seldon.mlops.scheduler.Scheduler/ServerStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-today",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-finish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
