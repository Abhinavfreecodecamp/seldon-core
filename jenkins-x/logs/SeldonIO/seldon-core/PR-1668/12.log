
Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mpr-build-comment[0m and container [32mstep-credential-initializer-cfrb5[0m
{"level":"warn","ts":1586203356.2598188,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: \"ref: refs/heads/0.8.0-**-support-backwards-incompats\" is not a valid GitHub commit ID"}
{"level":"info","ts":1586203356.2602007,"logger":"fallback-logger","caller":"creds-init/main.go:40","msg":"Credentials initialized."}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mpr-build-comment[0m and container [32mstep-working-dir-initializer-q9kpm[0m
{"level":"warn","ts":1586203365.599144,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1586203365.6013675,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p /workspace/source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mpr-build-comment[0m and container [32mstep-place-tools[0m

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mpr-build-comment[0m and container [32mstep-create-dir-workspace-9q8rh[0m
{"level":"warn","ts":1586203384.7915182,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1586203384.794908,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mpr-build-comment[0m and container [32mstep-git-source-seldonio-seldon-core-pr-1668-in-h4wt4[0m
{"level":"warn","ts":1586203385.214629,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: \"ref: refs/heads/0.8.0-**-support-backwards-incompats\" is not a valid GitHub commit ID"}
{"level":"info","ts":1586203389.6869645,"logger":"fallback-logger","caller":"git/git.go:103","msg":"Successfully cloned https://github.com/SeldonIO/seldon-core.git @ master in path /workspace/source"}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mpr-build-comment[0m and container [32mstep-git-merge[0m
Using SHAs from PULL_REFS=master:3a0767c8ac5907ddb966001d7eca83cd362cffd2,1668:fcb2115957c67642e342a16f0f26ef1b8ec0e851
DEBUG: ran git fetch --unshallow origin fcb2115957c67642e342a16f0f26ef1b8ec0e851: 3a0767c8ac5907ddb966001d7eca83cd362cffd2: in 
DEBUG: ran git checkout master in 
DEBUG: ran git reset --hard 3a0767c8ac5907ddb966001d7eca83cd362cffd2 in 
DEBUG: ran clean --force -d . in 
DEBUG: ran git merge fcb2115957c67642e342a16f0f26ef1b8ec0e851 in 
Merged SHA fcb2115957c67642e342a16f0f26ef1b8ec0e851 with commit message 'fixed explainer typo' into base branch master
Merged SHA 360cbf98d8112463f1d249fe546faa3d1617ceb0 with commit message 'fixed explainer typo' into base branch master
Merged SHA c478c833923714c5a429bacf318c9dd9182a8553 with commit message 'Merge remote-tracking branch 'upstream/master' into 1626_simple_explainer_gateway_fix' into base branch master
Merged SHA ea77210b57b2f6150c2957390bf630a3a283bbb8 with commit message 'Added explainer test' into base branch master
Merged SHA d2123cd80acc26761e6d33f4968298d01f9613fb with commit message 'Updated operator to have aligned requirements on path' into base branch master
Merged SHA a084dcc00f3c941d8792047dfe4c8e936ac8c83e with commit message 'Updated python client to existing changes of explainer' into base branch master
Merged SHA 05ce1234f9ca24c5839b1c57e5a939aff18d664b with commit message 'Updated operator constants' into base branch master

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mpr-build-comment[0m and container [32mstep-step2[0m
+++ dirname ./add-pr-build-comment
++ cd .
++ pwd
+ STARTUP_DIR=/workspace/source/ci
+ REPO_OWNER=SeldonIO
+ REPO_NAME=seldon-core
+ PULL_NUMBER=1668
+ BUILD_NUMBER=12
+ PIPELINE_CONTEXT=integration
++ cat
+++ date
+ COMMENT_MSG='Mon Apr  6 20:03:17 UTC 2020
The logs for [integration] [12] will show after the pipeline context has finished.  
https://github.com/SeldonIO/seldon-core/blob/gh-pages/jenkins-x/logs/SeldonIO/seldon-core/PR-1668/12.log

impatient try  
** get build logs SeldonIO/seldon-core/PR-1668 --build=12'
+ ** step pr comment --owner=SeldonIO --repository=seldon-core --pull-request=1668 '--comment=Mon Apr  6 20:03:17 UTC 2020
The logs for [integration] [12] will show after the pipeline context has finished.  
https://github.com/SeldonIO/seldon-core/blob/gh-pages/jenkins-x/logs/SeldonIO/seldon-core/PR-1668/12.log

impatient try  
** get build logs SeldonIO/seldon-core/PR-1668 --build=12'

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mpr-build-comment[0m and container [32mstep-source-mkdir-seldonio-seldon-core-pr-1668-in-2md7l[0m
{"level":"warn","ts":1586203399.6058557,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1586203399.7546997,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p /pvc/pr-build-comment/workspace\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mpr-build-comment[0m and container [32mstep-source-copy-seldonio-seldon-core-pr-1668-in-hc6zw[0m
{"level":"warn","ts":1586203399.968444,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1586203400.3990145,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c cp -r source/. /pvc/pr-build-comment/workspace\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mend-to-end[0m and container [32mstep-credential-initializer-tz79c[0m
{"level":"warn","ts":1586203445.5377553,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: \"ref: refs/heads/0.8.0-**-support-backwards-incompats\" is not a valid GitHub commit ID"}
{"level":"info","ts":1586203445.5383227,"logger":"fallback-logger","caller":"creds-init/main.go:40","msg":"Credentials initialized."}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mend-to-end[0m and container [32mstep-working-dir-initializer-7vd9c[0m
{"level":"warn","ts":1586203447.319937,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1586203447.323011,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p /workspace/source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mend-to-end[0m and container [32mstep-place-tools[0m

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mend-to-end[0m and container [32mstep-create-dir-workspace-rh8wk[0m
{"level":"warn","ts":1586203462.0153108,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1586203462.017206,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c mkdir -p /workspace/source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mend-to-end[0m and container [32mstep-source-copy-workspace-h72tt[0m
{"level":"warn","ts":1586203462.5527985,"logger":"fallback-logger","caller":"logging/config.go:69","msg":"Fetch GitHub commit ID from kodata failed: open /var/run/ko/HEAD: no such file or directory"}
{"level":"info","ts":1586203466.6309843,"logger":"fallback-logger","caller":"bash/main.go:64","msg":"Successfully executed command \"sh -c cp -r /pvc/pr-build-comment/workspace/. /workspace/source\"; output "}

Showing logs for build [32mseldonio-seldon-core-pr-1668-in-j5w67-12[0m stage [32mend-to-end[0m and container [32mstep-test-end-to-end[0m
Test run type is: [base]
Starting Docker: docker.
[SETUP] Waiting for Docker to be ready, sleeping for 1 seconds ...
kind create cluster --config ../resources/kind_config.yaml
Creating cluster "kind" ...
 ‚Ä¢ Ensuring node image (kindest/node:v1.16.3) üñº  ...
 ‚úì Ensuring node image (kindest/node:v1.16.3) üñº
 ‚Ä¢ Preparing nodes üì¶  ...
 ‚úì Preparing nodes üì¶
 ‚Ä¢ Writing configuration üìú  ...
 ‚úì Writing configuration üìú
 ‚Ä¢ Starting control-plane üïπÔ∏è  ...
 ‚úì Starting control-plane üïπÔ∏è
 ‚Ä¢ Installing CNI üîå  ...
 ‚úì Installing CNI üîå
 ‚Ä¢ Installing StorageClass üíæ  ...
 ‚úì Installing StorageClass üíæ
 ‚Ä¢ Joining worker nodes üöú  ...
 ‚úì Joining worker nodes üöú
Set kubectl context to "kind-kind"
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community üôÇ
`kind get kubeconfig-path` is deprecated!

KIND will export and merge kubeconfig like kops, minikube, etc.
This command is now unnecessary and will be removed in a future release.

For more info see: https://github.com/kubernetes-sigs/kind/issues/1060
See also the output of `kind create cluster`

Files changed in python folder:
python/seldon_core/seldon_client.py
cd ../../wrappers/s2i/python/build_scripts && ./build_all_local.sh
make[1]: Entering directory '/workspace/source/wrappers/s2i/python'
mkdir -p _python
cp -r ../../../python _python
cat Dockerfile.local.tmpl | sed  -e "s|%PYTHON_VERSION%|3.6|" | sed  -e "s|%CONDA_VERSION%|4.7.12|" > Dockerfile
set -x && docker build -t docker.io/seldonio/seldon-core-s2i-python`echo -n 3.6 | sed 's/\.//g'`:1.0.3-SNAPSHOT .
++ sed 's/\.//g'
++ echo -n 3.6
+ docker build -t docker.io/seldonio/seldon-core-s2i-python36:1.0.3-SNAPSHOT .
Sending build context to Docker daemon  954.4kB
Step 1/10 : FROM continuumio/miniconda3:4.7.12
4.7.12: Pulling from continuumio/miniconda3
b8f262c62ec6: Pulling fs layer
0a43c0154f16: Pulling fs layer
906d7b5da8fb: Pulling fs layer
b8f262c62ec6: Verifying Checksum
b8f262c62ec6: Download complete
906d7b5da8fb: Verifying Checksum
906d7b5da8fb: Download complete
0a43c0154f16: Verifying Checksum
0a43c0154f16: Download complete
b8f262c62ec6: Pull complete
0a43c0154f16: Pull complete
906d7b5da8fb: Pull complete
Digest: sha256:6c979670684d970f8ba934bf9b7bf42e77c30a22eb96af1f30a039b484719159
Status: Downloaded newer image for continuumio/miniconda3:4.7.12
 ---> 406f2b43ea59
Step 2/10 : LABEL io.openshift.s2i.scripts-url="image:///s2i/bin"
 ---> Running in e06ef7d72de7
Removing intermediate container e06ef7d72de7
 ---> 16043c3f84d6
Step 3/10 : RUN conda install --yes python=3.6 conda=4.7.12
 ---> Running in bd71621a387e
Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.
Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /opt/conda

  added / updated specs:
    - conda=4.7.12
    - python=3.6


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    asn1crypto-1.3.0           |           py36_0         164 KB
    ca-certificates-2020.1.1   |                0         125 KB
    certifi-2019.11.28         |           py36_1         157 KB
    cffi-1.14.0                |   py36h2e261b9_0         223 KB
    chardet-3.0.4              |        py36_1003         180 KB
    conda-4.7.12               |           py36_0         2.8 MB
    conda-package-handling-1.6.0|   py36h7b6447c_0         795 KB
    cryptography-2.8           |   py36h1ba5d50_0         552 KB
    idna-2.9                   |             py_1          49 KB
    openssl-1.1.1f             |       h7b6447c_0         2.5 MB
    pip-20.0.2                 |           py36_1         1.7 MB
    pycosat-0.6.3              |   py36h7b6447c_0          82 KB
    pycparser-2.20             |             py_0          92 KB
    pyopenssl-19.1.0           |           py36_0          87 KB
    pysocks-1.7.1              |           py36_0          30 KB
    python-3.6.9               |       h265db76_0        30.2 MB
    requests-2.23.0            |           py36_0          91 KB
    ruamel_yaml-0.15.87        |   py36h7b6447c_0         257 KB
    setuptools-46.1.3          |           py36_0         513 KB
    six-1.14.0                 |           py36_0          27 KB
    tqdm-4.36.1                |             py_0          50 KB
    urllib3-1.25.8             |           py36_0         169 KB
    wheel-0.34.2               |           py36_0          51 KB
    ------------------------------------------------------------
                                           Total:        40.8 MB

The following packages will be UPDATED:

  asn1crypto                                   1.0.1-py37_0 --> 1.3.0-py36_0
  ca-certificates                               2019.8.28-0 --> 2020.1.1-0
  certifi                                  2019.9.11-py37_0 --> 2019.11.28-py36_1
  cffi                                1.12.3-py37h2e261b9_0 --> 1.14.0-py36h2e261b9_0
  cryptography                           2.7-py37h1ba5d50_0 --> 2.8-py36h1ba5d50_0
  idna                  pkgs/main/linux-64::idna-2.8-py37_0 --> pkgs/main/noarch::idna-2.9-py_1
  openssl                                 1.1.1d-h7b6447c_2 --> 1.1.1f-h7b6447c_0
  pip                                         19.2.3-py37_0 --> 20.0.2-py36_1
  pycparser          pkgs/main/linux-64::pycparser-2.19-py~ --> pkgs/main/noarch::pycparser-2.20-py_0
  pyopenssl                                   19.0.0-py37_0 --> 19.1.0-py36_0
  requests                                    2.22.0-py37_0 --> 2.23.0-py36_0
  ruamel_yaml                        0.15.46-py37h14c3975_0 --> 0.15.87-py36h7b6447c_0
  setuptools                                  41.4.0-py37_0 --> 46.1.3-py36_0
  six                                         1.12.0-py37_0 --> 1.14.0-py36_0
  urllib3                                     1.24.2-py37_0 --> 1.25.8-py36_0
  wheel                                       0.33.6-py37_0 --> 0.34.2-py36_0

The following packages will be DOWNGRADED:

  chardet                                   3.0.4-py37_1003 --> 3.0.4-py36_1003
  conda                                       4.7.12-py37_0 --> 4.7.12-py36_0
  conda-package-han~                   1.6.0-py37h7b6447c_0 --> 1.6.0-py36h7b6447c_0
  pycosat                              0.6.3-py37h14c3975_0 --> 0.6.3-py36h7b6447c_0
  pysocks                                      1.7.1-py37_0 --> 1.7.1-py36_0
  python                                   3.7.4-h265db76_1 --> 3.6.9-h265db76_0



Downloading and Extracting Packages
pip-20.0.2           | 1.7 MB    |            |   0% pip-20.0.2           | 1.7 MB    | ########## | 100% 
conda-4.7.12         | 2.8 MB    |            |   0% conda-4.7.12         | 2.8 MB    | ########## | 100% 
tqdm-4.36.1          | 50 KB     |            |   0% tqdm-4.36.1          | 50 KB     | ########## | 100% 
wheel-0.34.2         | 51 KB     |            |   0% wheel-0.34.2         | 51 KB     | ########## | 100% 
requests-2.23.0      | 91 KB     |            |   0% requests-2.23.0      | 91 KB     | ########## | 100% 
python-3.6.9         | 30.2 MB   |            |   0% python-3.6.9         | 30.2 MB   | #9         |  20% python-3.6.9         | 30.2 MB   | ####8      |  49% python-3.6.9         | 30.2 MB   | ######7    |  68% python-3.6.9         | 30.2 MB   | ########6  |  87% python-3.6.9         | 30.2 MB   | ########## | 100% 
pysocks-1.7.1        | 30 KB     |            |   0% pysocks-1.7.1        | 30 KB     | ########## | 100% 
pycparser-2.20       | 92 KB     |            |   0% pycparser-2.20       | 92 KB     | ########## | 100% 
ruamel_yaml-0.15.87  | 257 KB    |            |   0% ruamel_yaml-0.15.87  | 257 KB    | ########## | 100% 
asn1crypto-1.3.0     | 164 KB    |            |   0% asn1crypto-1.3.0     | 164 KB    | ########## | 100% 
idna-2.9             | 49 KB     |            |   0% idna-2.9             | 49 KB     | ########## | 100% 
conda-package-handli | 795 KB    |            |   0% conda-package-handli | 795 KB    | ########## | 100% 
pyopenssl-19.1.0     | 87 KB     |            |   0% pyopenssl-19.1.0     | 87 KB     | ########## | 100% 
certifi-2019.11.28   | 157 KB    |            |   0% certifi-2019.11.28   | 157 KB    | ########## | 100% 
ca-certificates-2020 | 125 KB    |            |   0% ca-certificates-2020 | 125 KB    | ########## | 100% 
setuptools-46.1.3    | 513 KB    |            |   0% setuptools-46.1.3    | 513 KB    | ########## | 100% 
pycosat-0.6.3        | 82 KB     |            |   0% pycosat-0.6.3        | 82 KB     | ########## | 100% 
cryptography-2.8     | 552 KB    |            |   0% cryptography-2.8     | 552 KB    | ########## | 100% 
urllib3-1.25.8       | 169 KB    |            |   0% urllib3-1.25.8       | 169 KB    | ########## | 100% 
chardet-3.0.4        | 180 KB    |            |   0% chardet-3.0.4        | 180 KB    | ########## | 100% 
openssl-1.1.1f       | 2.5 MB    |            |   0% openssl-1.1.1f       | 2.5 MB    | ########## | 100% 
cffi-1.14.0          | 223 KB    |            |   0% cffi-1.14.0          | 223 KB    | 7          |   7% cffi-1.14.0          | 223 KB    | ########## | 100% 
six-1.14.0           | 27 KB     |            |   0% six-1.14.0           | 27 KB     | ########## | 100% 
Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
[91m

==> WARNING: A newer version of conda exists. <==
  current version: 4.7.12
  latest version: 4.8.3

Please update conda by running

    $ conda update -n base -c defaults conda


[0mRemoving intermediate container bd71621a387e
 ---> aff30ea1b533
Step 4/10 : RUN apt-get update --yes && apt-get install --yes gcc make build-essential
 ---> Running in 3aad1e4a5506
Get:1 http://deb.debian.org/debian buster InRelease [122 kB]
Get:2 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]
Get:3 http://deb.debian.org/debian buster-updates InRelease [49.3 kB]
Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [187 kB]
Get:5 http://deb.debian.org/debian buster/main amd64 Packages [7907 kB]
Get:6 http://deb.debian.org/debian buster-updates/main amd64 Packages.diff/Index [2212 B]
Get:7 http://deb.debian.org/debian buster-updates/main amd64 Packages 2020-02-23-2017.41.pdiff [2162 B]
Get:7 http://deb.debian.org/debian buster-updates/main amd64 Packages 2020-02-23-2017.41.pdiff [2162 B]
Fetched 8334 kB in 2s (4334 kB/s)
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
The following additional packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-8 dirmngr
  dpkg-dev fakeroot g++ g++-8 gcc-8 gnupg gnupg-l10n gnupg-utils gpg gpg-agent
  gpg-wks-client gpg-wks-server gpgconf gpgsm libalgorithm-diff-perl
  libalgorithm-diff-xs-perl libalgorithm-merge-perl libasan5 libassuan0
  libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0 libdpkg-perl
  libfakeroot libfile-fcntllock-perl libgcc-8-dev libgomp1 libisl19 libitm1
  libksba8 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libmpx2 libnpth0
  libquadmath0 libstdc++-8-dev libtsan0 libubsan1 linux-libc-dev manpages
  manpages-dev pinentry-curses
Suggested packages:
  binutils-doc cpp-doc gcc-8-locales dbus-user-session libpam-systemd
  pinentry-gnome3 tor debian-keyring g++-multilib g++-8-multilib gcc-8-doc
  libstdc++6-8-dbg gcc-multilib autoconf automake libtool flex bison gdb
  gcc-doc gcc-8-multilib libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg
  libasan5-dbg liblsan0-dbg libtsan0-dbg libubsan1-dbg libmpx2-dbg
  libquadmath0-dbg parcimonie xloadimage scdaemon glibc-doc bzr
  libstdc++-8-doc make-doc man-browser pinentry-doc
The following NEW packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu build-essential cpp cpp-8
  dirmngr dpkg-dev fakeroot g++ g++-8 gcc gcc-8 gnupg gnupg-l10n gnupg-utils
  gpg gpg-agent gpg-wks-client gpg-wks-server gpgconf gpgsm
  libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl
  libasan5 libassuan0 libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0
  libdpkg-perl libfakeroot libfile-fcntllock-perl libgcc-8-dev libgomp1
  libisl19 libitm1 libksba8 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6
  libmpx2 libnpth0 libquadmath0 libstdc++-8-dev libtsan0 libubsan1
  linux-libc-dev make manpages manpages-dev pinentry-curses
0 upgraded, 55 newly installed, 0 to remove and 31 not upgraded.
Need to get 57.7 MB of archives.
After this operation, 202 MB of additional disk space will be used.
Get:1 http://deb.debian.org/debian buster/main amd64 liblocale-gettext-perl amd64 1.07-3+b4 [18.9 kB]
Get:2 http://deb.debian.org/debian buster/main amd64 manpages all 4.16-2 [1295 kB]
Get:3 http://deb.debian.org/debian buster/main amd64 binutils-common amd64 2.31.1-16 [2073 kB]
Get:4 http://deb.debian.org/debian buster/main amd64 libbinutils amd64 2.31.1-16 [478 kB]
Get:5 http://deb.debian.org/debian buster/main amd64 binutils-x86-64-linux-gnu amd64 2.31.1-16 [1823 kB]
Get:6 http://deb.debian.org/debian buster/main amd64 binutils amd64 2.31.1-16 [56.8 kB]
Get:7 http://deb.debian.org/debian buster/main amd64 libc-dev-bin amd64 2.28-10 [275 kB]
Get:8 http://deb.debian.org/debian buster/main amd64 linux-libc-dev amd64 4.19.98-1 [1314 kB]
Get:9 http://deb.debian.org/debian buster/main amd64 libc6-dev amd64 2.28-10 [2691 kB]
Get:10 http://deb.debian.org/debian buster/main amd64 libisl19 amd64 0.20-2 [587 kB]
Get:11 http://deb.debian.org/debian buster/main amd64 libmpfr6 amd64 4.0.2-1 [775 kB]
Get:12 http://deb.debian.org/debian buster/main amd64 libmpc3 amd64 1.1.0-1 [41.3 kB]
Get:13 http://deb.debian.org/debian buster/main amd64 cpp-8 amd64 8.3.0-6 [8914 kB]
Get:14 http://deb.debian.org/debian buster/main amd64 cpp amd64 4:8.3.0-1 [19.4 kB]
Get:15 http://deb.debian.org/debian buster/main amd64 libcc1-0 amd64 8.3.0-6 [46.6 kB]
Get:16 http://deb.debian.org/debian buster/main amd64 libgomp1 amd64 8.3.0-6 [75.8 kB]
Get:17 http://deb.debian.org/debian buster/main amd64 libitm1 amd64 8.3.0-6 [27.7 kB]
Get:18 http://deb.debian.org/debian buster/main amd64 libatomic1 amd64 8.3.0-6 [9032 B]
Get:19 http://deb.debian.org/debian buster/main amd64 libasan5 amd64 8.3.0-6 [362 kB]
Get:20 http://deb.debian.org/debian buster/main amd64 liblsan0 amd64 8.3.0-6 [131 kB]
Get:21 http://deb.debian.org/debian buster/main amd64 libtsan0 amd64 8.3.0-6 [283 kB]
Get:22 http://deb.debian.org/debian buster/main amd64 libubsan1 amd64 8.3.0-6 [120 kB]
Get:23 http://deb.debian.org/debian buster/main amd64 libmpx2 amd64 8.3.0-6 [11.4 kB]
Get:24 http://deb.debian.org/debian buster/main amd64 libquadmath0 amd64 8.3.0-6 [133 kB]
Get:25 http://deb.debian.org/debian buster/main amd64 libgcc-8-dev amd64 8.3.0-6 [2298 kB]
Get:26 http://deb.debian.org/debian buster/main amd64 gcc-8 amd64 8.3.0-6 [9452 kB]
Get:27 http://deb.debian.org/debian buster/main amd64 gcc amd64 4:8.3.0-1 [5196 B]
Get:28 http://deb.debian.org/debian buster/main amd64 libstdc++-8-dev amd64 8.3.0-6 [1532 kB]
Get:29 http://deb.debian.org/debian buster/main amd64 g++-8 amd64 8.3.0-6 [9752 kB]
Get:30 http://deb.debian.org/debian buster/main amd64 g++ amd64 4:8.3.0-1 [1644 B]
Get:31 http://deb.debian.org/debian buster/main amd64 make amd64 4.2.1-1.2 [341 kB]
Get:32 http://deb.debian.org/debian buster/main amd64 libdpkg-perl all 1.19.7 [1414 kB]
Get:33 http://deb.debian.org/debian buster/main amd64 dpkg-dev all 1.19.7 [1773 kB]
Get:34 http://deb.debian.org/debian buster/main amd64 build-essential amd64 12.6 [7576 B]
Get:35 http://deb.debian.org/debian buster/main amd64 libassuan0 amd64 2.5.2-1 [49.4 kB]
Get:36 http://deb.debian.org/debian buster/main amd64 gpgconf amd64 2.2.12-1+deb10u1 [510 kB]
Get:37 http://deb.debian.org/debian buster/main amd64 libksba8 amd64 1.3.5-2 [99.7 kB]
Get:38 http://deb.debian.org/debian buster/main amd64 libnpth0 amd64 1.6-1 [18.4 kB]
Get:39 http://deb.debian.org/debian buster/main amd64 dirmngr amd64 2.2.12-1+deb10u1 [712 kB]
Get:40 http://deb.debian.org/debian buster/main amd64 libfakeroot amd64 1.23-1 [45.9 kB]
Get:41 http://deb.debian.org/debian buster/main amd64 fakeroot amd64 1.23-1 [85.8 kB]
Get:42 http://deb.debian.org/debian buster/main amd64 gnupg-l10n all 2.2.12-1+deb10u1 [1010 kB]
Get:43 http://deb.debian.org/debian buster/main amd64 gnupg-utils amd64 2.2.12-1+deb10u1 [861 kB]
Get:44 http://deb.debian.org/debian buster/main amd64 gpg amd64 2.2.12-1+deb10u1 [865 kB]
Get:45 http://deb.debian.org/debian buster/main amd64 pinentry-curses amd64 1.1.0-2 [64.5 kB]
Get:46 http://deb.debian.org/debian buster/main amd64 gpg-agent amd64 2.2.12-1+deb10u1 [617 kB]
Get:47 http://deb.debian.org/debian buster/main amd64 gpg-wks-client amd64 2.2.12-1+deb10u1 [485 kB]
Get:48 http://deb.debian.org/debian buster/main amd64 gpg-wks-server amd64 2.2.12-1+deb10u1 [478 kB]
Get:49 http://deb.debian.org/debian buster/main amd64 gpgsm amd64 2.2.12-1+deb10u1 [604 kB]
Get:50 http://deb.debian.org/debian buster/main amd64 gnupg all 2.2.12-1+deb10u1 [715 kB]
Get:51 http://deb.debian.org/debian buster/main amd64 libalgorithm-diff-perl all 1.19.03-2 [47.9 kB]
Get:52 http://deb.debian.org/debian buster/main amd64 libalgorithm-diff-xs-perl amd64 0.04-5+b1 [11.8 kB]
Get:53 http://deb.debian.org/debian buster/main amd64 libalgorithm-merge-perl all 0.08-3 [12.7 kB]
Get:54 http://deb.debian.org/debian buster/main amd64 libfile-fcntllock-perl amd64 0.22-3+b5 [35.4 kB]
Get:55 http://deb.debian.org/debian buster/main amd64 manpages-dev all 4.16-2 [2232 kB]
[91mdebconf: delaying package configuration, since apt-utils is not installed
[0mFetched 57.7 MB in 1s (74.2 MB/s)
Selecting previously unselected package liblocale-gettext-perl.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 12557 files and directories currently installed.)
Preparing to unpack .../00-liblocale-gettext-perl_1.07-3+b4_amd64.deb ...
Unpacking liblocale-gettext-perl (1.07-3+b4) ...
Selecting previously unselected package manpages.
Preparing to unpack .../01-manpages_4.16-2_all.deb ...
Unpacking manpages (4.16-2) ...
Selecting previously unselected package binutils-common:amd64.
Preparing to unpack .../02-binutils-common_2.31.1-16_amd64.deb ...
Unpacking binutils-common:amd64 (2.31.1-16) ...
Selecting previously unselected package libbinutils:amd64.
Preparing to unpack .../03-libbinutils_2.31.1-16_amd64.deb ...
Unpacking libbinutils:amd64 (2.31.1-16) ...
Selecting previously unselected package binutils-x86-64-linux-gnu.
Preparing to unpack .../04-binutils-x86-64-linux-gnu_2.31.1-16_amd64.deb ...
Unpacking binutils-x86-64-linux-gnu (2.31.1-16) ...
Selecting previously unselected package binutils.
Preparing to unpack .../05-binutils_2.31.1-16_amd64.deb ...
Unpacking binutils (2.31.1-16) ...
Selecting previously unselected package libc-dev-bin.
Preparing to unpack .../06-libc-dev-bin_2.28-10_amd64.deb ...
Unpacking libc-dev-bin (2.28-10) ...
Selecting previously unselected package linux-libc-dev:amd64.
Preparing to unpack .../07-linux-libc-dev_4.19.98-1_amd64.deb ...
Unpacking linux-libc-dev:amd64 (4.19.98-1) ...
Selecting previously unselected package libc6-dev:amd64.
Preparing to unpack .../08-libc6-dev_2.28-10_amd64.deb ...
Unpacking libc6-dev:amd64 (2.28-10) ...
Selecting previously unselected package libisl19:amd64.
Preparing to unpack .../09-libisl19_0.20-2_amd64.deb ...
Unpacking libisl19:amd64 (0.20-2) ...
Selecting previously unselected package libmpfr6:amd64.
Preparing to unpack .../10-libmpfr6_4.0.2-1_amd64.deb ...
Unpacking libmpfr6:amd64 (4.0.2-1) ...
Selecting previously unselected package libmpc3:amd64.
Preparing to unpack .../11-libmpc3_1.1.0-1_amd64.deb ...
Unpacking libmpc3:amd64 (1.1.0-1) ...
Selecting previously unselected package cpp-8.
Preparing to unpack .../12-cpp-8_8.3.0-6_amd64.deb ...
Unpacking cpp-8 (8.3.0-6) ...
Selecting previously unselected package cpp.
Preparing to unpack .../13-cpp_4%3a8.3.0-1_amd64.deb ...
Unpacking cpp (4:8.3.0-1) ...
Selecting previously unselected package libcc1-0:amd64.
Preparing to unpack .../14-libcc1-0_8.3.0-6_amd64.deb ...
Unpacking libcc1-0:amd64 (8.3.0-6) ...
Selecting previously unselected package libgomp1:amd64.
Preparing to unpack .../15-libgomp1_8.3.0-6_amd64.deb ...
Unpacking libgomp1:amd64 (8.3.0-6) ...
Selecting previously unselected package libitm1:amd64.
Preparing to unpack .../16-libitm1_8.3.0-6_amd64.deb ...
Unpacking libitm1:amd64 (8.3.0-6) ...
Selecting previously unselected package libatomic1:amd64.
Preparing to unpack .../17-libatomic1_8.3.0-6_amd64.deb ...
Unpacking libatomic1:amd64 (8.3.0-6) ...
Selecting previously unselected package libasan5:amd64.
Preparing to unpack .../18-libasan5_8.3.0-6_amd64.deb ...
Unpacking libasan5:amd64 (8.3.0-6) ...
Selecting previously unselected package liblsan0:amd64.
Preparing to unpack .../19-liblsan0_8.3.0-6_amd64.deb ...
Unpacking liblsan0:amd64 (8.3.0-6) ...
Selecting previously unselected package libtsan0:amd64.
Preparing to unpack .../20-libtsan0_8.3.0-6_amd64.deb ...
Unpacking libtsan0:amd64 (8.3.0-6) ...
Selecting previously unselected package libubsan1:amd64.
Preparing to unpack .../21-libubsan1_8.3.0-6_amd64.deb ...
Unpacking libubsan1:amd64 (8.3.0-6) ...
Selecting previously unselected package libmpx2:amd64.
Preparing to unpack .../22-libmpx2_8.3.0-6_amd64.deb ...
Unpacking libmpx2:amd64 (8.3.0-6) ...
Selecting previously unselected package libquadmath0:amd64.
Preparing to unpack .../23-libquadmath0_8.3.0-6_amd64.deb ...
Unpacking libquadmath0:amd64 (8.3.0-6) ...
Selecting previously unselected package libgcc-8-dev:amd64.
Preparing to unpack .../24-libgcc-8-dev_8.3.0-6_amd64.deb ...
Unpacking libgcc-8-dev:amd64 (8.3.0-6) ...
Selecting previously unselected package gcc-8.
Preparing to unpack .../25-gcc-8_8.3.0-6_amd64.deb ...
Unpacking gcc-8 (8.3.0-6) ...
Selecting previously unselected package gcc.
Preparing to unpack .../26-gcc_4%3a8.3.0-1_amd64.deb ...
Unpacking gcc (4:8.3.0-1) ...
Selecting previously unselected package libstdc++-8-dev:amd64.
Preparing to unpack .../27-libstdc++-8-dev_8.3.0-6_amd64.deb ...
Unpacking libstdc++-8-dev:amd64 (8.3.0-6) ...
Selecting previously unselected package g++-8.
Preparing to unpack .../28-g++-8_8.3.0-6_amd64.deb ...
Unpacking g++-8 (8.3.0-6) ...
Selecting previously unselected package g++.
Preparing to unpack .../29-g++_4%3a8.3.0-1_amd64.deb ...
Unpacking g++ (4:8.3.0-1) ...
Selecting previously unselected package make.
Preparing to unpack .../30-make_4.2.1-1.2_amd64.deb ...
Unpacking make (4.2.1-1.2) ...
Selecting previously unselected package libdpkg-perl.
Preparing to unpack .../31-libdpkg-perl_1.19.7_all.deb ...
Unpacking libdpkg-perl (1.19.7) ...
Selecting previously unselected package dpkg-dev.
Preparing to unpack .../32-dpkg-dev_1.19.7_all.deb ...
Unpacking dpkg-dev (1.19.7) ...
Selecting previously unselected package build-essential.
Preparing to unpack .../33-build-essential_12.6_amd64.deb ...
Unpacking build-essential (12.6) ...
Selecting previously unselected package libassuan0:amd64.
Preparing to unpack .../34-libassuan0_2.5.2-1_amd64.deb ...
Unpacking libassuan0:amd64 (2.5.2-1) ...
Selecting previously unselected package gpgconf.
Preparing to unpack .../35-gpgconf_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpgconf (2.2.12-1+deb10u1) ...
Selecting previously unselected package libksba8:amd64.
Preparing to unpack .../36-libksba8_1.3.5-2_amd64.deb ...
Unpacking libksba8:amd64 (1.3.5-2) ...
Selecting previously unselected package libnpth0:amd64.
Preparing to unpack .../37-libnpth0_1.6-1_amd64.deb ...
Unpacking libnpth0:amd64 (1.6-1) ...
Selecting previously unselected package dirmngr.
Preparing to unpack .../38-dirmngr_2.2.12-1+deb10u1_amd64.deb ...
Unpacking dirmngr (2.2.12-1+deb10u1) ...
Selecting previously unselected package libfakeroot:amd64.
Preparing to unpack .../39-libfakeroot_1.23-1_amd64.deb ...
Unpacking libfakeroot:amd64 (1.23-1) ...
Selecting previously unselected package fakeroot.
Preparing to unpack .../40-fakeroot_1.23-1_amd64.deb ...
Unpacking fakeroot (1.23-1) ...
Selecting previously unselected package gnupg-l10n.
Preparing to unpack .../41-gnupg-l10n_2.2.12-1+deb10u1_all.deb ...
Unpacking gnupg-l10n (2.2.12-1+deb10u1) ...
Selecting previously unselected package gnupg-utils.
Preparing to unpack .../42-gnupg-utils_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gnupg-utils (2.2.12-1+deb10u1) ...
Selecting previously unselected package gpg.
Preparing to unpack .../43-gpg_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpg (2.2.12-1+deb10u1) ...
Selecting previously unselected package pinentry-curses.
Preparing to unpack .../44-pinentry-curses_1.1.0-2_amd64.deb ...
Unpacking pinentry-curses (1.1.0-2) ...
Selecting previously unselected package gpg-agent.
Preparing to unpack .../45-gpg-agent_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpg-agent (2.2.12-1+deb10u1) ...
Selecting previously unselected package gpg-wks-client.
Preparing to unpack .../46-gpg-wks-client_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpg-wks-client (2.2.12-1+deb10u1) ...
Selecting previously unselected package gpg-wks-server.
Preparing to unpack .../47-gpg-wks-server_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpg-wks-server (2.2.12-1+deb10u1) ...
Selecting previously unselected package gpgsm.
Preparing to unpack .../48-gpgsm_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpgsm (2.2.12-1+deb10u1) ...
Selecting previously unselected package gnupg.
Preparing to unpack .../49-gnupg_2.2.12-1+deb10u1_all.deb ...
Unpacking gnupg (2.2.12-1+deb10u1) ...
Selecting previously unselected package libalgorithm-diff-perl.
Preparing to unpack .../50-libalgorithm-diff-perl_1.19.03-2_all.deb ...
Unpacking libalgorithm-diff-perl (1.19.03-2) ...
Selecting previously unselected package libalgorithm-diff-xs-perl.
Preparing to unpack .../51-libalgorithm-diff-xs-perl_0.04-5+b1_amd64.deb ...
Unpacking libalgorithm-diff-xs-perl (0.04-5+b1) ...
Selecting previously unselected package libalgorithm-merge-perl.
Preparing to unpack .../52-libalgorithm-merge-perl_0.08-3_all.deb ...
Unpacking libalgorithm-merge-perl (0.08-3) ...
Selecting previously unselected package libfile-fcntllock-perl.
Preparing to unpack .../53-libfile-fcntllock-perl_0.22-3+b5_amd64.deb ...
Unpacking libfile-fcntllock-perl (0.22-3+b5) ...
Selecting previously unselected package manpages-dev.
Preparing to unpack .../54-manpages-dev_4.16-2_all.deb ...
Unpacking manpages-dev (4.16-2) ...
Setting up libksba8:amd64 (1.3.5-2) ...
Setting up libfile-fcntllock-perl (0.22-3+b5) ...
Setting up libalgorithm-diff-perl (1.19.03-2) ...
Setting up manpages (4.16-2) ...
Setting up binutils-common:amd64 (2.31.1-16) ...
Setting up linux-libc-dev:amd64 (4.19.98-1) ...
Setting up libnpth0:amd64 (1.6-1) ...
Setting up libassuan0:amd64 (2.5.2-1) ...
Setting up libgomp1:amd64 (8.3.0-6) ...
Setting up libfakeroot:amd64 (1.23-1) ...
Setting up fakeroot (1.23-1) ...
update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode
update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
Setting up libasan5:amd64 (8.3.0-6) ...
Setting up make (4.2.1-1.2) ...
Setting up libmpfr6:amd64 (4.0.2-1) ...
Setting up gnupg-l10n (2.2.12-1+deb10u1) ...
Setting up libquadmath0:amd64 (8.3.0-6) ...
Setting up libmpc3:amd64 (1.1.0-1) ...
Setting up libatomic1:amd64 (8.3.0-6) ...
Setting up libdpkg-perl (1.19.7) ...
Setting up libmpx2:amd64 (8.3.0-6) ...
Setting up libubsan1:amd64 (8.3.0-6) ...
Setting up libisl19:amd64 (0.20-2) ...
Setting up gpgconf (2.2.12-1+deb10u1) ...
Setting up libbinutils:amd64 (2.31.1-16) ...
Setting up cpp-8 (8.3.0-6) ...
Setting up libc-dev-bin (2.28-10) ...
Setting up libalgorithm-diff-xs-perl (0.04-5+b1) ...
Setting up libcc1-0:amd64 (8.3.0-6) ...
Setting up liblocale-gettext-perl (1.07-3+b4) ...
Setting up gpg (2.2.12-1+deb10u1) ...
Setting up liblsan0:amd64 (8.3.0-6) ...
Setting up libitm1:amd64 (8.3.0-6) ...
Setting up libalgorithm-merge-perl (0.08-3) ...
Setting up gnupg-utils (2.2.12-1+deb10u1) ...
Setting up binutils-x86-64-linux-gnu (2.31.1-16) ...
Setting up libtsan0:amd64 (8.3.0-6) ...
Setting up pinentry-curses (1.1.0-2) ...
Setting up manpages-dev (4.16-2) ...
Setting up gpg-agent (2.2.12-1+deb10u1) ...
Setting up gpgsm (2.2.12-1+deb10u1) ...
Setting up binutils (2.31.1-16) ...
Setting up dpkg-dev (1.19.7) ...
Setting up dirmngr (2.2.12-1+deb10u1) ...
Setting up libgcc-8-dev:amd64 (8.3.0-6) ...
Setting up gpg-wks-server (2.2.12-1+deb10u1) ...
Setting up cpp (4:8.3.0-1) ...
Setting up libc6-dev:amd64 (2.28-10) ...
Setting up libstdc++-8-dev:amd64 (8.3.0-6) ...
Setting up gcc-8 (8.3.0-6) ...
Setting up gpg-wks-client (2.2.12-1+deb10u1) ...
Setting up gcc (4:8.3.0-1) ...
Setting up g++-8 (8.3.0-6) ...
Setting up gnupg (2.2.12-1+deb10u1) ...
Setting up g++ (4:8.3.0-1) ...
update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode
Setting up build-essential (12.6) ...
Processing triggers for libc-bin (2.28-10) ...
Removing intermediate container 3aad1e4a5506
 ---> 8fb1b714eb6c
Step 5/10 : RUN mkdir microservice
 ---> Running in 571d133f6f3e
Removing intermediate container 571d133f6f3e
 ---> 83109d46f0e4
Step 6/10 : WORKDIR /microservice
 ---> Running in 36830f88396f
Removing intermediate container 36830f88396f
 ---> e37e7753f2e5
Step 7/10 : COPY ./s2i/bin/ /s2i/bin
 ---> aacb7d11fa73
Step 8/10 : COPY _python /microservice
 ---> d4b3f01f8b50
Step 9/10 : RUN cd /microservice/python && make install
 ---> Running in 04de24983a49
[91mcat: ../version.txt: No such file or directory
[0mpip install -e .
Obtaining file:///microservice/python
Collecting Flask<2.0.0
  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)
Collecting Flask-cors<4.0.0
  Downloading Flask_Cors-3.0.8-py2.py3-none-any.whl (14 kB)
Collecting redis<4.0.0
  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)
Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.6/site-packages (from seldon-core==1.0.2) (2.23.0)
Collecting numpy<2.0.0
  Downloading numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)
Collecting flatbuffers<2.0.0
  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)
Collecting protobuf<4.0.0
  Downloading protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)
Collecting grpcio<2.0.0
  Downloading grpcio-1.28.1-cp36-cp36m-manylinux2010_x86_64.whl (2.8 MB)
Collecting Flask-OpenTracing<1.2.0,>=1.1.0
  Downloading Flask-OpenTracing-1.1.0.tar.gz (8.2 kB)
Collecting opentracing<2.3.0,>=2.2.0
  Downloading opentracing-2.2.0.tar.gz (47 kB)
Collecting jaeger-client<4.2.0,>=4.1.0
  Downloading jaeger-client-4.1.0.tar.gz (80 kB)
Collecting grpcio-opentracing<1.2.0,>=1.1.4
  Downloading grpcio_opentracing-1.1.4-py3-none-any.whl (14 kB)
Collecting pyaml<20.0.0
  Downloading pyaml-19.12.0-py2.py3-none-any.whl (17 kB)
Collecting gunicorn<20.1.0,>=19.9.0
  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)
Collecting minio<6.0.0,>=4.0.9
  Downloading minio-5.0.8-py2.py3-none-any.whl (73 kB)
Collecting azure-storage-blob<3.0.0,>=2.0.1
  Downloading azure_storage_blob-2.1.0-py2.py3-none-any.whl (88 kB)
Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from seldon-core==1.0.2) (46.1.3.post20200330)
Collecting prometheus_client<0.8.0,>=0.7.1
  Downloading prometheus_client-0.7.1.tar.gz (38 kB)
Collecting Jinja2>=2.10.1
  Downloading Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)
Collecting itsdangerous>=0.24
  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting click>=5.1
  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)
Collecting Werkzeug>=0.15
  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)
Requirement already satisfied: Six in /opt/conda/lib/python3.6/site-packages (from Flask-cors<4.0.0->seldon-core==1.0.2) (1.14.0)
Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0->seldon-core==1.0.2) (2019.11.28)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0->seldon-core==1.0.2) (1.25.8)
Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0->seldon-core==1.0.2) (2.9)
Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0->seldon-core==1.0.2) (3.0.4)
Collecting threadloop<2,>=1
  Downloading threadloop-1.0.2.tar.gz (4.9 kB)
Collecting thrift
  Downloading thrift-0.13.0.tar.gz (59 kB)
Collecting tornado<6,>=4.3
  Downloading tornado-5.1.1.tar.gz (516 kB)
Collecting PyYAML
  Downloading PyYAML-5.3.1.tar.gz (269 kB)
Collecting pytz
  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)
Collecting configparser
  Downloading configparser-5.0.0-py3-none-any.whl (22 kB)
Collecting python-dateutil
  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)
Collecting azure-common>=1.1.5
  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)
Collecting azure-storage-common~=2.1
  Downloading azure_storage_common-2.1.0-py2.py3-none-any.whl (47 kB)
Collecting MarkupSafe>=0.23
  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)
Requirement already satisfied: cryptography in /opt/conda/lib/python3.6/site-packages (from azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (2.8)
Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.6/site-packages (from cryptography->azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (1.14.0)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (2.20)
Building wheels for collected packages: Flask-OpenTracing, opentracing, jaeger-client, prometheus-client, threadloop, thrift, tornado, PyYAML
  Building wheel for Flask-OpenTracing (setup.py): started
  Building wheel for Flask-OpenTracing (setup.py): finished with status 'done'
  Created wheel for Flask-OpenTracing: filename=Flask_OpenTracing-1.1.0-py3-none-any.whl size=9070 sha256=92be310c12810dde227146d4f2980ed6cebcf32b7c912c301eaccd364f046ff0
  Stored in directory: /root/.cache/pip/wheels/ad/4b/2d/24ff0da0a0b53c7c77ce59b843bcceaf644c88703241e59615
  Building wheel for opentracing (setup.py): started
  Building wheel for opentracing (setup.py): finished with status 'done'
  Created wheel for opentracing: filename=opentracing-2.2.0-py3-none-any.whl size=49319 sha256=744122a51d8516b29109c686077548f6a8734e9c3406da521942ce897ce03884
  Stored in directory: /root/.cache/pip/wheels/39/40/44/8bace79f4514e99786236c31f1df8d1b814ff02c1e08b1d697
  Building wheel for jaeger-client (setup.py): started
  Building wheel for jaeger-client (setup.py): finished with status 'done'
  Created wheel for jaeger-client: filename=jaeger_client-4.1.0-py3-none-any.whl size=64309 sha256=e210df9fac2cf3922fe1c1adb2128aadd5d391799c01544f3647284eddbd0593
  Stored in directory: /root/.cache/pip/wheels/e9/9b/8c/503d0cc13b39a551c054515683ba1d15b40324c863dc442e66
  Building wheel for prometheus-client (setup.py): started
  Building wheel for prometheus-client (setup.py): finished with status 'done'
  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41404 sha256=c715996cfcced94b893548cd5f6a4e3fac3ac2e70e2bde983d805af358d93f7d
  Stored in directory: /root/.cache/pip/wheels/1d/4a/79/a3ad3f74b3495b4555359375ca33ad7b64e77f8b7a53c8894f
  Building wheel for threadloop (setup.py): started
  Building wheel for threadloop (setup.py): finished with status 'done'
  Created wheel for threadloop: filename=threadloop-1.0.2-py3-none-any.whl size=3423 sha256=fe5849587ccb700c47a8d9896e22e506e51afecd4002f62e9e42c770f378cbce
  Stored in directory: /root/.cache/pip/wheels/02/54/65/9f87de48fe8fcaaee30f279973d946ad55f9df56b93b3e78da
  Building wheel for thrift (setup.py): started
  Building wheel for thrift (setup.py): finished with status 'done'
  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=483899 sha256=7f1835c97f024fc497296a11bc73a374f093a2ae3def5a96156124eaf5ee13fd
  Stored in directory: /root/.cache/pip/wheels/e0/38/fc/472fe18756b177b42096961f8bd3ff2dc5c5620ac399fce52d
  Building wheel for tornado (setup.py): started
  Building wheel for tornado (setup.py): finished with status 'done'
  Created wheel for tornado: filename=tornado-5.1.1-cp36-cp36m-linux_x86_64.whl size=462664 sha256=2704f8e02aa46a596a0b48f3f1636a875ad63fc76ffb51e4172b71d4ae0dd6ba
  Stored in directory: /root/.cache/pip/wheels/64/74/71/e7a0d0eb4fc42cb20a17aec36f8f0b5b8c5e1ec19c701fd34a
  Building wheel for PyYAML (setup.py): started
  Building wheel for PyYAML (setup.py): finished with status 'done'
  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=a453861929292704d675c80823a0fcfe9e8909c04cd1c45af85b9d4224645f41
  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc
Successfully built Flask-OpenTracing opentracing jaeger-client prometheus-client threadloop thrift tornado PyYAML
Installing collected packages: MarkupSafe, Jinja2, itsdangerous, click, Werkzeug, Flask, Flask-cors, redis, numpy, flatbuffers, protobuf, grpcio, opentracing, Flask-OpenTracing, tornado, threadloop, thrift, jaeger-client, grpcio-opentracing, PyYAML, pyaml, gunicorn, pytz, configparser, python-dateutil, minio, azure-common, azure-storage-common, azure-storage-blob, prometheus-client, seldon-core
  Running setup.py develop for seldon-core
Successfully installed Flask-1.1.2 Flask-OpenTracing-1.1.0 Flask-cors-3.0.8 Jinja2-2.11.1 MarkupSafe-1.1.1 PyYAML-5.3.1 Werkzeug-1.0.1 azure-common-1.1.25 azure-storage-blob-2.1.0 azure-storage-common-2.1.0 click-7.1.1 configparser-5.0.0 flatbuffers-1.12 grpcio-1.28.1 grpcio-opentracing-1.1.4 gunicorn-20.0.4 itsdangerous-1.1.0 jaeger-client-4.1.0 minio-5.0.8 numpy-1.18.2 opentracing-2.2.0 prometheus-client-0.7.1 protobuf-3.11.3 pyaml-19.12.0 python-dateutil-2.8.1 pytz-2019.3 redis-3.4.1 seldon-core threadloop-1.0.2 thrift-0.13.0 tornado-5.1.1
Removing intermediate container 04de24983a49
 ---> 4a54acfd47ef
Step 10/10 : EXPOSE 5000
 ---> Running in b618b3875d10
Removing intermediate container b618b3875d10
 ---> d31404f241fb
Successfully built d31404f241fb
Successfully tagged seldonio/seldon-core-s2i-python36:1.0.3-SNAPSHOT
make[1]: Leaving directory '/workspace/source/wrappers/s2i/python'
make[1]: Entering directory '/workspace/source/wrappers/s2i/python'
mkdir -p _python
cp -r ../../../python _python
cat Dockerfile.local.tmpl | sed  -e "s|%PYTHON_VERSION%|3.7|" | sed  -e "s|%CONDA_VERSION%|4.7.12|" > Dockerfile
set -x && docker build -t docker.io/seldonio/seldon-core-s2i-python`echo -n 3.7 | sed 's/\.//g'`:1.0.3-SNAPSHOT .
++ sed 's/\.//g'
++ echo -n 3.7
+ docker build -t docker.io/seldonio/seldon-core-s2i-python37:1.0.3-SNAPSHOT .
Sending build context to Docker daemon  954.4kB
Step 1/10 : FROM continuumio/miniconda3:4.7.12
 ---> 406f2b43ea59
Step 2/10 : LABEL io.openshift.s2i.scripts-url="image:///s2i/bin"
 ---> Using cache
 ---> 16043c3f84d6
Step 3/10 : RUN conda install --yes python=3.7 conda=4.7.12
 ---> Running in 91b5fb7e872c
Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /opt/conda

  added / updated specs:
    - conda=4.7.12
    - python=3.7


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    ca-certificates-2020.1.1   |                0         125 KB
    certifi-2019.11.28         |           py37_1         156 KB
    openssl-1.1.1f             |       h7b6447c_0         2.5 MB
    ------------------------------------------------------------
                                           Total:         2.8 MB

The following packages will be UPDATED:

  ca-certificates                               2019.8.28-0 --> 2020.1.1-0
  certifi                                  2019.9.11-py37_0 --> 2019.11.28-py37_1
  openssl                                 1.1.1d-h7b6447c_2 --> 1.1.1f-h7b6447c_0



Downloading and Extracting Packages
openssl-1.1.1f       | 2.5 MB    |            |   0% openssl-1.1.1f       | 2.5 MB    | ###9       |  40% openssl-1.1.1f       | 2.5 MB    | ########## | 100% 
certifi-2019.11.28   | 156 KB    |            |   0% certifi-2019.11.28   | 156 KB    | ########## | 100% 
ca-certificates-2020 | 125 KB    |            |   0% ca-certificates-2020 | 125 KB    | ########## | 100% 
Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
[91m

==> WARNING: A newer version of conda exists. <==
  current version: 4.7.12
  latest version: 4.8.3

Please update conda by running

    $ conda update -n base -c defaults conda


[0mRemoving intermediate container 91b5fb7e872c
 ---> 25b88c0f2551
Step 4/10 : RUN apt-get update --yes && apt-get install --yes gcc make build-essential
 ---> Running in 6f1e9b9cdd85
Get:1 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]
Get:2 http://deb.debian.org/debian buster InRelease [122 kB]
Get:3 http://deb.debian.org/debian buster-updates InRelease [49.3 kB]
Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [187 kB]
Get:5 http://deb.debian.org/debian buster/main amd64 Packages [7907 kB]
Get:6 http://deb.debian.org/debian buster-updates/main amd64 Packages.diff/Index [2212 B]
Get:7 http://deb.debian.org/debian buster-updates/main amd64 Packages 2020-02-23-2017.41.pdiff [2162 B]
Get:7 http://deb.debian.org/debian buster-updates/main amd64 Packages 2020-02-23-2017.41.pdiff [2162 B]
Fetched 8334 kB in 2s (4173 kB/s)
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
The following additional packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-8 dirmngr
  dpkg-dev fakeroot g++ g++-8 gcc-8 gnupg gnupg-l10n gnupg-utils gpg gpg-agent
  gpg-wks-client gpg-wks-server gpgconf gpgsm libalgorithm-diff-perl
  libalgorithm-diff-xs-perl libalgorithm-merge-perl libasan5 libassuan0
  libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0 libdpkg-perl
  libfakeroot libfile-fcntllock-perl libgcc-8-dev libgomp1 libisl19 libitm1
  libksba8 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libmpx2 libnpth0
  libquadmath0 libstdc++-8-dev libtsan0 libubsan1 linux-libc-dev manpages
  manpages-dev pinentry-curses
Suggested packages:
  binutils-doc cpp-doc gcc-8-locales dbus-user-session libpam-systemd
  pinentry-gnome3 tor debian-keyring g++-multilib g++-8-multilib gcc-8-doc
  libstdc++6-8-dbg gcc-multilib autoconf automake libtool flex bison gdb
  gcc-doc gcc-8-multilib libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg
  libasan5-dbg liblsan0-dbg libtsan0-dbg libubsan1-dbg libmpx2-dbg
  libquadmath0-dbg parcimonie xloadimage scdaemon glibc-doc bzr
  libstdc++-8-doc make-doc man-browser pinentry-doc
The following NEW packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu build-essential cpp cpp-8
  dirmngr dpkg-dev fakeroot g++ g++-8 gcc gcc-8 gnupg gnupg-l10n gnupg-utils
  gpg gpg-agent gpg-wks-client gpg-wks-server gpgconf gpgsm
  libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl
  libasan5 libassuan0 libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0
  libdpkg-perl libfakeroot libfile-fcntllock-perl libgcc-8-dev libgomp1
  libisl19 libitm1 libksba8 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6
  libmpx2 libnpth0 libquadmath0 libstdc++-8-dev libtsan0 libubsan1
  linux-libc-dev make manpages manpages-dev pinentry-curses
0 upgraded, 55 newly installed, 0 to remove and 31 not upgraded.
Need to get 57.7 MB of archives.
After this operation, 202 MB of additional disk space will be used.
Get:1 http://deb.debian.org/debian buster/main amd64 liblocale-gettext-perl amd64 1.07-3+b4 [18.9 kB]
Get:2 http://deb.debian.org/debian buster/main amd64 manpages all 4.16-2 [1295 kB]
Get:3 http://deb.debian.org/debian buster/main amd64 binutils-common amd64 2.31.1-16 [2073 kB]
Get:4 http://deb.debian.org/debian buster/main amd64 libbinutils amd64 2.31.1-16 [478 kB]
Get:5 http://deb.debian.org/debian buster/main amd64 binutils-x86-64-linux-gnu amd64 2.31.1-16 [1823 kB]
Get:6 http://deb.debian.org/debian buster/main amd64 binutils amd64 2.31.1-16 [56.8 kB]
Get:7 http://deb.debian.org/debian buster/main amd64 libc-dev-bin amd64 2.28-10 [275 kB]
Get:8 http://deb.debian.org/debian buster/main amd64 linux-libc-dev amd64 4.19.98-1 [1314 kB]
Get:9 http://deb.debian.org/debian buster/main amd64 libc6-dev amd64 2.28-10 [2691 kB]
Get:10 http://deb.debian.org/debian buster/main amd64 libisl19 amd64 0.20-2 [587 kB]
Get:11 http://deb.debian.org/debian buster/main amd64 libmpfr6 amd64 4.0.2-1 [775 kB]
Get:12 http://deb.debian.org/debian buster/main amd64 libmpc3 amd64 1.1.0-1 [41.3 kB]
Get:13 http://deb.debian.org/debian buster/main amd64 cpp-8 amd64 8.3.0-6 [8914 kB]
Get:14 http://deb.debian.org/debian buster/main amd64 cpp amd64 4:8.3.0-1 [19.4 kB]
Get:15 http://deb.debian.org/debian buster/main amd64 libcc1-0 amd64 8.3.0-6 [46.6 kB]
Get:16 http://deb.debian.org/debian buster/main amd64 libgomp1 amd64 8.3.0-6 [75.8 kB]
Get:17 http://deb.debian.org/debian buster/main amd64 libitm1 amd64 8.3.0-6 [27.7 kB]
Get:18 http://deb.debian.org/debian buster/main amd64 libatomic1 amd64 8.3.0-6 [9032 B]
Get:19 http://deb.debian.org/debian buster/main amd64 libasan5 amd64 8.3.0-6 [362 kB]
Get:20 http://deb.debian.org/debian buster/main amd64 liblsan0 amd64 8.3.0-6 [131 kB]
Get:21 http://deb.debian.org/debian buster/main amd64 libtsan0 amd64 8.3.0-6 [283 kB]
Get:22 http://deb.debian.org/debian buster/main amd64 libubsan1 amd64 8.3.0-6 [120 kB]
Get:23 http://deb.debian.org/debian buster/main amd64 libmpx2 amd64 8.3.0-6 [11.4 kB]
Get:24 http://deb.debian.org/debian buster/main amd64 libquadmath0 amd64 8.3.0-6 [133 kB]
Get:25 http://deb.debian.org/debian buster/main amd64 libgcc-8-dev amd64 8.3.0-6 [2298 kB]
Get:26 http://deb.debian.org/debian buster/main amd64 gcc-8 amd64 8.3.0-6 [9452 kB]
Get:27 http://deb.debian.org/debian buster/main amd64 gcc amd64 4:8.3.0-1 [5196 B]
Get:28 http://deb.debian.org/debian buster/main amd64 libstdc++-8-dev amd64 8.3.0-6 [1532 kB]
Get:29 http://deb.debian.org/debian buster/main amd64 g++-8 amd64 8.3.0-6 [9752 kB]
Get:30 http://deb.debian.org/debian buster/main amd64 g++ amd64 4:8.3.0-1 [1644 B]
Get:31 http://deb.debian.org/debian buster/main amd64 make amd64 4.2.1-1.2 [341 kB]
Get:32 http://deb.debian.org/debian buster/main amd64 libdpkg-perl all 1.19.7 [1414 kB]
Get:33 http://deb.debian.org/debian buster/main amd64 dpkg-dev all 1.19.7 [1773 kB]
Get:34 http://deb.debian.org/debian buster/main amd64 build-essential amd64 12.6 [7576 B]
Get:35 http://deb.debian.org/debian buster/main amd64 libassuan0 amd64 2.5.2-1 [49.4 kB]
Get:36 http://deb.debian.org/debian buster/main amd64 gpgconf amd64 2.2.12-1+deb10u1 [510 kB]
Get:37 http://deb.debian.org/debian buster/main amd64 libksba8 amd64 1.3.5-2 [99.7 kB]
Get:38 http://deb.debian.org/debian buster/main amd64 libnpth0 amd64 1.6-1 [18.4 kB]
Get:39 http://deb.debian.org/debian buster/main amd64 dirmngr amd64 2.2.12-1+deb10u1 [712 kB]
Get:40 http://deb.debian.org/debian buster/main amd64 libfakeroot amd64 1.23-1 [45.9 kB]
Get:41 http://deb.debian.org/debian buster/main amd64 fakeroot amd64 1.23-1 [85.8 kB]
Get:42 http://deb.debian.org/debian buster/main amd64 gnupg-l10n all 2.2.12-1+deb10u1 [1010 kB]
Get:43 http://deb.debian.org/debian buster/main amd64 gnupg-utils amd64 2.2.12-1+deb10u1 [861 kB]
Get:44 http://deb.debian.org/debian buster/main amd64 gpg amd64 2.2.12-1+deb10u1 [865 kB]
Get:45 http://deb.debian.org/debian buster/main amd64 pinentry-curses amd64 1.1.0-2 [64.5 kB]
Get:46 http://deb.debian.org/debian buster/main amd64 gpg-agent amd64 2.2.12-1+deb10u1 [617 kB]
Get:47 http://deb.debian.org/debian buster/main amd64 gpg-wks-client amd64 2.2.12-1+deb10u1 [485 kB]
Get:48 http://deb.debian.org/debian buster/main amd64 gpg-wks-server amd64 2.2.12-1+deb10u1 [478 kB]
Get:49 http://deb.debian.org/debian buster/main amd64 gpgsm amd64 2.2.12-1+deb10u1 [604 kB]
Get:50 http://deb.debian.org/debian buster/main amd64 gnupg all 2.2.12-1+deb10u1 [715 kB]
Get:51 http://deb.debian.org/debian buster/main amd64 libalgorithm-diff-perl all 1.19.03-2 [47.9 kB]
Get:52 http://deb.debian.org/debian buster/main amd64 libalgorithm-diff-xs-perl amd64 0.04-5+b1 [11.8 kB]
Get:53 http://deb.debian.org/debian buster/main amd64 libalgorithm-merge-perl all 0.08-3 [12.7 kB]
Get:54 http://deb.debian.org/debian buster/main amd64 libfile-fcntllock-perl amd64 0.22-3+b5 [35.4 kB]
Get:55 http://deb.debian.org/debian buster/main amd64 manpages-dev all 4.16-2 [2232 kB]
[91mdebconf: delaying package configuration, since apt-utils is not installed
[0mFetched 57.7 MB in 1s (77.1 MB/s)
Selecting previously unselected package liblocale-gettext-perl.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 12557 files and directories currently installed.)
Preparing to unpack .../00-liblocale-gettext-perl_1.07-3+b4_amd64.deb ...
Unpacking liblocale-gettext-perl (1.07-3+b4) ...
Selecting previously unselected package manpages.
Preparing to unpack .../01-manpages_4.16-2_all.deb ...
Unpacking manpages (4.16-2) ...
Selecting previously unselected package binutils-common:amd64.
Preparing to unpack .../02-binutils-common_2.31.1-16_amd64.deb ...
Unpacking binutils-common:amd64 (2.31.1-16) ...
Selecting previously unselected package libbinutils:amd64.
Preparing to unpack .../03-libbinutils_2.31.1-16_amd64.deb ...
Unpacking libbinutils:amd64 (2.31.1-16) ...
Selecting previously unselected package binutils-x86-64-linux-gnu.
Preparing to unpack .../04-binutils-x86-64-linux-gnu_2.31.1-16_amd64.deb ...
Unpacking binutils-x86-64-linux-gnu (2.31.1-16) ...
Selecting previously unselected package binutils.
Preparing to unpack .../05-binutils_2.31.1-16_amd64.deb ...
Unpacking binutils (2.31.1-16) ...
Selecting previously unselected package libc-dev-bin.
Preparing to unpack .../06-libc-dev-bin_2.28-10_amd64.deb ...
Unpacking libc-dev-bin (2.28-10) ...
Selecting previously unselected package linux-libc-dev:amd64.
Preparing to unpack .../07-linux-libc-dev_4.19.98-1_amd64.deb ...
Unpacking linux-libc-dev:amd64 (4.19.98-1) ...
Selecting previously unselected package libc6-dev:amd64.
Preparing to unpack .../08-libc6-dev_2.28-10_amd64.deb ...
Unpacking libc6-dev:amd64 (2.28-10) ...
Selecting previously unselected package libisl19:amd64.
Preparing to unpack .../09-libisl19_0.20-2_amd64.deb ...
Unpacking libisl19:amd64 (0.20-2) ...
Selecting previously unselected package libmpfr6:amd64.
Preparing to unpack .../10-libmpfr6_4.0.2-1_amd64.deb ...
Unpacking libmpfr6:amd64 (4.0.2-1) ...
Selecting previously unselected package libmpc3:amd64.
Preparing to unpack .../11-libmpc3_1.1.0-1_amd64.deb ...
Unpacking libmpc3:amd64 (1.1.0-1) ...
Selecting previously unselected package cpp-8.
Preparing to unpack .../12-cpp-8_8.3.0-6_amd64.deb ...
Unpacking cpp-8 (8.3.0-6) ...
Selecting previously unselected package cpp.
Preparing to unpack .../13-cpp_4%3a8.3.0-1_amd64.deb ...
Unpacking cpp (4:8.3.0-1) ...
Selecting previously unselected package libcc1-0:amd64.
Preparing to unpack .../14-libcc1-0_8.3.0-6_amd64.deb ...
Unpacking libcc1-0:amd64 (8.3.0-6) ...
Selecting previously unselected package libgomp1:amd64.
Preparing to unpack .../15-libgomp1_8.3.0-6_amd64.deb ...
Unpacking libgomp1:amd64 (8.3.0-6) ...
Selecting previously unselected package libitm1:amd64.
Preparing to unpack .../16-libitm1_8.3.0-6_amd64.deb ...
Unpacking libitm1:amd64 (8.3.0-6) ...
Selecting previously unselected package libatomic1:amd64.
Preparing to unpack .../17-libatomic1_8.3.0-6_amd64.deb ...
Unpacking libatomic1:amd64 (8.3.0-6) ...
Selecting previously unselected package libasan5:amd64.
Preparing to unpack .../18-libasan5_8.3.0-6_amd64.deb ...
Unpacking libasan5:amd64 (8.3.0-6) ...
Selecting previously unselected package liblsan0:amd64.
Preparing to unpack .../19-liblsan0_8.3.0-6_amd64.deb ...
Unpacking liblsan0:amd64 (8.3.0-6) ...
Selecting previously unselected package libtsan0:amd64.
Preparing to unpack .../20-libtsan0_8.3.0-6_amd64.deb ...
Unpacking libtsan0:amd64 (8.3.0-6) ...
Selecting previously unselected package libubsan1:amd64.
Preparing to unpack .../21-libubsan1_8.3.0-6_amd64.deb ...
Unpacking libubsan1:amd64 (8.3.0-6) ...
Selecting previously unselected package libmpx2:amd64.
Preparing to unpack .../22-libmpx2_8.3.0-6_amd64.deb ...
Unpacking libmpx2:amd64 (8.3.0-6) ...
Selecting previously unselected package libquadmath0:amd64.
Preparing to unpack .../23-libquadmath0_8.3.0-6_amd64.deb ...
Unpacking libquadmath0:amd64 (8.3.0-6) ...
Selecting previously unselected package libgcc-8-dev:amd64.
Preparing to unpack .../24-libgcc-8-dev_8.3.0-6_amd64.deb ...
Unpacking libgcc-8-dev:amd64 (8.3.0-6) ...
Selecting previously unselected package gcc-8.
Preparing to unpack .../25-gcc-8_8.3.0-6_amd64.deb ...
Unpacking gcc-8 (8.3.0-6) ...
Selecting previously unselected package gcc.
Preparing to unpack .../26-gcc_4%3a8.3.0-1_amd64.deb ...
Unpacking gcc (4:8.3.0-1) ...
Selecting previously unselected package libstdc++-8-dev:amd64.
Preparing to unpack .../27-libstdc++-8-dev_8.3.0-6_amd64.deb ...
Unpacking libstdc++-8-dev:amd64 (8.3.0-6) ...
Selecting previously unselected package g++-8.
Preparing to unpack .../28-g++-8_8.3.0-6_amd64.deb ...
Unpacking g++-8 (8.3.0-6) ...
Selecting previously unselected package g++.
Preparing to unpack .../29-g++_4%3a8.3.0-1_amd64.deb ...
Unpacking g++ (4:8.3.0-1) ...
Selecting previously unselected package make.
Preparing to unpack .../30-make_4.2.1-1.2_amd64.deb ...
Unpacking make (4.2.1-1.2) ...
Selecting previously unselected package libdpkg-perl.
Preparing to unpack .../31-libdpkg-perl_1.19.7_all.deb ...
Unpacking libdpkg-perl (1.19.7) ...
Selecting previously unselected package dpkg-dev.
Preparing to unpack .../32-dpkg-dev_1.19.7_all.deb ...
Unpacking dpkg-dev (1.19.7) ...
Selecting previously unselected package build-essential.
Preparing to unpack .../33-build-essential_12.6_amd64.deb ...
Unpacking build-essential (12.6) ...
Selecting previously unselected package libassuan0:amd64.
Preparing to unpack .../34-libassuan0_2.5.2-1_amd64.deb ...
Unpacking libassuan0:amd64 (2.5.2-1) ...
Selecting previously unselected package gpgconf.
Preparing to unpack .../35-gpgconf_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpgconf (2.2.12-1+deb10u1) ...
Selecting previously unselected package libksba8:amd64.
Preparing to unpack .../36-libksba8_1.3.5-2_amd64.deb ...
Unpacking libksba8:amd64 (1.3.5-2) ...
Selecting previously unselected package libnpth0:amd64.
Preparing to unpack .../37-libnpth0_1.6-1_amd64.deb ...
Unpacking libnpth0:amd64 (1.6-1) ...
Selecting previously unselected package dirmngr.
Preparing to unpack .../38-dirmngr_2.2.12-1+deb10u1_amd64.deb ...
Unpacking dirmngr (2.2.12-1+deb10u1) ...
Selecting previously unselected package libfakeroot:amd64.
Preparing to unpack .../39-libfakeroot_1.23-1_amd64.deb ...
Unpacking libfakeroot:amd64 (1.23-1) ...
Selecting previously unselected package fakeroot.
Preparing to unpack .../40-fakeroot_1.23-1_amd64.deb ...
Unpacking fakeroot (1.23-1) ...
Selecting previously unselected package gnupg-l10n.
Preparing to unpack .../41-gnupg-l10n_2.2.12-1+deb10u1_all.deb ...
Unpacking gnupg-l10n (2.2.12-1+deb10u1) ...
Selecting previously unselected package gnupg-utils.
Preparing to unpack .../42-gnupg-utils_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gnupg-utils (2.2.12-1+deb10u1) ...
Selecting previously unselected package gpg.
Preparing to unpack .../43-gpg_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpg (2.2.12-1+deb10u1) ...
Selecting previously unselected package pinentry-curses.
Preparing to unpack .../44-pinentry-curses_1.1.0-2_amd64.deb ...
Unpacking pinentry-curses (1.1.0-2) ...
Selecting previously unselected package gpg-agent.
Preparing to unpack .../45-gpg-agent_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpg-agent (2.2.12-1+deb10u1) ...
Selecting previously unselected package gpg-wks-client.
Preparing to unpack .../46-gpg-wks-client_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpg-wks-client (2.2.12-1+deb10u1) ...
Selecting previously unselected package gpg-wks-server.
Preparing to unpack .../47-gpg-wks-server_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpg-wks-server (2.2.12-1+deb10u1) ...
Selecting previously unselected package gpgsm.
Preparing to unpack .../48-gpgsm_2.2.12-1+deb10u1_amd64.deb ...
Unpacking gpgsm (2.2.12-1+deb10u1) ...
Selecting previously unselected package gnupg.
Preparing to unpack .../49-gnupg_2.2.12-1+deb10u1_all.deb ...
Unpacking gnupg (2.2.12-1+deb10u1) ...
Selecting previously unselected package libalgorithm-diff-perl.
Preparing to unpack .../50-libalgorithm-diff-perl_1.19.03-2_all.deb ...
Unpacking libalgorithm-diff-perl (1.19.03-2) ...
Selecting previously unselected package libalgorithm-diff-xs-perl.
Preparing to unpack .../51-libalgorithm-diff-xs-perl_0.04-5+b1_amd64.deb ...
Unpacking libalgorithm-diff-xs-perl (0.04-5+b1) ...
Selecting previously unselected package libalgorithm-merge-perl.
Preparing to unpack .../52-libalgorithm-merge-perl_0.08-3_all.deb ...
Unpacking libalgorithm-merge-perl (0.08-3) ...
Selecting previously unselected package libfile-fcntllock-perl.
Preparing to unpack .../53-libfile-fcntllock-perl_0.22-3+b5_amd64.deb ...
Unpacking libfile-fcntllock-perl (0.22-3+b5) ...
Selecting previously unselected package manpages-dev.
Preparing to unpack .../54-manpages-dev_4.16-2_all.deb ...
Unpacking manpages-dev (4.16-2) ...
Setting up libksba8:amd64 (1.3.5-2) ...
Setting up libfile-fcntllock-perl (0.22-3+b5) ...
Setting up libalgorithm-diff-perl (1.19.03-2) ...
Setting up manpages (4.16-2) ...
Setting up binutils-common:amd64 (2.31.1-16) ...
Setting up linux-libc-dev:amd64 (4.19.98-1) ...
Setting up libnpth0:amd64 (1.6-1) ...
Setting up libassuan0:amd64 (2.5.2-1) ...
Setting up libgomp1:amd64 (8.3.0-6) ...
Setting up libfakeroot:amd64 (1.23-1) ...
Setting up fakeroot (1.23-1) ...
update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode
update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
Setting up libasan5:amd64 (8.3.0-6) ...
Setting up make (4.2.1-1.2) ...
Setting up libmpfr6:amd64 (4.0.2-1) ...
Setting up gnupg-l10n (2.2.12-1+deb10u1) ...
Setting up libquadmath0:amd64 (8.3.0-6) ...
Setting up libmpc3:amd64 (1.1.0-1) ...
Setting up libatomic1:amd64 (8.3.0-6) ...
Setting up libdpkg-perl (1.19.7) ...
Setting up libmpx2:amd64 (8.3.0-6) ...
Setting up libubsan1:amd64 (8.3.0-6) ...
Setting up libisl19:amd64 (0.20-2) ...
Setting up gpgconf (2.2.12-1+deb10u1) ...
Setting up libbinutils:amd64 (2.31.1-16) ...
Setting up cpp-8 (8.3.0-6) ...
Setting up libc-dev-bin (2.28-10) ...
Setting up libalgorithm-diff-xs-perl (0.04-5+b1) ...
Setting up libcc1-0:amd64 (8.3.0-6) ...
Setting up liblocale-gettext-perl (1.07-3+b4) ...
Setting up gpg (2.2.12-1+deb10u1) ...
Setting up liblsan0:amd64 (8.3.0-6) ...
Setting up libitm1:amd64 (8.3.0-6) ...
Setting up libalgorithm-merge-perl (0.08-3) ...
Setting up gnupg-utils (2.2.12-1+deb10u1) ...
Setting up binutils-x86-64-linux-gnu (2.31.1-16) ...
Setting up libtsan0:amd64 (8.3.0-6) ...
Setting up pinentry-curses (1.1.0-2) ...
Setting up manpages-dev (4.16-2) ...
Setting up gpg-agent (2.2.12-1+deb10u1) ...
Setting up gpgsm (2.2.12-1+deb10u1) ...
Setting up binutils (2.31.1-16) ...
Setting up dpkg-dev (1.19.7) ...
Setting up dirmngr (2.2.12-1+deb10u1) ...
Setting up libgcc-8-dev:amd64 (8.3.0-6) ...
Setting up gpg-wks-server (2.2.12-1+deb10u1) ...
Setting up cpp (4:8.3.0-1) ...
Setting up libc6-dev:amd64 (2.28-10) ...
Setting up libstdc++-8-dev:amd64 (8.3.0-6) ...
Setting up gcc-8 (8.3.0-6) ...
Setting up gpg-wks-client (2.2.12-1+deb10u1) ...
Setting up gcc (4:8.3.0-1) ...
Setting up g++-8 (8.3.0-6) ...
Setting up gnupg (2.2.12-1+deb10u1) ...
Setting up g++ (4:8.3.0-1) ...
update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode
Setting up build-essential (12.6) ...
Processing triggers for libc-bin (2.28-10) ...
Removing intermediate container 6f1e9b9cdd85
 ---> 4114e1706df6
Step 5/10 : RUN mkdir microservice
 ---> Running in 5c21c6cec233
Removing intermediate container 5c21c6cec233
 ---> 94f4b2ea4073
Step 6/10 : WORKDIR /microservice
 ---> Running in 14166140c746
Removing intermediate container 14166140c746
 ---> 89b1ed2e8339
Step 7/10 : COPY ./s2i/bin/ /s2i/bin
 ---> da981a5d765a
Step 8/10 : COPY _python /microservice
 ---> 7791890042fe
Step 9/10 : RUN cd /microservice/python && make install
 ---> Running in 8ce54501d745
[91mcat: ../version.txt: No such file or directory
[0mpip install -e .
Obtaining file:///microservice/python
Collecting Flask<2.0.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl (94kB)
Collecting Flask-cors<4.0.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl
Collecting redis<4.0.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)
Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.7/site-packages (from seldon-core==1.0.2) (2.22.0)
Collecting numpy<2.0.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/b7/ce/d0b92f0283faa4da76ea82587ff9da70104e81f59ba14f76c87e4196254e/numpy-1.18.2-cp37-cp37m-manylinux1_x86_64.whl (20.2MB)
Collecting flatbuffers<2.0.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl
Collecting protobuf<4.0.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/ff/f1/8dcd4219bbae8aa44fe8871a89f05eca2dca9c04f8dbfed8a82b7be97a88/protobuf-3.11.3-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)
Collecting grpcio<2.0.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/f1/f4/c437929e1a8db457d85c0c16d348a5dd00427114e281a9a0579c07114cf6/grpcio-1.28.1-cp37-cp37m-manylinux2010_x86_64.whl (2.8MB)
Collecting Flask-OpenTracing<1.2.0,>=1.1.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/58/6c/6417701ba5ecc8854670c6db3207bcc3e5fbc96289a7cb18d5516d99a1c6/Flask-OpenTracing-1.1.0.tar.gz
Collecting opentracing<2.3.0,>=2.2.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/94/9f/289424136addf621fb4c75624ef9a3a80e8575da3993a87950c57e93217e/opentracing-2.2.0.tar.gz (47kB)
Collecting jaeger-client<4.2.0,>=4.1.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/f1/da/569a4f1bc3d0c412c7f903053f09ef62fa10949374ca90bc852b22dd3860/jaeger-client-4.1.0.tar.gz (80kB)
Collecting grpcio-opentracing<1.2.0,>=1.1.4 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/db/82/2fcad380697c3dab25de76ee590bcab3eb9bbfb4add916044d7e83ec2b10/grpcio_opentracing-1.1.4-py3-none-any.whl
Collecting pyaml<20.0.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/35/1e/eda9fe07f752ced7afcef590e7d74390f0d9c9c0b7ff98317afbaa0697e3/pyaml-19.12.0-py2.py3-none-any.whl
Collecting gunicorn<20.1.0,>=19.9.0 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)
Collecting minio<6.0.0,>=4.0.9 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/8f/ed/8670995efca990a8b6473f24331fcc40e61b59a00fe31e6e266b667f4866/minio-5.0.8-py2.py3-none-any.whl (73kB)
Collecting azure-storage-blob<3.0.0,>=2.0.1 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/3e/84/610f379b46d7d3c2d48eadeed6a12b6d46a43100fea70534f5992d0ac996/azure_storage_blob-2.1.0-py2.py3-none-any.whl (88kB)
Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from seldon-core==1.0.2) (41.4.0)
Collecting prometheus_client<0.8.0,>=0.7.1 (from seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz
Collecting itsdangerous>=0.24 (from Flask<2.0.0->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl
Collecting Jinja2>=2.10.1 (from Flask<2.0.0->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/27/24/4f35961e5c669e96f6559760042a55b9bcfcdb82b9bdb3c8753dbe042e35/Jinja2-2.11.1-py2.py3-none-any.whl (126kB)
Collecting click>=5.1 (from Flask<2.0.0->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/dd/c0/4d8f43a9b16e289f36478422031b8a63b54b6ac3b1ba605d602f10dd54d6/click-7.1.1-py2.py3-none-any.whl (82kB)
Collecting Werkzeug>=0.15 (from Flask<2.0.0->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)
Requirement already satisfied: Six in /opt/conda/lib/python3.7/site-packages (from Flask-cors<4.0.0->seldon-core==1.0.2) (1.12.0)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0->seldon-core==1.0.2) (3.0.4)
Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0->seldon-core==1.0.2) (2.8)
Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0->seldon-core==1.0.2) (2019.11.28)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0->seldon-core==1.0.2) (1.24.2)
Collecting threadloop<2,>=1 (from jaeger-client<4.2.0,>=4.1.0->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/d3/1d/8398c1645b97dc008d3c658e04beda01ede3d90943d40c8d56863cf891bd/threadloop-1.0.2.tar.gz
Collecting thrift (from jaeger-client<4.2.0,>=4.1.0->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/97/1e/3284d19d7be99305eda145b8aa46b0c33244e4a496ec66440dac19f8274d/thrift-0.13.0.tar.gz (59kB)
Collecting tornado<6,>=4.3 (from jaeger-client<4.2.0,>=4.1.0->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/e6/78/6e7b5af12c12bdf38ca9bfe863fcaf53dc10430a312d0324e76c1e5ca426/tornado-5.1.1.tar.gz (516kB)
Collecting PyYAML (from pyaml<20.0.0->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)
Collecting configparser (from minio<6.0.0,>=4.0.9->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl
Collecting pytz (from minio<6.0.0,>=4.0.9->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)
Collecting python-dateutil (from minio<6.0.0,>=4.0.9->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)
Collecting azure-storage-common~=2.1 (from azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/6b/a0/6794b318ce0118d1a4053bdf0149a60807407db9b710354f2b203c2f5975/azure_storage_common-2.1.0-py2.py3-none-any.whl (47kB)
Collecting azure-common>=1.1.5 (from azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/e5/4d/d000fc3c5af601d00d55750b71da5c231fcb128f42ac95b208ed1091c2c1/azure_common-1.1.25-py2.py3-none-any.whl
Collecting MarkupSafe>=0.23 (from Jinja2>=2.10.1->Flask<2.0.0->seldon-core==1.0.2)
  Downloading https://files.pythonhosted.org/packages/98/7b/ff284bd8c80654e471b769062a9b43cc5d03e7a615048d96f4619df8d420/MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl
Requirement already satisfied: cryptography in /opt/conda/lib/python3.7/site-packages (from azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (2.7)
Requirement already satisfied: asn1crypto>=0.21.0 in /opt/conda/lib/python3.7/site-packages (from cryptography->azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (1.0.1)
Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.7/site-packages (from cryptography->azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (1.12.3)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (2.19)
Building wheels for collected packages: Flask-OpenTracing, opentracing, jaeger-client, prometheus-client, threadloop, thrift, tornado, PyYAML
  Building wheel for Flask-OpenTracing (setup.py): started
  Building wheel for Flask-OpenTracing (setup.py): finished with status 'done'
  Created wheel for Flask-OpenTracing: filename=Flask_OpenTracing-1.1.0-cp37-none-any.whl size=9072 sha256=3b06f047e1d71a737626db05e1c8019628350bc2f6932229fbf319f104a41b5a
  Stored in directory: /root/.cache/pip/wheels/7b/dc/25/3cf0b35c129232ee596c413f13d1d1f5a8e38c427266276dfd
  Building wheel for opentracing (setup.py): started
  Building wheel for opentracing (setup.py): finished with status 'done'
  Created wheel for opentracing: filename=opentracing-2.2.0-cp37-none-any.whl size=49320 sha256=6f6e37113710e597ac05358fbedade5d01e2b8c8c8aa39b4434409ac5543ac9f
  Stored in directory: /root/.cache/pip/wheels/93/e9/b5/1cdc3544f99a54caca13832b5afa26fd98701fe709dc049576
  Building wheel for jaeger-client (setup.py): started
  Building wheel for jaeger-client (setup.py): finished with status 'done'
  Created wheel for jaeger-client: filename=jaeger_client-4.1.0-cp37-none-any.whl size=64309 sha256=cfb198c6690716cacde0daad76971670601ecde85471dfea2b781ba88461310b
  Stored in directory: /root/.cache/pip/wheels/f2/84/7f/e89da3ee8ce35598d6382b6389fa2ada5d66acca2422537994
  Building wheel for prometheus-client (setup.py): started
  Building wheel for prometheus-client (setup.py): finished with status 'done'
  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp37-none-any.whl size=41402 sha256=db94d4746e5acf70443cb8b41638df0bad9a2c7f9ea7f769a1cb63947e99ffe0
  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea
  Building wheel for threadloop (setup.py): started
  Building wheel for threadloop (setup.py): finished with status 'done'
  Created wheel for threadloop: filename=threadloop-1.0.2-cp37-none-any.whl size=3424 sha256=5d3ef714ebaa7eb59a6c6465b987f89c06a37f4313a23d8cb437b06edc7a6067
  Stored in directory: /root/.cache/pip/wheels/d7/7a/30/d212623a4cd34f6cce400f8122b1b7af740d3440c68023d51f
  Building wheel for thrift (setup.py): started
  Building wheel for thrift (setup.py): finished with status 'done'
  Created wheel for thrift: filename=thrift-0.13.0-cp37-cp37m-linux_x86_64.whl size=486831 sha256=291a73f9ff9fb7da4c714960944aafed4de30980e1dd51705c3d8e5c4ae46f02
  Stored in directory: /root/.cache/pip/wheels/02/a2/46/689ccfcf40155c23edc7cdbd9de488611c8fdf49ff34b1706e
  Building wheel for tornado (setup.py): started
  Building wheel for tornado (setup.py): finished with status 'done'
  Created wheel for tornado: filename=tornado-5.1.1-cp37-cp37m-linux_x86_64.whl size=463627 sha256=d92985beab63f195fd6961eb5d022845111c91424eacdc5c95d4f843192b23b2
  Stored in directory: /root/.cache/pip/wheels/6d/e1/ce/f4ee2fa420cc6b940123c64992b81047816d0a9fad6b879325
  Building wheel for PyYAML (setup.py): started
  Building wheel for PyYAML (setup.py): finished with status 'done'
  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=215e0422213f25135616f75ed292e1e7b390496a571ba9f85e136db6a66b6d2f
  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd
Successfully built Flask-OpenTracing opentracing jaeger-client prometheus-client threadloop thrift tornado PyYAML
Installing collected packages: itsdangerous, MarkupSafe, Jinja2, click, Werkzeug, Flask, Flask-cors, redis, numpy, flatbuffers, protobuf, grpcio, opentracing, Flask-OpenTracing, tornado, threadloop, thrift, jaeger-client, grpcio-opentracing, PyYAML, pyaml, gunicorn, configparser, pytz, python-dateutil, minio, azure-common, azure-storage-common, azure-storage-blob, prometheus-client, seldon-core
  Running setup.py develop for seldon-core
Successfully installed Flask-1.1.2 Flask-OpenTracing-1.1.0 Flask-cors-3.0.8 Jinja2-2.11.1 MarkupSafe-1.1.1 PyYAML-5.3.1 Werkzeug-1.0.1 azure-common-1.1.25 azure-storage-blob-2.1.0 azure-storage-common-2.1.0 click-7.1.1 configparser-5.0.0 flatbuffers-1.12 grpcio-1.28.1 grpcio-opentracing-1.1.4 gunicorn-20.0.4 itsdangerous-1.1.0 jaeger-client-4.1.0 minio-5.0.8 numpy-1.18.2 opentracing-2.2.0 prometheus-client-0.7.1 protobuf-3.11.3 pyaml-19.12.0 python-dateutil-2.8.1 pytz-2019.3 redis-3.4.1 seldon-core threadloop-1.0.2 thrift-0.13.0 tornado-5.1.1
Removing intermediate container 8ce54501d745
 ---> 160da37ab33a
Step 10/10 : EXPOSE 5000
 ---> Running in 61130cdbce67
Removing intermediate container 61130cdbce67
 ---> 3fb535dd1b97
Successfully built 3fb535dd1b97
Successfully tagged seldonio/seldon-core-s2i-python37:1.0.3-SNAPSHOT
make[1]: Leaving directory '/workspace/source/wrappers/s2i/python'
make[1]: Entering directory '/workspace/source/wrappers/s2i/python'
docker tag docker.io/seldonio/seldon-core-s2i-python`echo -n 3.7 | sed 's/\.//g'`:1.0.3-SNAPSHOT docker.io/seldonio/seldon-core-s2i-python`echo -n 3.7 | cut -d. -f1`:1.0.3-SNAPSHOT
make[1]: Leaving directory '/workspace/source/wrappers/s2i/python'
make[1]: Entering directory '/workspace/source/wrappers/s2i/python'
mkdir -p _python
cp -r ../../../python _python
cat Dockerfile.gpu.tmpl > Dockerfile
docker build -t docker.io/seldonio/seldon-core-s2i-python3-tf-gpu:1.0.3-SNAPSHOT .
Sending build context to Docker daemon  954.9kB
Step 1/10 : FROM nvidia/cuda:10.0-cudnn7-runtime-ubuntu18.04
10.0-cudnn7-runtime-ubuntu18.04: Pulling from nvidia/cuda
7ddbc47eeb70: Pulling fs layer
c1bbdc448b72: Pulling fs layer
8c3b70e39044: Pulling fs layer
45d437916d57: Pulling fs layer
d8f1569ddae6: Pulling fs layer
de5a2c57c41d: Pulling fs layer
ea6f04a00543: Pulling fs layer
7b872974e97c: Pulling fs layer
3b7640b8f8d2: Pulling fs layer
de5a2c57c41d: Waiting
ea6f04a00543: Waiting
7b872974e97c: Waiting
3b7640b8f8d2: Waiting
45d437916d57: Waiting
d8f1569ddae6: Waiting
8c3b70e39044: Verifying Checksum
8c3b70e39044: Download complete
c1bbdc448b72: Verifying Checksum
c1bbdc448b72: Download complete
7ddbc47eeb70: Download complete
45d437916d57: Verifying Checksum
45d437916d57: Download complete
d8f1569ddae6: Verifying Checksum
d8f1569ddae6: Download complete
de5a2c57c41d: Verifying Checksum
de5a2c57c41d: Download complete
ea6f04a00543: Verifying Checksum
ea6f04a00543: Download complete
7ddbc47eeb70: Pull complete
c1bbdc448b72: Pull complete
8c3b70e39044: Pull complete
45d437916d57: Pull complete
d8f1569ddae6: Pull complete
de5a2c57c41d: Pull complete
ea6f04a00543: Pull complete
3b7640b8f8d2: Download complete
7b872974e97c: Verifying Checksum
7b872974e97c: Download complete
7b872974e97c: Pull complete
3b7640b8f8d2: Pull complete
Digest: sha256:0012abba369318cd23dadac1e141543bf8adefa17cb5d2f685920321ad84bd49
Status: Downloaded newer image for nvidia/cuda:10.0-cudnn7-runtime-ubuntu18.04
 ---> a9fac7264a6d
Step 2/10 : LABEL io.openshift.s2i.scripts-url="image:///s2i/bin"
 ---> Running in 8c08ce769e6d
Removing intermediate container 8c08ce769e6d
 ---> 7d2155cc5367
Step 3/10 : RUN apt-get update -y &&     apt-get install -y python3-pip python3-dev &&     ln -s /usr/bin/pip3 /usr/bin/pip &&     ln -s /usr/bin/python3 /usr/bin/python
 ---> Running in 1a24b1174564
Get:1 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB]
Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]
Get:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]
Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]
Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease
Get:6 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB]
Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB]
Get:8 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]
Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB]
Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [12.2 kB]
Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [54.8 kB]
Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1367 kB]
Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1170 kB]
Get:14 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [4247 B]
Get:15 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [2496 B]
Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [835 kB]
Ign:17 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease
Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [564 B]
Get:19 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]
Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [819 B]
Get:21 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]
Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [141 kB]
Get:23 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [31.7 kB]
Get:24 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [873 kB]
Get:25 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [7904 B]
Get:26 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [38.5 kB]
Fetched 17.9 MB in 2s (8402 kB/s)
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
The following additional packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu build-essential cpp cpp-7
  dbus dh-python dpkg-dev fakeroot file g++ g++-7 gcc gcc-7 gcc-7-base
  gcc-8-base gir1.2-glib-2.0 libalgorithm-diff-perl libalgorithm-diff-xs-perl
  libalgorithm-merge-perl libapparmor1 libasan4 libatomic1 libbinutils
  libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libdbus-1-3 libdpkg-perl
  libexpat1 libexpat1-dev libfakeroot libfile-fcntllock-perl libgcc-7-dev
  libgcc1 libgdbm-compat4 libgdbm5 libgirepository-1.0-1 libglib2.0-0
  libglib2.0-data libgomp1 libicu60 libisl19 libitm1 liblocale-gettext-perl
  liblsan0 libmagic-mgc libmagic1 libmpc3 libmpdec2 libmpfr6 libmpx2
  libperl5.26 libpython3-dev libpython3-stdlib libpython3.6 libpython3.6-dev
  libpython3.6-minimal libpython3.6-stdlib libquadmath0 libstdc++-7-dev
  libstdc++6 libtsan0 libubsan0 libxml2 linux-libc-dev make manpages
  manpages-dev mime-support netbase patch perl perl-modules-5.26
  python-pip-whl python3 python3-asn1crypto python3-cffi-backend
  python3-crypto python3-cryptography python3-dbus python3-distutils
  python3-gi python3-idna python3-keyring python3-keyrings.alt python3-lib2to3
  python3-minimal python3-pkg-resources python3-secretstorage
  python3-setuptools python3-six python3-wheel python3-xdg python3.6
  python3.6-dev python3.6-minimal shared-mime-info xdg-user-dirs xz-utils
Suggested packages:
  binutils-doc cpp-doc gcc-7-locales default-dbus-session-bus
  | dbus-session-bus debian-keyring g++-multilib g++-7-multilib gcc-7-doc
  libstdc++6-7-dbg gcc-multilib autoconf automake libtool flex bison gdb
  gcc-doc gcc-7-multilib libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg
  libasan4-dbg liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg
  libmpx2-dbg libquadmath0-dbg glibc-doc git bzr gdbm-l10n libstdc++-7-doc
  make-doc man-browser ed diffutils-doc perl-doc libterm-readline-gnu-perl
  | libterm-readline-perl-perl python3-doc python3-tk python3-venv
  python-crypto-doc python-cryptography-doc python3-cryptography-vectors
  python-dbus-doc python3-dbus-dbg gnome-keyring libkf5wallet-bin
  gir1.2-gnomekeyring-1.0 python-secretstorage-doc python-setuptools-doc
  python3.6-venv python3.6-doc binfmt-support
The following NEW packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu build-essential cpp cpp-7
  dbus dh-python dpkg-dev fakeroot file g++ g++-7 gcc gcc-7 gcc-7-base
  gir1.2-glib-2.0 libalgorithm-diff-perl libalgorithm-diff-xs-perl
  libalgorithm-merge-perl libapparmor1 libasan4 libatomic1 libbinutils
  libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libdbus-1-3 libdpkg-perl
  libexpat1 libexpat1-dev libfakeroot libfile-fcntllock-perl libgcc-7-dev
  libgdbm-compat4 libgdbm5 libgirepository-1.0-1 libglib2.0-0 libglib2.0-data
  libgomp1 libicu60 libisl19 libitm1 liblocale-gettext-perl liblsan0
  libmagic-mgc libmagic1 libmpc3 libmpdec2 libmpfr6 libmpx2 libperl5.26
  libpython3-dev libpython3-stdlib libpython3.6 libpython3.6-dev
  libpython3.6-minimal libpython3.6-stdlib libquadmath0 libstdc++-7-dev
  libtsan0 libubsan0 libxml2 linux-libc-dev make manpages manpages-dev
  mime-support netbase patch perl perl-modules-5.26 python-pip-whl python3
  python3-asn1crypto python3-cffi-backend python3-crypto python3-cryptography
  python3-dbus python3-dev python3-distutils python3-gi python3-idna
  python3-keyring python3-keyrings.alt python3-lib2to3 python3-minimal
  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools
  python3-six python3-wheel python3-xdg python3.6 python3.6-dev
  python3.6-minimal shared-mime-info xdg-user-dirs xz-utils
The following packages will be upgraded:
  gcc-8-base libgcc1 libstdc++6
3 upgraded, 101 newly installed, 0 to remove and 23 not upgraded.
Need to get 118 MB of archives.
After this operation, 377 MB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblocale-gettext-perl amd64 1.07-3build2 [16.6 kB]
Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6-minimal amd64 3.6.9-1~18.04 [533 kB]
Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libexpat1 amd64 2.2.5-3ubuntu0.2 [80.5 kB]
Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3.6-minimal amd64 3.6.9-1~18.04 [1610 kB]
Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-minimal amd64 3.6.7-1~18.04 [23.7 kB]
Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 mime-support all 3.60ubuntu1 [30.1 kB]
Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmpdec2 amd64 2.4.2-1ubuntu1 [84.1 kB]
Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6-stdlib amd64 3.6.9-1~18.04 [1709 kB]
Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3.6 amd64 3.6.9-1~18.04 [203 kB]
Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3-stdlib amd64 3.6.7-1~18.04 [7240 B]
Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3 amd64 3.6.7-1~18.04 [47.2 kB]
Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 perl-modules-5.26 all 5.26.1-6ubuntu0.3 [2763 kB]
Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdbm5 amd64 1.14.1-6 [26.0 kB]
Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdbm-compat4 amd64 1.14.1-6 [6084 B]
Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libperl5.26 amd64 5.26.1-6ubuntu0.3 [3527 kB]
Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 perl amd64 5.26.1-6ubuntu0.3 [201 kB]
Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gcc-8-base amd64 8.4.0-1ubuntu1~18.04 [18.7 kB]
Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libstdc++6 amd64 8.4.0-1ubuntu1~18.04 [400 kB]
Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgcc1 amd64 1:8.4.0-1ubuntu1~18.04 [40.6 kB]
Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libapparmor1 amd64 2.12-4ubuntu5.1 [31.3 kB]
Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdbus-1-3 amd64 1.12.2-1ubuntu1.1 [175 kB]
Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 dbus amd64 1.12.2-1ubuntu1.1 [150 kB]
Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.3 [184 kB]
Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.3 [68.7 kB]
Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.3 [22.1 kB]
Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-0 amd64 2.56.4-0ubuntu0.18.04.6 [1171 kB]
Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgirepository-1.0-1 amd64 1.56.1-1 [82.0 kB]
Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-glib-2.0 amd64 1.56.1-1 [131 kB]
Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-data all 2.56.4-0ubuntu0.18.04.6 [4540 B]
Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libicu60 amd64 60.2-3ubuntu3.1 [8054 kB]
Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxml2 amd64 2.9.4+dfsg1-6.1ubuntu1.3 [663 kB]
Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 netbase all 5.4 [12.7 kB]
Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-dbus amd64 1.2.6-1 [89.9 kB]
Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-gi amd64 3.26.1-2ubuntu1 [153 kB]
Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 shared-mime-info amd64 1.9-2 [426 kB]
Get:36 http://archive.ubuntu.com/ubuntu bionic/main amd64 xdg-user-dirs amd64 0.17-1ubuntu1 [48.0 kB]
Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 xz-utils amd64 5.2.2-1.3 [83.8 kB]
Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 manpages all 4.15-1 [1234 kB]
Get:39 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils-common amd64 2.30-21ubuntu1~18.04.2 [193 kB]
Get:40 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbinutils amd64 2.30-21ubuntu1~18.04.2 [503 kB]
Get:41 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.30-21ubuntu1~18.04.2 [1856 kB]
Get:42 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils amd64 2.30-21ubuntu1~18.04.2 [3396 B]
Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 libc-dev-bin amd64 2.27-3ubuntu1 [71.8 kB]
Get:44 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 linux-libc-dev amd64 4.15.0-96.97 [1021 kB]
Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 libc6-dev amd64 2.27-3ubuntu1 [2587 kB]
Get:46 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gcc-7-base amd64 7.5.0-3ubuntu1~18.04 [18.3 kB]
Get:47 http://archive.ubuntu.com/ubuntu bionic/main amd64 libisl19 amd64 0.19-1 [551 kB]
Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmpfr6 amd64 4.0.1-1 [243 kB]
Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmpc3 amd64 1.1.0-1 [40.8 kB]
Get:50 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 cpp-7 amd64 7.5.0-3ubuntu1~18.04 [8591 kB]
Get:51 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 cpp amd64 4:7.4.0-1ubuntu2.3 [27.7 kB]
Get:52 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcc1-0 amd64 8.4.0-1ubuntu1~18.04 [39.4 kB]
Get:53 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgomp1 amd64 8.4.0-1ubuntu1~18.04 [76.5 kB]
Get:54 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libitm1 amd64 8.4.0-1ubuntu1~18.04 [27.9 kB]
Get:55 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libatomic1 amd64 8.4.0-1ubuntu1~18.04 [9192 B]
Get:56 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libasan4 amd64 7.5.0-3ubuntu1~18.04 [358 kB]
Get:57 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 liblsan0 amd64 8.4.0-1ubuntu1~18.04 [133 kB]
Get:58 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtsan0 amd64 8.4.0-1ubuntu1~18.04 [288 kB]
Get:59 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libubsan0 amd64 7.5.0-3ubuntu1~18.04 [126 kB]
Get:60 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcilkrts5 amd64 7.5.0-3ubuntu1~18.04 [42.5 kB]
Get:61 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmpx2 amd64 8.4.0-1ubuntu1~18.04 [11.6 kB]
Get:62 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libquadmath0 amd64 8.4.0-1ubuntu1~18.04 [134 kB]
Get:63 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgcc-7-dev amd64 7.5.0-3ubuntu1~18.04 [2378 kB]
Get:64 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gcc-7 amd64 7.5.0-3ubuntu1~18.04 [9381 kB]
Get:65 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gcc amd64 4:7.4.0-1ubuntu2.3 [5184 B]
Get:66 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libstdc++-7-dev amd64 7.5.0-3ubuntu1~18.04 [1471 kB]
Get:67 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 g++-7 amd64 7.5.0-3ubuntu1~18.04 [9697 kB]
Get:68 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 g++ amd64 4:7.4.0-1ubuntu2.3 [1568 B]
Get:69 http://archive.ubuntu.com/ubuntu bionic/main amd64 make amd64 4.1-9.1ubuntu1 [154 kB]
Get:70 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdpkg-perl all 1.19.0.5ubuntu2.3 [211 kB]
Get:71 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 patch amd64 2.7.6-2ubuntu1.1 [102 kB]
Get:72 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 dpkg-dev all 1.19.0.5ubuntu2.3 [607 kB]
Get:73 http://archive.ubuntu.com/ubuntu bionic/main amd64 build-essential amd64 12.4ubuntu1 [4758 B]
Get:74 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-lib2to3 all 3.6.9-1~18.04 [77.4 kB]
Get:75 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-distutils all 3.6.9-1~18.04 [144 kB]
Get:76 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-python all 3.20180325ubuntu2 [89.2 kB]
Get:77 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfakeroot amd64 1.22-2ubuntu1 [25.9 kB]
Get:78 http://archive.ubuntu.com/ubuntu bionic/main amd64 fakeroot amd64 1.22-2ubuntu1 [62.3 kB]
Get:79 http://archive.ubuntu.com/ubuntu bionic/main amd64 libalgorithm-diff-perl all 1.19.03-1 [47.6 kB]
Get:80 http://archive.ubuntu.com/ubuntu bionic/main amd64 libalgorithm-diff-xs-perl amd64 0.04-5 [11.1 kB]
Get:81 http://archive.ubuntu.com/ubuntu bionic/main amd64 libalgorithm-merge-perl all 0.08-3 [12.0 kB]
Get:82 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libexpat1-dev amd64 2.2.5-3ubuntu0.2 [122 kB]
Get:83 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfile-fcntllock-perl amd64 0.22-3build2 [33.2 kB]
Get:84 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6 amd64 3.6.9-1~18.04 [1414 kB]
Get:85 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6-dev amd64 3.6.9-1~18.04 [44.8 MB]
Get:86 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3-dev amd64 3.6.7-1~18.04 [7328 B]
Get:87 http://archive.ubuntu.com/ubuntu bionic/main amd64 manpages-dev all 4.15-1 [2217 kB]
Get:88 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.1 [1653 kB]
Get:89 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]
Get:90 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]
Get:91 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]
Get:92 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]
Get:93 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]
Get:94 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.3 [221 kB]
Get:95 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3.6-dev amd64 3.6.9-1~18.04 [508 kB]
Get:96 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-dev amd64 3.6.7-1~18.04 [1288 B]
Get:97 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]
Get:98 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]
Get:99 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]
Get:100 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.1 [114 kB]
Get:101 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]
Get:102 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]
Get:103 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]
Get:104 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-xdg all 0.25-4ubuntu1 [31.4 kB]
[91mdebconf: delaying package configuration, since apt-utils is not installed
[0mFetched 118 MB in 2s (64.9 MB/s)
Selecting previously unselected package liblocale-gettext-perl.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 4835 files and directories currently installed.)
Preparing to unpack .../liblocale-gettext-perl_1.07-3build2_amd64.deb ...
Unpacking liblocale-gettext-perl (1.07-3build2) ...
Selecting previously unselected package libpython3.6-minimal:amd64.
Preparing to unpack .../libpython3.6-minimal_3.6.9-1~18.04_amd64.deb ...
Unpacking libpython3.6-minimal:amd64 (3.6.9-1~18.04) ...
Selecting previously unselected package libexpat1:amd64.
Preparing to unpack .../libexpat1_2.2.5-3ubuntu0.2_amd64.deb ...
Unpacking libexpat1:amd64 (2.2.5-3ubuntu0.2) ...
Selecting previously unselected package python3.6-minimal.
Preparing to unpack .../python3.6-minimal_3.6.9-1~18.04_amd64.deb ...
Unpacking python3.6-minimal (3.6.9-1~18.04) ...
Setting up libpython3.6-minimal:amd64 (3.6.9-1~18.04) ...
Setting up libexpat1:amd64 (2.2.5-3ubuntu0.2) ...
Setting up python3.6-minimal (3.6.9-1~18.04) ...
Selecting previously unselected package python3-minimal.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 5096 files and directories currently installed.)
Preparing to unpack .../0-python3-minimal_3.6.7-1~18.04_amd64.deb ...
Unpacking python3-minimal (3.6.7-1~18.04) ...
Selecting previously unselected package mime-support.
Preparing to unpack .../1-mime-support_3.60ubuntu1_all.deb ...
Unpacking mime-support (3.60ubuntu1) ...
Selecting previously unselected package libmpdec2:amd64.
Preparing to unpack .../2-libmpdec2_2.4.2-1ubuntu1_amd64.deb ...
Unpacking libmpdec2:amd64 (2.4.2-1ubuntu1) ...
Selecting previously unselected package libpython3.6-stdlib:amd64.
Preparing to unpack .../3-libpython3.6-stdlib_3.6.9-1~18.04_amd64.deb ...
Unpacking libpython3.6-stdlib:amd64 (3.6.9-1~18.04) ...
Selecting previously unselected package python3.6.
Preparing to unpack .../4-python3.6_3.6.9-1~18.04_amd64.deb ...
Unpacking python3.6 (3.6.9-1~18.04) ...
Selecting previously unselected package libpython3-stdlib:amd64.
Preparing to unpack .../5-libpython3-stdlib_3.6.7-1~18.04_amd64.deb ...
Unpacking libpython3-stdlib:amd64 (3.6.7-1~18.04) ...
Setting up python3-minimal (3.6.7-1~18.04) ...
Selecting previously unselected package python3.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 5526 files and directories currently installed.)
Preparing to unpack .../0-python3_3.6.7-1~18.04_amd64.deb ...
Unpacking python3 (3.6.7-1~18.04) ...
Selecting previously unselected package perl-modules-5.26.
Preparing to unpack .../1-perl-modules-5.26_5.26.1-6ubuntu0.3_all.deb ...
Unpacking perl-modules-5.26 (5.26.1-6ubuntu0.3) ...
Selecting previously unselected package libgdbm5:amd64.
Preparing to unpack .../2-libgdbm5_1.14.1-6_amd64.deb ...
Unpacking libgdbm5:amd64 (1.14.1-6) ...
Selecting previously unselected package libgdbm-compat4:amd64.
Preparing to unpack .../3-libgdbm-compat4_1.14.1-6_amd64.deb ...
Unpacking libgdbm-compat4:amd64 (1.14.1-6) ...
Selecting previously unselected package libperl5.26:amd64.
Preparing to unpack .../4-libperl5.26_5.26.1-6ubuntu0.3_amd64.deb ...
Unpacking libperl5.26:amd64 (5.26.1-6ubuntu0.3) ...
Selecting previously unselected package perl.
Preparing to unpack .../5-perl_5.26.1-6ubuntu0.3_amd64.deb ...
Unpacking perl (5.26.1-6ubuntu0.3) ...
Preparing to unpack .../6-gcc-8-base_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking gcc-8-base:amd64 (8.4.0-1ubuntu1~18.04) over (8.3.0-6ubuntu1~18.04.1) ...
Setting up gcc-8-base:amd64 (8.4.0-1ubuntu1~18.04) ...
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 7469 files and directories currently installed.)
Preparing to unpack .../libstdc++6_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking libstdc++6:amd64 (8.4.0-1ubuntu1~18.04) over (8.3.0-6ubuntu1~18.04.1) ...
Setting up libstdc++6:amd64 (8.4.0-1ubuntu1~18.04) ...
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 7469 files and directories currently installed.)
Preparing to unpack .../libgcc1_1%3a8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking libgcc1:amd64 (1:8.4.0-1ubuntu1~18.04) over (1:8.3.0-6ubuntu1~18.04.1) ...
Setting up libgcc1:amd64 (1:8.4.0-1ubuntu1~18.04) ...
Selecting previously unselected package libapparmor1:amd64.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 7469 files and directories currently installed.)
Preparing to unpack .../00-libapparmor1_2.12-4ubuntu5.1_amd64.deb ...
Unpacking libapparmor1:amd64 (2.12-4ubuntu5.1) ...
Selecting previously unselected package libdbus-1-3:amd64.
Preparing to unpack .../01-libdbus-1-3_1.12.2-1ubuntu1.1_amd64.deb ...
Unpacking libdbus-1-3:amd64 (1.12.2-1ubuntu1.1) ...
Selecting previously unselected package dbus.
Preparing to unpack .../02-dbus_1.12.2-1ubuntu1.1_amd64.deb ...
Unpacking dbus (1.12.2-1ubuntu1.1) ...
Selecting previously unselected package libmagic-mgc.
Preparing to unpack .../03-libmagic-mgc_1%3a5.32-2ubuntu0.3_amd64.deb ...
Unpacking libmagic-mgc (1:5.32-2ubuntu0.3) ...
Selecting previously unselected package libmagic1:amd64.
Preparing to unpack .../04-libmagic1_1%3a5.32-2ubuntu0.3_amd64.deb ...
Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.3) ...
Selecting previously unselected package file.
Preparing to unpack .../05-file_1%3a5.32-2ubuntu0.3_amd64.deb ...
Unpacking file (1:5.32-2ubuntu0.3) ...
Selecting previously unselected package libglib2.0-0:amd64.
Preparing to unpack .../06-libglib2.0-0_2.56.4-0ubuntu0.18.04.6_amd64.deb ...
Unpacking libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.6) ...
Selecting previously unselected package libgirepository-1.0-1:amd64.
Preparing to unpack .../07-libgirepository-1.0-1_1.56.1-1_amd64.deb ...
Unpacking libgirepository-1.0-1:amd64 (1.56.1-1) ...
Selecting previously unselected package gir1.2-glib-2.0:amd64.
Preparing to unpack .../08-gir1.2-glib-2.0_1.56.1-1_amd64.deb ...
Unpacking gir1.2-glib-2.0:amd64 (1.56.1-1) ...
Selecting previously unselected package libglib2.0-data.
Preparing to unpack .../09-libglib2.0-data_2.56.4-0ubuntu0.18.04.6_all.deb ...
Unpacking libglib2.0-data (2.56.4-0ubuntu0.18.04.6) ...
Selecting previously unselected package libicu60:amd64.
Preparing to unpack .../10-libicu60_60.2-3ubuntu3.1_amd64.deb ...
Unpacking libicu60:amd64 (60.2-3ubuntu3.1) ...
Selecting previously unselected package libxml2:amd64.
Preparing to unpack .../11-libxml2_2.9.4+dfsg1-6.1ubuntu1.3_amd64.deb ...
Unpacking libxml2:amd64 (2.9.4+dfsg1-6.1ubuntu1.3) ...
Selecting previously unselected package netbase.
Preparing to unpack .../12-netbase_5.4_all.deb ...
Unpacking netbase (5.4) ...
Selecting previously unselected package python3-dbus.
Preparing to unpack .../13-python3-dbus_1.2.6-1_amd64.deb ...
Unpacking python3-dbus (1.2.6-1) ...
Selecting previously unselected package python3-gi.
Preparing to unpack .../14-python3-gi_3.26.1-2ubuntu1_amd64.deb ...
Unpacking python3-gi (3.26.1-2ubuntu1) ...
Selecting previously unselected package shared-mime-info.
Preparing to unpack .../15-shared-mime-info_1.9-2_amd64.deb ...
Unpacking shared-mime-info (1.9-2) ...
Selecting previously unselected package xdg-user-dirs.
Preparing to unpack .../16-xdg-user-dirs_0.17-1ubuntu1_amd64.deb ...
Unpacking xdg-user-dirs (0.17-1ubuntu1) ...
Selecting previously unselected package xz-utils.
Preparing to unpack .../17-xz-utils_5.2.2-1.3_amd64.deb ...
Unpacking xz-utils (5.2.2-1.3) ...
Selecting previously unselected package manpages.
Preparing to unpack .../18-manpages_4.15-1_all.deb ...
Unpacking manpages (4.15-1) ...
Selecting previously unselected package binutils-common:amd64.
Preparing to unpack .../19-binutils-common_2.30-21ubuntu1~18.04.2_amd64.deb ...
Unpacking binutils-common:amd64 (2.30-21ubuntu1~18.04.2) ...
Selecting previously unselected package libbinutils:amd64.
Preparing to unpack .../20-libbinutils_2.30-21ubuntu1~18.04.2_amd64.deb ...
Unpacking libbinutils:amd64 (2.30-21ubuntu1~18.04.2) ...
Selecting previously unselected package binutils-x86-64-linux-gnu.
Preparing to unpack .../21-binutils-x86-64-linux-gnu_2.30-21ubuntu1~18.04.2_amd64.deb ...
Unpacking binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.2) ...
Selecting previously unselected package binutils.
Preparing to unpack .../22-binutils_2.30-21ubuntu1~18.04.2_amd64.deb ...
Unpacking binutils (2.30-21ubuntu1~18.04.2) ...
Selecting previously unselected package libc-dev-bin.
Preparing to unpack .../23-libc-dev-bin_2.27-3ubuntu1_amd64.deb ...
Unpacking libc-dev-bin (2.27-3ubuntu1) ...
Selecting previously unselected package linux-libc-dev:amd64.
Preparing to unpack .../24-linux-libc-dev_4.15.0-96.97_amd64.deb ...
Unpacking linux-libc-dev:amd64 (4.15.0-96.97) ...
Selecting previously unselected package libc6-dev:amd64.
Preparing to unpack .../25-libc6-dev_2.27-3ubuntu1_amd64.deb ...
Unpacking libc6-dev:amd64 (2.27-3ubuntu1) ...
Selecting previously unselected package gcc-7-base:amd64.
Preparing to unpack .../26-gcc-7-base_7.5.0-3ubuntu1~18.04_amd64.deb ...
Unpacking gcc-7-base:amd64 (7.5.0-3ubuntu1~18.04) ...
Selecting previously unselected package libisl19:amd64.
Preparing to unpack .../27-libisl19_0.19-1_amd64.deb ...
Unpacking libisl19:amd64 (0.19-1) ...
Selecting previously unselected package libmpfr6:amd64.
Preparing to unpack .../28-libmpfr6_4.0.1-1_amd64.deb ...
Unpacking libmpfr6:amd64 (4.0.1-1) ...
Selecting previously unselected package libmpc3:amd64.
Preparing to unpack .../29-libmpc3_1.1.0-1_amd64.deb ...
Unpacking libmpc3:amd64 (1.1.0-1) ...
Selecting previously unselected package cpp-7.
Preparing to unpack .../30-cpp-7_7.5.0-3ubuntu1~18.04_amd64.deb ...
Unpacking cpp-7 (7.5.0-3ubuntu1~18.04) ...
Selecting previously unselected package cpp.
Preparing to unpack .../31-cpp_4%3a7.4.0-1ubuntu2.3_amd64.deb ...
Unpacking cpp (4:7.4.0-1ubuntu2.3) ...
Selecting previously unselected package libcc1-0:amd64.
Preparing to unpack .../32-libcc1-0_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking libcc1-0:amd64 (8.4.0-1ubuntu1~18.04) ...
Selecting previously unselected package libgomp1:amd64.
Preparing to unpack .../33-libgomp1_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking libgomp1:amd64 (8.4.0-1ubuntu1~18.04) ...
Selecting previously unselected package libitm1:amd64.
Preparing to unpack .../34-libitm1_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking libitm1:amd64 (8.4.0-1ubuntu1~18.04) ...
Selecting previously unselected package libatomic1:amd64.
Preparing to unpack .../35-libatomic1_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking libatomic1:amd64 (8.4.0-1ubuntu1~18.04) ...
Selecting previously unselected package libasan4:amd64.
Preparing to unpack .../36-libasan4_7.5.0-3ubuntu1~18.04_amd64.deb ...
Unpacking libasan4:amd64 (7.5.0-3ubuntu1~18.04) ...
Selecting previously unselected package liblsan0:amd64.
Preparing to unpack .../37-liblsan0_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking liblsan0:amd64 (8.4.0-1ubuntu1~18.04) ...
Selecting previously unselected package libtsan0:amd64.
Preparing to unpack .../38-libtsan0_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking libtsan0:amd64 (8.4.0-1ubuntu1~18.04) ...
Selecting previously unselected package libubsan0:amd64.
Preparing to unpack .../39-libubsan0_7.5.0-3ubuntu1~18.04_amd64.deb ...
Unpacking libubsan0:amd64 (7.5.0-3ubuntu1~18.04) ...
Selecting previously unselected package libcilkrts5:amd64.
Preparing to unpack .../40-libcilkrts5_7.5.0-3ubuntu1~18.04_amd64.deb ...
Unpacking libcilkrts5:amd64 (7.5.0-3ubuntu1~18.04) ...
Selecting previously unselected package libmpx2:amd64.
Preparing to unpack .../41-libmpx2_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking libmpx2:amd64 (8.4.0-1ubuntu1~18.04) ...
Selecting previously unselected package libquadmath0:amd64.
Preparing to unpack .../42-libquadmath0_8.4.0-1ubuntu1~18.04_amd64.deb ...
Unpacking libquadmath0:amd64 (8.4.0-1ubuntu1~18.04) ...
Selecting previously unselected package libgcc-7-dev:amd64.
Preparing to unpack .../43-libgcc-7-dev_7.5.0-3ubuntu1~18.04_amd64.deb ...
Unpacking libgcc-7-dev:amd64 (7.5.0-3ubuntu1~18.04) ...
Selecting previously unselected package gcc-7.
Preparing to unpack .../44-gcc-7_7.5.0-3ubuntu1~18.04_amd64.deb ...
Unpacking gcc-7 (7.5.0-3ubuntu1~18.04) ...
Selecting previously unselected package gcc.
Preparing to unpack .../45-gcc_4%3a7.4.0-1ubuntu2.3_amd64.deb ...
Unpacking gcc (4:7.4.0-1ubuntu2.3) ...
Selecting previously unselected package libstdc++-7-dev:amd64.
Preparing to unpack .../46-libstdc++-7-dev_7.5.0-3ubuntu1~18.04_amd64.deb ...
Unpacking libstdc++-7-dev:amd64 (7.5.0-3ubuntu1~18.04) ...
Selecting previously unselected package g++-7.
Preparing to unpack .../47-g++-7_7.5.0-3ubuntu1~18.04_amd64.deb ...
Unpacking g++-7 (7.5.0-3ubuntu1~18.04) ...
Selecting previously unselected package g++.
Preparing to unpack .../48-g++_4%3a7.4.0-1ubuntu2.3_amd64.deb ...
Unpacking g++ (4:7.4.0-1ubuntu2.3) ...
Selecting previously unselected package make.
Preparing to unpack .../49-make_4.1-9.1ubuntu1_amd64.deb ...
Unpacking make (4.1-9.1ubuntu1) ...
Selecting previously unselected package libdpkg-perl.
Preparing to unpack .../50-libdpkg-perl_1.19.0.5ubuntu2.3_all.deb ...
Unpacking libdpkg-perl (1.19.0.5ubuntu2.3) ...
Selecting previously unselected package patch.
Preparing to unpack .../51-patch_2.7.6-2ubuntu1.1_amd64.deb ...
Unpacking patch (2.7.6-2ubuntu1.1) ...
Selecting previously unselected package dpkg-dev.
Preparing to unpack .../52-dpkg-dev_1.19.0.5ubuntu2.3_all.deb ...
Unpacking dpkg-dev (1.19.0.5ubuntu2.3) ...
Selecting previously unselected package build-essential.
Preparing to unpack .../53-build-essential_12.4ubuntu1_amd64.deb ...
Unpacking build-essential (12.4ubuntu1) ...
Selecting previously unselected package python3-lib2to3.
Preparing to unpack .../54-python3-lib2to3_3.6.9-1~18.04_all.deb ...
Unpacking python3-lib2to3 (3.6.9-1~18.04) ...
Selecting previously unselected package python3-distutils.
Preparing to unpack .../55-python3-distutils_3.6.9-1~18.04_all.deb ...
Unpacking python3-distutils (3.6.9-1~18.04) ...
Selecting previously unselected package dh-python.
Preparing to unpack .../56-dh-python_3.20180325ubuntu2_all.deb ...
Unpacking dh-python (3.20180325ubuntu2) ...
Selecting previously unselected package libfakeroot:amd64.
Preparing to unpack .../57-libfakeroot_1.22-2ubuntu1_amd64.deb ...
Unpacking libfakeroot:amd64 (1.22-2ubuntu1) ...
Selecting previously unselected package fakeroot.
Preparing to unpack .../58-fakeroot_1.22-2ubuntu1_amd64.deb ...
Unpacking fakeroot (1.22-2ubuntu1) ...
Selecting previously unselected package libalgorithm-diff-perl.
Preparing to unpack .../59-libalgorithm-diff-perl_1.19.03-1_all.deb ...
Unpacking libalgorithm-diff-perl (1.19.03-1) ...
Selecting previously unselected package libalgorithm-diff-xs-perl.
Preparing to unpack .../60-libalgorithm-diff-xs-perl_0.04-5_amd64.deb ...
Unpacking libalgorithm-diff-xs-perl (0.04-5) ...
Selecting previously unselected package libalgorithm-merge-perl.
Preparing to unpack .../61-libalgorithm-merge-perl_0.08-3_all.deb ...
Unpacking libalgorithm-merge-perl (0.08-3) ...
Selecting previously unselected package libexpat1-dev:amd64.
Preparing to unpack .../62-libexpat1-dev_2.2.5-3ubuntu0.2_amd64.deb ...
Unpacking libexpat1-dev:amd64 (2.2.5-3ubuntu0.2) ...
Selecting previously unselected package libfile-fcntllock-perl.
Preparing to unpack .../63-libfile-fcntllock-perl_0.22-3build2_amd64.deb ...
Unpacking libfile-fcntllock-perl (0.22-3build2) ...
Selecting previously unselected package libpython3.6:amd64.
Preparing to unpack .../64-libpython3.6_3.6.9-1~18.04_amd64.deb ...
Unpacking libpython3.6:amd64 (3.6.9-1~18.04) ...
Selecting previously unselected package libpython3.6-dev:amd64.
Preparing to unpack .../65-libpython3.6-dev_3.6.9-1~18.04_amd64.deb ...
Unpacking libpython3.6-dev:amd64 (3.6.9-1~18.04) ...
Selecting previously unselected package libpython3-dev:amd64.
Preparing to unpack .../66-libpython3-dev_3.6.7-1~18.04_amd64.deb ...
Unpacking libpython3-dev:amd64 (3.6.7-1~18.04) ...
Selecting previously unselected package manpages-dev.
Preparing to unpack .../67-manpages-dev_4.15-1_all.deb ...
Unpacking manpages-dev (4.15-1) ...
Selecting previously unselected package python-pip-whl.
Preparing to unpack .../68-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...
Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...
Selecting previously unselected package python3-asn1crypto.
Preparing to unpack .../69-python3-asn1crypto_0.24.0-1_all.deb ...
Unpacking python3-asn1crypto (0.24.0-1) ...
Selecting previously unselected package python3-cffi-backend.
Preparing to unpack .../70-python3-cffi-backend_1.11.5-1_amd64.deb ...
Unpacking python3-cffi-backend (1.11.5-1) ...
Selecting previously unselected package python3-crypto.
Preparing to unpack .../71-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...
Unpacking python3-crypto (2.6.1-8ubuntu2) ...
Selecting previously unselected package python3-idna.
Preparing to unpack .../72-python3-idna_2.6-1_all.deb ...
Unpacking python3-idna (2.6-1) ...
Selecting previously unselected package python3-six.
Preparing to unpack .../73-python3-six_1.11.0-2_all.deb ...
Unpacking python3-six (1.11.0-2) ...
Selecting previously unselected package python3-cryptography.
Preparing to unpack .../74-python3-cryptography_2.1.4-1ubuntu1.3_amd64.deb ...
Unpacking python3-cryptography (2.1.4-1ubuntu1.3) ...
Selecting previously unselected package python3.6-dev.
Preparing to unpack .../75-python3.6-dev_3.6.9-1~18.04_amd64.deb ...
Unpacking python3.6-dev (3.6.9-1~18.04) ...
Selecting previously unselected package python3-dev.
Preparing to unpack .../76-python3-dev_3.6.7-1~18.04_amd64.deb ...
Unpacking python3-dev (3.6.7-1~18.04) ...
Selecting previously unselected package python3-secretstorage.
Preparing to unpack .../77-python3-secretstorage_2.3.1-2_all.deb ...
Unpacking python3-secretstorage (2.3.1-2) ...
Selecting previously unselected package python3-keyring.
Preparing to unpack .../78-python3-keyring_10.6.0-1_all.deb ...
Unpacking python3-keyring (10.6.0-1) ...
Selecting previously unselected package python3-keyrings.alt.
Preparing to unpack .../79-python3-keyrings.alt_3.0-1_all.deb ...
Unpacking python3-keyrings.alt (3.0-1) ...
Selecting previously unselected package python3-pip.
Preparing to unpack .../80-python3-pip_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...
Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.1) ...
Selecting previously unselected package python3-pkg-resources.
Preparing to unpack .../81-python3-pkg-resources_39.0.1-2_all.deb ...
Unpacking python3-pkg-resources (39.0.1-2) ...
Selecting previously unselected package python3-setuptools.
Preparing to unpack .../82-python3-setuptools_39.0.1-2_all.deb ...
Unpacking python3-setuptools (39.0.1-2) ...
Selecting previously unselected package python3-wheel.
Preparing to unpack .../83-python3-wheel_0.30.0-0.2_all.deb ...
Unpacking python3-wheel (0.30.0-0.2) ...
Selecting previously unselected package python3-xdg.
Preparing to unpack .../84-python3-xdg_0.25-4ubuntu1_all.deb ...
Unpacking python3-xdg (0.25-4ubuntu1) ...
Setting up libquadmath0:amd64 (8.4.0-1ubuntu1~18.04) ...
Setting up libgomp1:amd64 (8.4.0-1ubuntu1~18.04) ...
Setting up libatomic1:amd64 (8.4.0-1ubuntu1~18.04) ...
Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...
Setting up manpages (4.15-1) ...
Setting up libicu60:amd64 (60.2-3ubuntu3.1) ...
Setting up libcc1-0:amd64 (8.4.0-1ubuntu1~18.04) ...
Setting up make (4.1-9.1ubuntu1) ...
Setting up mime-support (3.60ubuntu1) ...
Setting up libtsan0:amd64 (8.4.0-1ubuntu1~18.04) ...
Setting up libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.6) ...
No schema files found: doing nothing.
Setting up linux-libc-dev:amd64 (4.15.0-96.97) ...
Setting up libmpfr6:amd64 (4.0.1-1) ...
Setting up perl-modules-5.26 (5.26.1-6ubuntu0.3) ...
Setting up libgdbm5:amd64 (1.14.1-6) ...
Setting up libgirepository-1.0-1:amd64 (1.56.1-1) ...
Setting up libxml2:amd64 (2.9.4+dfsg1-6.1ubuntu1.3) ...
Setting up libmagic-mgc (1:5.32-2ubuntu0.3) ...
Setting up libmagic1:amd64 (1:5.32-2ubuntu0.3) ...
Setting up liblsan0:amd64 (8.4.0-1ubuntu1~18.04) ...
Setting up gcc-7-base:amd64 (7.5.0-3ubuntu1~18.04) ...
Setting up binutils-common:amd64 (2.30-21ubuntu1~18.04.2) ...
Setting up libmpx2:amd64 (8.4.0-1ubuntu1~18.04) ...
Setting up gir1.2-glib-2.0:amd64 (1.56.1-1) ...
Setting up patch (2.7.6-2ubuntu1.1) ...
Setting up libglib2.0-data (2.56.4-0ubuntu0.18.04.6) ...
Setting up libapparmor1:amd64 (2.12-4ubuntu5.1) ...
Setting up xz-utils (5.2.2-1.3) ...
update-alternatives: using /usr/bin/xz to provide /usr/bin/lzma (lzma) in auto mode
update-alternatives: warning: skip creation of /usr/share/man/man1/lzma.1.gz because associated file /usr/share/man/man1/xz.1.gz (of link group lzma) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/unlzma.1.gz because associated file /usr/share/man/man1/unxz.1.gz (of link group lzma) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/lzcat.1.gz because associated file /usr/share/man/man1/xzcat.1.gz (of link group lzma) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/lzmore.1.gz because associated file /usr/share/man/man1/xzmore.1.gz (of link group lzma) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/lzless.1.gz because associated file /usr/share/man/man1/xzless.1.gz (of link group lzma) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/lzdiff.1.gz because associated file /usr/share/man/man1/xzdiff.1.gz (of link group lzma) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/lzcmp.1.gz because associated file /usr/share/man/man1/xzcmp.1.gz (of link group lzma) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/lzgrep.1.gz because associated file /usr/share/man/man1/xzgrep.1.gz (of link group lzma) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/lzegrep.1.gz because associated file /usr/share/man/man1/xzegrep.1.gz (of link group lzma) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/lzfgrep.1.gz because associated file /usr/share/man/man1/xzfgrep.1.gz (of link group lzma) doesn't exist
Setting up libfakeroot:amd64 (1.22-2ubuntu1) ...
Setting up liblocale-gettext-perl (1.07-3build2) ...
Setting up shared-mime-info (1.9-2) ...
Setting up libmpc3:amd64 (1.1.0-1) ...
Setting up libc-dev-bin (2.27-3ubuntu1) ...
Setting up libgdbm-compat4:amd64 (1.14.1-6) ...
Setting up manpages-dev (4.15-1) ...
Setting up libc6-dev:amd64 (2.27-3ubuntu1) ...
Setting up xdg-user-dirs (0.17-1ubuntu1) ...
Setting up libitm1:amd64 (8.4.0-1ubuntu1~18.04) ...
Setting up libmpdec2:amd64 (2.4.2-1ubuntu1) ...
Setting up libdbus-1-3:amd64 (1.12.2-1ubuntu1.1) ...
Setting up netbase (5.4) ...
Setting up libisl19:amd64 (0.19-1) ...
Setting up libpython3.6-stdlib:amd64 (3.6.9-1~18.04) ...
Setting up python3.6 (3.6.9-1~18.04) ...
Setting up libasan4:amd64 (7.5.0-3ubuntu1~18.04) ...
Setting up libbinutils:amd64 (2.30-21ubuntu1~18.04.2) ...
Setting up libcilkrts5:amd64 (7.5.0-3ubuntu1~18.04) ...
Setting up libubsan0:amd64 (7.5.0-3ubuntu1~18.04) ...
Setting up file (1:5.32-2ubuntu0.3) ...
Setting up fakeroot (1.22-2ubuntu1) ...
update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode
update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist
update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist
Setting up libgcc-7-dev:amd64 (7.5.0-3ubuntu1~18.04) ...
Setting up cpp-7 (7.5.0-3ubuntu1~18.04) ...
Setting up libstdc++-7-dev:amd64 (7.5.0-3ubuntu1~18.04) ...
Setting up libperl5.26:amd64 (5.26.1-6ubuntu0.3) ...
Setting up libexpat1-dev:amd64 (2.2.5-3ubuntu0.2) ...
Setting up dbus (1.12.2-1ubuntu1.1) ...
Setting up libpython3.6:amd64 (3.6.9-1~18.04) ...
Setting up binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.2) ...
Setting up libpython3-stdlib:amd64 (3.6.7-1~18.04) ...
Setting up cpp (4:7.4.0-1ubuntu2.3) ...
Setting up python3 (3.6.7-1~18.04) ...
running python rtupdate hooks for python3.6...
running python post-rtupdate hooks for python3.6...
Setting up python3-cffi-backend (1.11.5-1) ...
Setting up python3-crypto (2.6.1-8ubuntu2) ...
Setting up python3-idna (2.6-1) ...
Setting up python3-xdg (0.25-4ubuntu1) ...
Setting up python3-six (1.11.0-2) ...
Setting up python3-wheel (0.30.0-0.2) ...
Setting up python3-pkg-resources (39.0.1-2) ...
Setting up python3-gi (3.26.1-2ubuntu1) ...
Setting up libpython3.6-dev:amd64 (3.6.9-1~18.04) ...
Setting up perl (5.26.1-6ubuntu0.3) ...
Setting up python3-asn1crypto (0.24.0-1) ...
Setting up libfile-fcntllock-perl (0.22-3build2) ...
Setting up libalgorithm-diff-perl (1.19.03-1) ...
Setting up binutils (2.30-21ubuntu1~18.04.2) ...
Setting up python3.6-dev (3.6.9-1~18.04) ...
Setting up python3-lib2to3 (3.6.9-1~18.04) ...
Setting up python3-distutils (3.6.9-1~18.04) ...
Setting up libpython3-dev:amd64 (3.6.7-1~18.04) ...
Setting up python3-cryptography (2.1.4-1ubuntu1.3) ...
Setting up python3-dbus (1.2.6-1) ...
Setting up gcc-7 (7.5.0-3ubuntu1~18.04) ...
Setting up g++-7 (7.5.0-3ubuntu1~18.04) ...
Setting up python3-keyrings.alt (3.0-1) ...
Setting up libdpkg-perl (1.19.0.5ubuntu2.3) ...
Setting up gcc (4:7.4.0-1ubuntu2.3) ...
Setting up libalgorithm-merge-perl (0.08-3) ...
Setting up dpkg-dev (1.19.0.5ubuntu2.3) ...
Setting up libalgorithm-diff-xs-perl (0.04-5) ...
Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.1) ...
Setting up g++ (4:7.4.0-1ubuntu2.3) ...
update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode
update-alternatives: warning: skip creation of /usr/share/man/man1/c++.1.gz because associated file /usr/share/man/man1/g++.1.gz (of link group c++) doesn't exist
Setting up python3-setuptools (39.0.1-2) ...
Setting up python3-secretstorage (2.3.1-2) ...
Setting up dh-python (3.20180325ubuntu2) ...
Setting up python3-keyring (10.6.0-1) ...
Setting up build-essential (12.4ubuntu1) ...
Setting up python3-dev (3.6.7-1~18.04) ...
Processing triggers for libc-bin (2.27-3ubuntu1) ...
Removing intermediate container 1a24b1174564
 ---> e424d93af068
Step 4/10 : RUN mkdir microservice
 ---> Running in 38a2ee9e9837
Removing intermediate container 38a2ee9e9837
 ---> 5a6d1c857850
Step 5/10 : WORKDIR /microservice
 ---> Running in 017cc3730bc3
Removing intermediate container 017cc3730bc3
 ---> 7ff9d4a9d00b
Step 6/10 : COPY ./s2i/bin/ /s2i/bin
 ---> ee83cd90e33d
Step 7/10 : COPY requirements_gpu.txt ./requirements.txt
 ---> 9266ede80596
Step 8/10 : COPY _python/python/licenses/license.txt .
 ---> 261dd2d7fb5e
Step 9/10 : RUN pip3 install -r requirements.txt
 ---> Running in 4bd8f6fba1db
Collecting seldon-core==0.5.1 (from -r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/a7/5e/a55ff47468cc11aac0136b84af92a15133947d4dba75774ce439078d60d9/seldon_core-0.5.1-py3-none-any.whl (60kB)
Collecting tensorflow-gpu==1.13.1 (from -r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)
Collecting numpy==1.16.1 (from -r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)
Collecting azure-storage-blob<3.0.0,>=2.0.1 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/3e/84/610f379b46d7d3c2d48eadeed6a12b6d46a43100fea70534f5992d0ac996/azure_storage_blob-2.1.0-py2.py3-none-any.whl (88kB)
Collecting grpcio-opentracing<1.2.0,>=1.1.4 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/db/82/2fcad380697c3dab25de76ee590bcab3eb9bbfb4add916044d7e83ec2b10/grpcio_opentracing-1.1.4-py3-none-any.whl
Collecting requests<3.0.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)
Collecting minio<6.0.0,>=4.0.9 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/8f/ed/8670995efca990a8b6473f24331fcc40e61b59a00fe31e6e266b667f4866/minio-5.0.8-py2.py3-none-any.whl (73kB)
Collecting gunicorn<20.1.0,>=19.9.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)
Collecting opentracing<2.3.0,>=2.2.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/94/9f/289424136addf621fb4c75624ef9a3a80e8575da3993a87950c57e93217e/opentracing-2.2.0.tar.gz (47kB)
Collecting redis<4.0.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)
Collecting grpcio<2.0.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/cf/7a/9744998129fce7e29c5f2d8b0f545913b7383e65d8366fc0ae98d11936af/grpcio-1.28.1.tar.gz (19.5MB)
Collecting Flask-cors<4.0.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl
Collecting flatbuffers<2.0.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl
Collecting Flask-OpenTracing<1.2.0,>=1.1.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/58/6c/6417701ba5ecc8854670c6db3207bcc3e5fbc96289a7cb18d5516d99a1c6/Flask-OpenTracing-1.1.0.tar.gz
Collecting jaeger-client<4.2.0,>=4.1.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/f1/da/569a4f1bc3d0c412c7f903053f09ef62fa10949374ca90bc852b22dd3860/jaeger-client-4.1.0.tar.gz (80kB)
Collecting setuptools>=41.0.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl (582kB)
Collecting pyaml<20.0.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/35/1e/eda9fe07f752ced7afcef590e7d74390f0d9c9c0b7ff98317afbaa0697e3/pyaml-19.12.0-py2.py3-none-any.whl
Collecting protobuf<4.0.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/57/02/5432412c162989260fab61fa65e0a490c1872739eb91a659896e4d554b26/protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)
Collecting Flask<2.0.0 (from seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl (94kB)
Collecting keras-preprocessing>=1.0.5 (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)
Collecting absl-py>=0.1.6 (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)
Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)
Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)
Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
Collecting gast>=0.2.0 (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl
Collecting termcolor>=1.1.0 (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz
Collecting astor>=0.6.0 (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl
Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
Collecting keras-applications>=1.0.6 (from tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)
Collecting azure-common>=1.1.5 (from azure-storage-blob<3.0.0,>=2.0.1->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/e5/4d/d000fc3c5af601d00d55750b71da5c231fcb128f42ac95b208ed1091c2c1/azure_common-1.1.25-py2.py3-none-any.whl
Collecting azure-storage-common~=2.1 (from azure-storage-blob<3.0.0,>=2.0.1->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/6b/a0/6794b318ce0118d1a4053bdf0149a60807407db9b710354f2b203c2f5975/azure_storage_common-2.1.0-py2.py3-none-any.whl (47kB)
Collecting certifi>=2017.4.17 (from requests<3.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/57/2b/26e37a4b034800c960a00c4e1b3d9ca5d7014e983e6e729e33ea2f36426c/certifi-2020.4.5.1-py2.py3-none-any.whl (157kB)
Collecting chardet<4,>=3.0.2 (from requests<3.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl (125kB)
Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
Collecting configparser (from minio<6.0.0,>=4.0.9->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl
Collecting pytz (from minio<6.0.0,>=4.0.9->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)
Collecting python-dateutil (from minio<6.0.0,>=4.0.9->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)
Collecting threadloop<2,>=1 (from jaeger-client<4.2.0,>=4.1.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/d3/1d/8398c1645b97dc008d3c658e04beda01ede3d90943d40c8d56863cf891bd/threadloop-1.0.2.tar.gz
Collecting thrift (from jaeger-client<4.2.0,>=4.1.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/97/1e/3284d19d7be99305eda145b8aa46b0c33244e4a496ec66440dac19f8274d/thrift-0.13.0.tar.gz (59kB)
Collecting tornado<6,>=4.3 (from jaeger-client<4.2.0,>=4.1.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/e6/78/6e7b5af12c12bdf38ca9bfe863fcaf53dc10430a312d0324e76c1e5ca426/tornado-5.1.1.tar.gz (516kB)
Collecting PyYAML (from pyaml<20.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)
Collecting Jinja2>=2.10.1 (from Flask<2.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/27/24/4f35961e5c669e96f6559760042a55b9bcfcdb82b9bdb3c8753dbe042e35/Jinja2-2.11.1-py2.py3-none-any.whl (126kB)
Collecting Werkzeug>=0.15 (from Flask<2.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)
Collecting itsdangerous>=0.24 (from Flask<2.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl
Collecting click>=5.1 (from Flask<2.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/dd/c0/4d8f43a9b16e289f36478422031b8a63b54b6ac3b1ba605d602f10dd54d6/click-7.1.1-py2.py3-none-any.whl (82kB)
Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)
Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl
Collecting h5py (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)
Requirement already satisfied: cryptography in /usr/lib/python3/dist-packages (from azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==0.5.1->-r requirements.txt (line 1))
Collecting MarkupSafe>=0.23 (from Jinja2>=2.10.1->Flask<2.0.0->seldon-core==0.5.1->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl
Building wheels for collected packages: opentracing, grpcio, Flask-OpenTracing, jaeger-client, absl-py, termcolor, threadloop, thrift, tornado, PyYAML
  Running setup.py bdist_wheel for opentracing: started
  Running setup.py bdist_wheel for opentracing: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/93/e9/b5/1cdc3544f99a54caca13832b5afa26fd98701fe709dc049576
  Running setup.py bdist_wheel for grpcio: started
  Running setup.py bdist_wheel for grpcio: still running...
  Running setup.py bdist_wheel for grpcio: still running...
  Running setup.py bdist_wheel for grpcio: still running...
  Running setup.py bdist_wheel for grpcio: still running...
  Running setup.py bdist_wheel for grpcio: still running...
  Running setup.py bdist_wheel for grpcio: still running...
  Running setup.py bdist_wheel for grpcio: still running...
  Running setup.py bdist_wheel for grpcio: still running...
  Running setup.py bdist_wheel for grpcio: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/00/4d/5f/07d0d4283911d2b917b867a11b1622d9d2cc8c286eefd10c33
  Running setup.py bdist_wheel for Flask-OpenTracing: started
  Running setup.py bdist_wheel for Flask-OpenTracing: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/7b/dc/25/3cf0b35c129232ee596c413f13d1d1f5a8e38c427266276dfd
  Running setup.py bdist_wheel for jaeger-client: started
  Running setup.py bdist_wheel for jaeger-client: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/f2/84/7f/e89da3ee8ce35598d6382b6389fa2ada5d66acca2422537994
  Running setup.py bdist_wheel for absl-py: started
  Running setup.py bdist_wheel for absl-py: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d
  Running setup.py bdist_wheel for termcolor: started
  Running setup.py bdist_wheel for termcolor: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6
  Running setup.py bdist_wheel for threadloop: started
  Running setup.py bdist_wheel for threadloop: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/d7/7a/30/d212623a4cd34f6cce400f8122b1b7af740d3440c68023d51f
  Running setup.py bdist_wheel for thrift: started
  Running setup.py bdist_wheel for thrift: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/02/a2/46/689ccfcf40155c23edc7cdbd9de488611c8fdf49ff34b1706e
  Running setup.py bdist_wheel for tornado: started
  Running setup.py bdist_wheel for tornado: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/6d/e1/ce/f4ee2fa420cc6b940123c64992b81047816d0a9fad6b879325
  Running setup.py bdist_wheel for PyYAML: started
  Running setup.py bdist_wheel for PyYAML: finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd
Successfully built opentracing grpcio Flask-OpenTracing jaeger-client absl-py termcolor threadloop thrift tornado PyYAML
Installing collected packages: azure-common, python-dateutil, certifi, chardet, urllib3, requests, azure-storage-common, azure-storage-blob, grpcio, opentracing, grpcio-opentracing, configparser, pytz, minio, setuptools, gunicorn, redis, MarkupSafe, Jinja2, Werkzeug, itsdangerous, click, Flask, Flask-cors, numpy, flatbuffers, Flask-OpenTracing, tornado, threadloop, thrift, jaeger-client, PyYAML, pyaml, protobuf, seldon-core, keras-preprocessing, absl-py, markdown, tensorboard, mock, tensorflow-estimator, gast, termcolor, astor, h5py, keras-applications, tensorflow-gpu
  Found existing installation: setuptools 39.0.1
    Not uninstalling setuptools at /usr/lib/python3/dist-packages, outside environment /usr
Successfully installed Flask-1.1.2 Flask-OpenTracing-1.1.0 Flask-cors-3.0.8 Jinja2-2.11.1 MarkupSafe-1.1.1 PyYAML-5.3.1 Werkzeug-1.0.1 absl-py-0.9.0 astor-0.8.1 azure-common-1.1.25 azure-storage-blob-2.1.0 azure-storage-common-2.1.0 certifi-2020.4.5.1 chardet-3.0.4 click-7.1.1 configparser-5.0.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.28.1 grpcio-opentracing-1.1.4 gunicorn-20.0.4 h5py-2.10.0 itsdangerous-1.1.0 jaeger-client-4.1.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 minio-5.0.8 mock-4.0.2 numpy-1.16.1 opentracing-2.2.0 protobuf-3.11.3 pyaml-19.12.0 python-dateutil-2.8.1 pytz-2019.3 redis-3.4.1 requests-2.23.0 seldon-core-0.5.1 setuptools-46.1.3 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1 termcolor-1.1.0 threadloop-1.0.2 thrift-0.13.0 tornado-5.1.1 urllib3-1.25.8
Removing intermediate container 4bd8f6fba1db
 ---> 16f051157a87
Step 10/10 : EXPOSE 5000
 ---> Running in 15a0ce716148
Removing intermediate container 15a0ce716148
 ---> 253f8b273e1c
Successfully built 253f8b273e1c
Successfully tagged seldonio/seldon-core-s2i-python3-tf-gpu:1.0.3-SNAPSHOT
make[1]: Leaving directory '/workspace/source/wrappers/s2i/python'
Files changed in operator folder:
operator/constants/constants.go
operator/controllers/seldondeployment_explainers.go
cd ../../operator && make kind-image-install
make[1]: Entering directory '/workspace/source/operator'
go: creating new go.mod: module tmp
go: finding sigs.k8s.io v0.2.5
go: finding sigs.k8s.io/controller-tools/cmd/controller-gen v0.2.5
go: finding sigs.k8s.io/controller-tools/cmd v0.2.5
go: finding sigs.k8s.io/controller-tools v0.2.5
go: downloading sigs.k8s.io/controller-tools v0.2.5
go: extracting sigs.k8s.io/controller-tools v0.2.5
go: downloading github.com/spf13/cobra v0.0.5
go: downloading github.com/fatih/color v1.7.0
go: downloading k8s.io/apimachinery v0.17.0
go: downloading github.com/gobuffalo/flect v0.2.0
go: downloading k8s.io/apiextensions-apiserver v0.17.0
go: downloading sigs.k8s.io/yaml v1.1.0
go: downloading k8s.io/api v0.17.0
go: extracting github.com/fatih/color v1.7.0
go: extracting sigs.k8s.io/yaml v1.1.0
go: downloading gopkg.in/yaml.v2 v2.2.4
go: extracting github.com/spf13/cobra v0.0.5
go: extracting github.com/gobuffalo/flect v0.2.0
go: downloading github.com/spf13/pflag v1.0.5
go: extracting gopkg.in/yaml.v2 v2.2.4
go: downloading github.com/inconshreveable/mousetrap v1.0.0
go: extracting github.com/spf13/pflag v1.0.5
go: extracting github.com/inconshreveable/mousetrap v1.0.0
go: downloading github.com/mattn/go-colorable v0.1.2
go: extracting k8s.io/apiextensions-apiserver v0.17.0
go: extracting github.com/mattn/go-colorable v0.1.2
go: downloading github.com/mattn/go-isatty v0.0.8
go: extracting github.com/mattn/go-isatty v0.0.8
go: downloading golang.org/x/sys v0.0.0-20190826190057-c7b8b68b1456
go: extracting k8s.io/apimachinery v0.17.0
go: downloading golang.org/x/tools v0.0.0-20190920225731-5eefd052ad72
go: downloading github.com/gogo/protobuf v1.2.2-0.20190723190241-65acae22fc9d
go: downloading k8s.io/klog v1.0.0
go: downloading gopkg.in/yaml.v3 v3.0.0-20190905181640-827449938966
go: downloading gopkg.in/inf.v0 v0.9.1
go: downloading k8s.io/utils v0.0.0-20191114184206-e782cd3c129f
go: extracting k8s.io/klog v1.0.0
go: extracting gopkg.in/inf.v0 v0.9.1
go: downloading github.com/google/gofuzz v1.0.0
go: downloading golang.org/x/net v0.0.0-20191004110552-13f9640d40b9
go: extracting gopkg.in/yaml.v3 v3.0.0-20190905181640-827449938966
go: extracting k8s.io/utils v0.0.0-20191114184206-e782cd3c129f
go: extracting github.com/google/gofuzz v1.0.0
go: extracting golang.org/x/sys v0.0.0-20190826190057-c7b8b68b1456
go: extracting golang.org/x/tools v0.0.0-20190920225731-5eefd052ad72
go: extracting k8s.io/api v0.17.0
go: extracting github.com/gogo/protobuf v1.2.2-0.20190723190241-65acae22fc9d
go: extracting golang.org/x/net v0.0.0-20191004110552-13f9640d40b9
go: downloading golang.org/x/text v0.3.2
go: extracting golang.org/x/text v0.3.2
go: finding github.com/spf13/cobra v0.0.5
go: finding k8s.io/api v0.17.0
go: finding k8s.io/apimachinery v0.17.0
go: finding github.com/fatih/color v1.7.0
go: finding golang.org/x/tools v0.0.0-20190920225731-5eefd052ad72
go: finding gopkg.in/yaml.v3 v3.0.0-20190905181640-827449938966
go: finding k8s.io/apiextensions-apiserver v0.17.0
go: finding github.com/gobuffalo/flect v0.2.0
go: finding sigs.k8s.io/yaml v1.1.0
go: finding github.com/mattn/go-colorable v0.1.2
go: finding github.com/gogo/protobuf v1.2.2-0.20190723190241-65acae22fc9d
go: finding github.com/google/gofuzz v1.0.0
go: finding github.com/mattn/go-isatty v0.0.8
go: finding gopkg.in/inf.v0 v0.9.1
go: finding github.com/spf13/pflag v1.0.5
go: finding k8s.io/klog v1.0.0
go: finding k8s.io/utils v0.0.0-20191114184206-e782cd3c129f
go: finding gopkg.in/yaml.v2 v2.2.4
go: finding golang.org/x/net v0.0.0-20191004110552-13f9640d40b9
go: finding golang.org/x/sys v0.0.0-20190826190057-c7b8b68b1456
go: finding golang.org/x/text v0.3.2
/builder/home/go/bin/controller-gen object:headerFile=./hack/boilerplate.go.txt paths="./..."
go fmt ./...
go vet ./...
go: downloading github.com/onsi/gomega v1.8.1
go: downloading github.com/onsi/ginkgo v1.11.0
go: downloading github.com/Azure/go-autorest/autorest v0.9.2
go: downloading github.com/gophercloud/gophercloud v0.4.0
go: extracting github.com/Azure/go-autorest/autorest v0.9.2
go: extracting github.com/onsi/gomega v1.8.1
go: downloading github.com/Azure/go-autorest/autorest/adal v0.7.0
go: extracting github.com/onsi/ginkgo v1.11.0
go: extracting github.com/Azure/go-autorest/autorest/adal v0.7.0
go: downloading github.com/dgrijalva/jwt-go v3.2.0+incompatible
go: downloading github.com/Azure/go-autorest/logger v0.1.0
go: downloading github.com/Azure/go-autorest/autorest/date v0.2.0
go: extracting github.com/dgrijalva/jwt-go v3.2.0+incompatible
go: downloading golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7
go: extracting github.com/Azure/go-autorest/logger v0.1.0
go: extracting github.com/Azure/go-autorest/autorest/date v0.2.0
go: downloading github.com/Azure/go-autorest/tracing v0.5.0
go: extracting golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7
go: extracting github.com/Azure/go-autorest/tracing v0.5.0
go: downloading github.com/hpcloud/tail v1.0.0
go: extracting github.com/hpcloud/tail v1.0.0
go: downloading gopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7
go: extracting gopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7
go: extracting github.com/gophercloud/gophercloud v0.4.0
/builder/home/go/bin/controller-gen "crd:trivialVersions=true" rbac:roleName=manager-role webhook paths="./..." output:crd:artifacts:config=config/crd/bases
rm -rf generated
mkdir generated
kustomize build config/default/ -o generated
cp generated/apiextensions.k8s.io_v1beta1_customresourcedefinition_seldondeployments.machinelearning.seldon.io.yaml testing/machinelearning.seldon.io_seldondeployments.yaml
go test ./controllers/... ./apis/...  -coverprofile cover.out
ok  	github.com/seldonio/seldon-core/operator/controllers	20.206s	coverage: 52.4% of statements
?   	github.com/seldonio/seldon-core/operator/controllers/resources/credentials	[no test files]
ok  	github.com/seldonio/seldon-core/operator/controllers/resources/credentials/gcs	0.012s	coverage: 100.0% of statements
ok  	github.com/seldonio/seldon-core/operator/controllers/resources/credentials/s3	0.012s	coverage: 94.6% of statements
ok  	github.com/seldonio/seldon-core/operator/apis/machinelearning.seldon.io/v1	0.024s	coverage: 37.8% of statements
?   	github.com/seldonio/seldon-core/operator/apis/machinelearning.seldon.io/v1alpha2	[no test files]
?   	github.com/seldonio/seldon-core/operator/apis/machinelearning.seldon.io/v1alpha3	[no test files]
docker build . -t seldonio/seldon-core-operator:1.0.3-SNAPSHOT
Sending build context to Docker daemon  3.127MB
Step 1/17 : FROM golang:1.13.2 as builder
1.13.2: Pulling from library/golang
c7b7d16361e0: Pulling fs layer
b7a128769df1: Pulling fs layer
1128949d0793: Pulling fs layer
667692510b70: Pulling fs layer
c70d80036479: Pulling fs layer
667692510b70: Waiting
a8669f8c1a42: Pulling fs layer
433331673060: Pulling fs layer
c70d80036479: Waiting
a8669f8c1a42: Waiting
b7a128769df1: Verifying Checksum
b7a128769df1: Download complete
1128949d0793: Verifying Checksum
1128949d0793: Download complete
c7b7d16361e0: Verifying Checksum
c7b7d16361e0: Download complete
667692510b70: Verifying Checksum
667692510b70: Download complete
433331673060: Verifying Checksum
433331673060: Download complete
c70d80036479: Verifying Checksum
c70d80036479: Download complete
a8669f8c1a42: Verifying Checksum
a8669f8c1a42: Download complete
c7b7d16361e0: Pull complete
b7a128769df1: Pull complete
1128949d0793: Pull complete
667692510b70: Pull complete
c70d80036479: Pull complete
a8669f8c1a42: Pull complete
433331673060: Pull complete
Digest: sha256:b3086f21bfbe896973dd6147b46f2736a7deb2c04ed76219835befa0244a9562
Status: Downloaded newer image for golang:1.13.2
 ---> e37698ff7351
Step 2/17 : WORKDIR /workspace
 ---> Running in 2f79aa9b1910
Removing intermediate container 2f79aa9b1910
 ---> a651ddc03e7c
Step 3/17 : COPY go.mod go.mod
 ---> 93aa384c236d
Step 4/17 : COPY go.sum go.sum
 ---> c397e81d9a18
Step 5/17 : RUN go mod download
 ---> Running in 22c43ca293ae
[91mgo: finding cloud.google.com/go v0.38.0
[0m[91mgo: finding github.com/Azure/go-ansiterm v0.0.0-20170929234023-d6e3b3328b78
[0m[91mgo: finding github.com/Azure/go-autorest/autorest v0.9.2
[0m[91mgo: finding github.com/Azure/go-autorest/autorest/adal v0.7.0
[0m[91mgo: finding github.com/Azure/go-autorest/autorest/date v0.2.0
[0m[91mgo: finding github.com/Azure/go-autorest/autorest/mocks v0.3.0
[0m[91mgo: finding github.com/Azure/go-autorest/logger v0.1.0
[0m[91mgo: finding github.com/Azure/go-autorest/tracing v0.5.0
[0m[91mgo: finding github.com/BurntSushi/toml v0.3.1
[0m[91mgo: finding github.com/BurntSushi/xgb v0.0.0-20160522181843-27f122750802
[0m[91mgo: finding github.com/NYTimes/gziphandler v0.0.0-20170623195520-56545f4a5d46
[0m[91mgo: finding github.com/PuerkitoBio/purell v1.1.1
[0m[91mgo: finding github.com/PuerkitoBio/urlesc v0.0.0-20170810143723-de5bf2ad4578
[0m[91mgo: finding github.com/agnivade/levenshtein v1.0.1
[0m[91mgo: finding github.com/alecthomas/template v0.0.0-20160405071501-a0175ee3bccc
[0m[91mgo: finding github.com/alecthomas/units v0.0.0-20151022065526-2efee857e7cf
[0m[91mgo: finding github.com/andreyvit/diff v0.0.0-20170406064948-c7f18ee00883
[0m[91mgo: finding github.com/armon/consul-api v0.0.0-20180202201655-eb2c6b5be1b6
[0m[91mgo: finding github.com/asaskevich/govalidator v0.0.0-20190424111038-f61b66f89f4a
[0m[91mgo: finding github.com/beorn7/perks v1.0.0
[0m[91mgo: finding github.com/bgentry/speakeasy v0.1.0
[0m[91mgo: finding github.com/blang/semver v3.5.0+incompatible
[0m[91mgo: finding github.com/client9/misspell v0.3.4
[0m[91mgo: finding github.com/cockroachdb/datadriven v0.0.0-20190809214429-80d97fb3cbaa
[0m[91mgo: finding github.com/coreos/etcd v3.3.10+incompatible
[0m[91mgo: finding github.com/coreos/go-etcd v2.0.0+incompatible
[0m[91mgo: finding github.com/coreos/go-oidc v2.1.0+incompatible
[0m[91mgo: finding github.com/coreos/go-semver v0.3.0
[0m[91mgo: finding github.com/coreos/go-systemd v0.0.0-20190321100706-95778dfbb74e
[0m[91mgo: finding github.com/coreos/pkg v0.0.0-20180108230652-97fdf19511ea
[0m[91mgo: finding github.com/cpuguy83/go-md2man v1.0.10
[0m[91mgo: finding github.com/creack/pty v1.1.7
[0m[91mgo: finding github.com/davecgh/go-spew v1.1.1
[0m[91mgo: finding github.com/dgrijalva/jwt-go v3.2.0+incompatible
[0m[91mgo: finding github.com/docker/docker v0.7.3-0.20190327010347-be7ac8be2ae0
[0m[91mgo: finding github.com/docker/go-units v0.4.0
[0m[91mgo: finding github.com/docker/spdystream v0.0.0-20160310174837-449fdfce4d96
[0m[91mgo: finding github.com/docopt/docopt-go v0.0.0-20180111231733-ee0de3bc6815
[0m[91mgo: finding github.com/dustin/go-humanize v1.0.0
[0m[91mgo: finding github.com/elazarl/goproxy v0.0.0-20170405201442-c4fc26588b6e
[0m[91mgo: finding github.com/emicklei/go-restful v2.9.5+incompatible
[0m[91mgo: finding github.com/evanphx/json-patch v4.5.0+incompatible
[0m[91mgo: finding github.com/fatih/color v1.7.0
[0m[91mgo: finding github.com/fsnotify/fsnotify v1.4.7
[0m[91mgo: finding github.com/ghodss/yaml v1.0.0
[0m[91mgo: finding github.com/globalsign/mgo v0.0.0-20181015135952-eeefdecb41b8
[0m[91mgo: finding github.com/go-kit/kit v0.8.0
[0m[91mgo: finding github.com/go-logfmt/logfmt v0.3.0
[0m[91mgo: finding github.com/go-logr/logr v0.1.0
[0m[91mgo: finding github.com/go-logr/zapr v0.1.0
[0m[91mgo: finding github.com/go-openapi/analysis v0.19.5
[0m[91mgo: finding github.com/go-openapi/errors v0.19.2
[0m[91mgo: finding github.com/go-openapi/jsonpointer v0.19.3
[0m[91mgo: finding github.com/go-openapi/jsonreference v0.19.3
[0m[91mgo: finding github.com/go-openapi/loads v0.19.4
[0m[91mgo: finding github.com/go-openapi/runtime v0.19.4
[0m[91mgo: finding github.com/go-openapi/spec v0.19.3
[0m[91mgo: finding github.com/go-openapi/strfmt v0.19.3
[0m[91mgo: finding github.com/go-openapi/swag v0.19.5
[0m[91mgo: finding github.com/go-openapi/validate v0.19.5
[0m[91mgo: finding github.com/go-stack/stack v1.8.0
[0m[91mgo: finding github.com/gogo/protobuf v1.3.1
[0m[91mgo: finding github.com/golang/glog v0.0.0-20160126235308-23def4e6c14b
[0m[91mgo: finding github.com/golang/groupcache v0.0.0-20190702054246-869f871628b6
[0m[91mgo: finding github.com/golang/mock v1.2.0
[0m[91mgo: finding github.com/golang/protobuf v1.3.2
[0m[91mgo: finding github.com/google/btree v1.0.0
[0m[91mgo: finding github.com/google/go-cmp v0.3.1
[0m[91mgo: finding github.com/google/gofuzz v1.0.0
[0m[91mgo: finding github.com/google/martian v2.1.0+incompatible
[0m[91mgo: finding github.com/google/pprof v0.0.0-20181206194817-3ea8567a2e57
[0m[91mgo: finding github.com/google/uuid v1.1.1
[0m[91mgo: finding github.com/googleapis/gax-go/v2 v2.0.4
[0m[91mgo: finding github.com/googleapis/gnostic v0.3.1
[0m[91mgo: finding github.com/gophercloud/gophercloud v0.4.0
[0m[91mgo: finding github.com/gorilla/websocket v1.4.0
[0m[91mgo: finding github.com/gregjones/httpcache v0.0.0-20180305231024-9cad4c3443a7
[0m[91mgo: finding github.com/grpc-ecosystem/go-grpc-middleware v1.0.1-0.20190118093823-f849b5445de4
[0m[91mgo: finding github.com/grpc-ecosystem/go-grpc-prometheus v1.2.0
[0m[91mgo: finding github.com/grpc-ecosystem/grpc-gateway v1.9.5
[0m[91mgo: finding github.com/hashicorp/golang-lru v0.5.4
[0m[91mgo: finding github.com/hashicorp/hcl v1.0.0
[0m[91mgo: finding github.com/hpcloud/tail v1.0.0
[0m[91mgo: finding github.com/imdario/mergo v0.3.7
[0m[91mgo: finding github.com/inconshreveable/mousetrap v1.0.0
[0m[91mgo: finding github.com/jonboulle/clockwork v0.1.0
[0m[91mgo: finding github.com/json-iterator/go v1.1.9
[0m[91mgo: finding github.com/jstemmer/go-junit-report v0.0.0-20190106144839-af01ea7f8024
[0m[91mgo: finding github.com/julienschmidt/httprouter v1.2.0
[0m[91mgo: finding github.com/kisielk/errcheck v1.2.0
[0m[91mgo: finding github.com/kisielk/gotool v1.0.0
[0m[91mgo: finding github.com/konsorten/go-windows-terminal-sequences v1.0.1
[0m[91mgo: finding github.com/kr/logfmt v0.0.0-20140226030751-b84e30acd515
[0m[91mgo: finding github.com/kr/pretty v0.1.0
[0m[91mgo: finding github.com/kr/pty v1.1.5
[0m[91mgo: finding github.com/kr/text v0.1.0
[0m[91mgo: finding github.com/magiconair/properties v1.8.0
[0m[91mgo: finding github.com/mailru/easyjson v0.7.0
[0m[91mgo: finding github.com/mattn/go-colorable v0.0.9
[0m[91mgo: finding github.com/mattn/go-isatty v0.0.4
[0m[91mgo: finding github.com/mattn/go-runewidth v0.0.2
[0m[91mgo: finding github.com/matttproud/golang_protobuf_extensions v1.0.1
[0m[91mgo: finding github.com/mitchellh/go-homedir v1.1.0
[0m[91mgo: finding github.com/mitchellh/mapstructure v1.1.2
[0m[91mgo: finding github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd
[0m[91mgo: finding github.com/modern-go/reflect2 v1.0.1
[0m[91mgo: finding github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822
[0m[91mgo: finding github.com/mwitkow/go-conntrack v0.0.0-20161129095857-cc309e4a2223
[0m[91mgo: finding github.com/mxk/go-flowrate v0.0.0-20140419014527-cca7078d478f
[0m[91mgo: finding github.com/olekukonko/tablewriter v0.0.0-20170122224234-a0225b3f23b5
[0m[91mgo: finding github.com/onsi/ginkgo v1.11.0
[0m[91mgo: finding github.com/onsi/gomega v1.8.1
[0m[91mgo: finding github.com/pborman/uuid v1.2.0
[0m[91mgo: finding github.com/pelletier/go-toml v1.2.0
[0m[91mgo: finding github.com/peterbourgon/diskv v2.0.1+incompatible
[0m[91mgo: finding github.com/pkg/errors v0.8.1
[0m[91mgo: finding github.com/pmezard/go-difflib v1.0.0
[0m[91mgo: finding github.com/pquerna/cachecontrol v0.0.0-20171018203845-0dec1b30a021
[0m[91mgo: finding github.com/prometheus/client_golang v1.0.0
[0m[91mgo: finding github.com/prometheus/client_model v0.0.0-20190129233127-fd36f4220a90
[0m[91mgo: finding github.com/prometheus/common v0.4.1
[0m[91mgo: finding github.com/prometheus/procfs v0.0.2
[0m[91mgo: finding github.com/remyoudompheng/bigfft v0.0.0-20170806203942-52369c62f446
[0m[91mgo: finding github.com/rogpeppe/fastuuid v0.0.0-20150106093220-6724a57986af
[0m[91mgo: finding github.com/russross/blackfriday v1.5.2
[0m[91mgo: finding github.com/sergi/go-diff v1.0.0
[0m[91mgo: finding github.com/sirupsen/logrus v1.4.2
[0m[91mgo: finding github.com/soheilhy/cmux v0.1.4
[0m[91mgo: finding github.com/spf13/afero v1.2.2
[0m[91mgo: finding github.com/spf13/cast v1.3.0
[0m[91mgo: finding github.com/spf13/cobra v0.0.5
[0m[91mgo: finding github.com/spf13/jwalterweatherman v1.0.0
[0m[91mgo: finding github.com/spf13/pflag v1.0.5
[0m[91mgo: finding github.com/spf13/viper v1.3.2
[0m[91mgo: finding github.com/stretchr/ob** v0.2.0
[0m[91mgo: finding github.com/stretchr/testify v1.4.0
[0m[91mgo: finding github.com/tidwall/pretty v1.0.0
[0m[91mgo: finding github.com/tmc/grpc-websocket-proxy v0.0.0-20170815181823-89b8d40f7ca8
[0m[91mgo: finding github.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8
[0m[91mgo: finding github.com/urfave/cli v1.20.0
[0m[91mgo: finding github.com/vektah/gqlparser v1.1.2
[0m[91mgo: finding github.com/xiang90/probing v0.0.0-20190116061207-43a291ad63a2
[0m[91mgo: finding github.com/xordataexchange/crypt v0.0.3-0.20170626215501-b2862e3d0a77
[0m[91mgo: finding go.etcd.io/bbolt v1.3.3
[0m[91mgo: finding go.etcd.io/etcd v0.0.0-20191023171146-3cf2f69b5738
[0m[91mgo: finding go.mongodb.org/mongo-driver v1.1.2
[0m[91mgo: finding go.opencensus.io v0.21.0
[0m[91mgo: finding go.uber.org/atomic v1.3.2
[0m[91mgo: finding go.uber.org/multierr v1.1.0
[0m[91mgo: finding go.uber.org/zap v1.10.0
[0m[91mgo: finding golang.org/x/crypto v0.0.0-20190923035154-9ee001bba392
[0m[91mgo: finding golang.org/x/exp v0.0.0-20190312203227-4b39c73a6495
[0m[91mgo: finding golang.org/x/image v0.0.0-20190227222117-0694c2d4d067
[0m[91mgo: finding golang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3
[0m[91mgo: finding golang.org/x/mobile v0.0.0-20190312151609-d3739f865fa6
[0m[91mgo: finding golang.org/x/net v0.0.0-20191004110552-13f9640d40b9
[0m[91mgo: finding golang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45
[0m[91mgo: finding golang.org/x/sync v0.0.0-20190423024810-112230192c58
[0m[91mgo: finding golang.org/x/sys v0.0.0-20190924154521-2837fb4f24fe
[0m[91mgo: finding golang.org/x/text v0.3.2
[0m[91mgo: finding golang.org/x/time v0.0.0-20190921001708-c4c64cad1fd0
[0m[91mgo: finding golang.org/x/tools v0.0.0-20190920225731-5eefd052ad72
[0m[91mgo: finding golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7
[0m[91mgo: finding gomodules.xyz/jsonpatch/v2 v2.0.1
[0m[91mgo: finding gonum.org/v1/gonum v0.0.0-20190331200053-3d26580ed485
[0m[91mgo: finding gonum.org/v1/netlib v0.0.0-20190331212654-76723241ea4e
[0m[91mgo: finding google.golang.org/api v0.4.0
[0m[91mgo: finding google.golang.org/appengine v1.6.5
[0m[91mgo: finding google.golang.org/genproto v0.0.0-20190916214212-f660b8655731
[0m[91mgo: finding google.golang.org/grpc v1.23.1
[0m[91mgo: finding gopkg.in/alecthomas/kingpin.v2 v2.2.6
[0m[91mgo: finding gopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15
[0m[91mgo: finding gopkg.in/cheggaaa/pb.v1 v1.0.25
[0m[91mgo: finding gopkg.in/fsnotify.v1 v1.4.7
[0m[91mgo: finding gopkg.in/inf.v0 v0.9.1
[0m[91mgo: finding gopkg.in/natefinch/lumberjack.v2 v2.0.0
[0m[91mgo: finding gopkg.in/resty.v1 v1.12.0
[0m[91mgo: finding gopkg.in/square/go-jose.v2 v2.2.2
[0m[91mgo: finding gopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7
[0m[91mgo: finding gopkg.in/yaml.v2 v2.2.4
[0m[91mgo: finding gotest.tools v2.2.0+incompatible
[0m[91mgo: finding honnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc
[0m[91mgo: finding istio.io/api v0.0.0-20200305220354-742c3015842e
[0m[91mgo: finding istio.io/client-go v0.0.0-20200305195406-fddfc7a9ca06
[0m[91mgo: finding istio.io/gogo-genproto v0.0.0-20190930162913-45029607206a
[0m[91mgo: finding k8s.io/api v0.17.2
[0m[91mgo: finding k8s.io/apiextensions-apiserver v0.17.2
[0m[91mgo: finding k8s.io/apimachinery v0.17.2
[0m[91mgo: finding k8s.io/apiserver v0.17.2
[0m[91mgo: finding k8s.io/client-go v0.17.2
[0m[91mgo: finding k8s.io/code-generator v0.17.2
[0m[91mgo: finding k8s.io/component-base v0.17.2
[0m[91mgo: finding k8s.io/gengo v0.0.0-20190822140433-26a664648505
[0m[91mgo: finding k8s.io/klog v1.0.0
[0m[91mgo: finding k8s.io/kube-openapi v0.0.0-20191107075043-30be4d16710a
[0m[91mgo: finding k8s.io/utils v0.0.0-20191114184206-e782cd3c129f
[0m[91mgo: finding knative.dev/pkg v0.0.0-20200306225627-d1665814487e
[0m[91mgo: finding modernc.org/cc v1.0.0
[0m[91mgo: finding modernc.org/golex v1.0.0
[0m[91mgo: finding modernc.org/mathutil v1.0.0
[0m[91mgo: finding modernc.org/strutil v1.0.0
[0m[91mgo: finding modernc.org/xc v1.0.0
[0m[91mgo: finding sigs.k8s.io/controller-runtime v0.5.0
[0m[91mgo: finding sigs.k8s.io/structured-merge-diff v1.0.1-0.20191108220359-b1b620dd3f06
[0m[91mgo: finding sigs.k8s.io/yaml v1.1.0
[0mRemoving intermediate container 22c43ca293ae
 ---> a3eb37c754b9
Step 6/17 : COPY main.go main.go
 ---> 48a90156e1da
Step 7/17 : COPY apis/ apis/
 ---> 5811e30d8541
Step 8/17 : COPY controllers/ controllers/
 ---> 4d1005b08ce3
Step 9/17 : COPY utils/ utils/
 ---> beecce3bbc8e
Step 10/17 : COPY constants/ constants/
 ---> e1da0bb8ad93
Step 11/17 : COPY client/ client/
 ---> 93a84723da49
Step 12/17 : RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 GO111MODULE=on go build -a -o manager main.go
 ---> Running in bb2bd9f0ac71
Removing intermediate container bb2bd9f0ac71
 ---> 4a35d3b552ae
Step 13/17 : FROM gcr.io/distroless/static:latest
latest: Pulling from distroless/static
9ff2acc3204b: Pulling fs layer
9ff2acc3204b: Download complete
9ff2acc3204b: Pull complete
Digest: sha256:c6d5981545ce1406d33e61434c61e9452dad93ecd8397c41e89036ef977a88f4
Status: Downloaded newer image for gcr.io/distroless/static:latest
 ---> e4d2a899b1bf
Step 14/17 : WORKDIR /
 ---> Running in 13dd79cce756
Removing intermediate container 13dd79cce756
 ---> e785f251f57c
Step 15/17 : COPY --from=builder /workspace/manager .
 ---> d32a0f06b8a4
Step 16/17 : COPY licenses/license.txt .
 ---> c2ed31ed2333
Step 17/17 : ENTRYPOINT ["/manager"]
 ---> Running in 28ed6d10898a
Removing intermediate container 28ed6d10898a
 ---> 730f30beb2dc
Successfully built 730f30beb2dc
Successfully tagged seldonio/seldon-core-operator:1.0.3-SNAPSHOT
docker save seldonio/seldon-core-operator:1.0.3-SNAPSHOT > operator.tar
kind load image-archive operator.tar 
make[1]: Leaving directory '/workspace/source/operator'
Files changed in engine folder:
SKIPPING ENGINE IMAGE BUILD...
Files changed in executor folder:
SKIPPING EXECUTOR IMAGE BUILD...
Build fixed models
cd ../docker/fixed-model && make kind_load_images
make[1]: Entering directory '/workspace/source/testing/docker/fixed-model'
s2i build -E environment_rest_v1 . seldonio/seldon-core-s2i-python3:0.15 seldonio/fixed-model:0.1
---> Installing application source...
Build completed successfully
s2i build -E environment_rest_v2 . seldonio/seldon-core-s2i-python3:0.15 seldonio/fixed-model:0.2
---> Installing application source...
Build completed successfully
kind load -v 3 docker-image seldonio/fixed-model:0.1
Image: "seldonio/fixed-model:0.1" with ID "sha256:61e74cb0ed2c23dcb4b20f4a7b9bb643ba684a82624df3a193e6a9bc8da8b766" not present on node "kind-control-plane"
Image: "seldonio/fixed-model:0.1" with ID "sha256:61e74cb0ed2c23dcb4b20f4a7b9bb643ba684a82624df3a193e6a9bc8da8b766" not present on node "kind-worker"
kind load -v 3 docker-image seldonio/fixed-model:0.2
Image: "seldonio/fixed-model:0.2" with ID "sha256:84446fd85b875aae6cc2f98f3bd50d8e7963d47a0c162f51f1472399c1242504" not present on node "kind-control-plane"
Image: "seldonio/fixed-model:0.2" with ID "sha256:84446fd85b875aae6cc2f98f3bd50d8e7963d47a0c162f51f1472399c1242504" not present on node "kind-worker"
make[1]: Leaving directory '/workspace/source/testing/docker/fixed-model'
kubectl create namespace seldon || echo "Namespace seldon already exists"
namespace/seldon created
kubectl create namespace test1 || echo "Namespace test1 already exists"
namespace/test1 created
helm repo add stable https://kubernetes-charts.storage.googleapis.com/
"stable" has been added to your repositories
helm repo add seldonio https://storage.googleapis.com/seldon-charts
"seldonio" has been added to your repositories
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
"jaegertracing" has been added to your repositories
helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "jaegertracing" chart repository
...Successfully got an update from the "seldonio" chart repository
...Successfully got an update from the "stable" chart repository
Update Complete. ‚éà Happy Helming!‚éà 
helm install ambassador \
	stable/ambassador \
	-f ../resources/ambassador_values.yaml \
	--set crds.keep=false \
	--namespace seldon \
	--set replicaCount=1 \
	--wait
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
NAME: ambassador
LAST DEPLOYED: Mon Apr  6 20:28:55 2020
NAMESPACE: seldon
STATUS: deployed
REVISION: 1
NOTES:
Congratulations! You've successfully installed Ambassador.

For help, visit our Slack at https://d6e.co/slack or view the documentation online at https://www.getambassador.io.

To get the IP address of Ambassador, run the following commands:
  export NODE_PORT=$(kubectl get --namespace seldon -o jsonpath="{.spec.ports[0].nodePort}" services ambassador)
  export NODE_IP=$(kubectl get nodes --namespace seldon -o jsonpath="{.items[0].status.addresses[0].address}")
  echo http://$NODE_IP:$NODE_PORT
kubectl apply -f istio-1.4.2.yaml
clusterrole.rbac.authorization.k8s.io/istio-reader-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-reader-istio-system created
customresourcedefinition.apiextensions.k8s.io/attributemanifests.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/clusterrbacconfigs.rbac.istio.io created
customresourcedefinition.apiextensions.k8s.io/destinationrules.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/envoyfilters.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/gateways.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/httpapispecbindings.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/httpapispecs.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/meshpolicies.authentication.istio.io created
customresourcedefinition.apiextensions.k8s.io/policies.authentication.istio.io created
customresourcedefinition.apiextensions.k8s.io/quotaspecbindings.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/quotaspecs.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/rbacconfigs.rbac.istio.io created
customresourcedefinition.apiextensions.k8s.io/rules.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/serviceentries.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/servicerolebindings.rbac.istio.io created
customresourcedefinition.apiextensions.k8s.io/serviceroles.rbac.istio.io created
customresourcedefinition.apiextensions.k8s.io/virtualservices.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/adapters.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/instances.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/templates.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/handlers.config.istio.io created
customresourcedefinition.apiextensions.k8s.io/sidecars.networking.istio.io created
customresourcedefinition.apiextensions.k8s.io/authorizationpolicies.security.istio.io created
namespace/istio-system created
serviceaccount/istio-reader-service-account created
clusterrole.rbac.authorization.k8s.io/istio-citadel-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-citadel-istio-system created
deployment.apps/istio-citadel created
poddisruptionbudget.policy/istio-citadel created
service/istio-citadel created
serviceaccount/istio-citadel-service-account created
deployment.apps/istio-egressgateway created
poddisruptionbudget.policy/istio-egressgateway created
gateway.networking.istio.io/istio-multicluster-egressgateway created
virtualservice.networking.istio.io/istio-multicluster-egressgateway created
envoyfilter.networking.istio.io/istio-multicluster-egressgateway created
destinationrule.networking.istio.io/istio-multicluster-destinationrule created
service/istio-egressgateway created
role.rbac.authorization.k8s.io/istio-egressgateway-sds created
rolebinding.rbac.authorization.k8s.io/istio-egressgateway-sds created
serviceaccount/istio-egressgateway-service-account created
clusterrole.rbac.authorization.k8s.io/istio-galley-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-galley-*****-role-binding-istio-system created
configmap/istio-mesh-galley created
configmap/istio-galley-configuration created
deployment.apps/istio-galley created
poddisruptionbudget.policy/istio-galley created
service/istio-galley created
serviceaccount/istio-galley-service-account created
configmap/istio-grafana-configuration-dashboards-citadel-dashboard created
configmap/istio-grafana-configuration-dashboards-galley-dashboard created
configmap/istio-grafana-configuration-dashboards-istio-mesh-dashboard created
configmap/istio-grafana-configuration-dashboards-istio-performance-dashboard created
configmap/istio-grafana-configuration-dashboards-istio-service-dashboard created
configmap/istio-grafana-configuration-dashboards-istio-workload-dashboard created
configmap/istio-grafana-configuration-dashboards-mixer-dashboard created
configmap/istio-grafana-configuration-dashboards-pilot-dashboard created
configmap/istio-grafana created
deployment.apps/grafana created
policy.authentication.istio.io/grafana-ports-mtls-disabled created
service/grafana created
deployment.apps/istio-ingressgateway created
gateway.networking.istio.io/ingressgateway created
poddisruptionbudget.policy/ingressgateway created
service/istio-ingressgateway created
serviceaccount/istio-ingressgateway-service-account created
sidecar.networking.istio.io/default created
clusterrole.rbac.authorization.k8s.io/istio-sidecar-injector-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-sidecar-injector-*****-role-binding-istio-system created
configmap/injector-mesh created
deployment.apps/istio-sidecar-injector created
mutatingwebhookconfiguration.admissionregistration.k8s.io/istio-sidecar-injector created
poddisruptionbudget.policy/istio-sidecar-injector created
service/istio-sidecar-injector created
serviceaccount/istio-sidecar-injector-service-account created
configmap/istio-sidecar-injector created
clusterrole.rbac.authorization.k8s.io/kiali created
clusterrole.rbac.authorization.k8s.io/kiali-viewer created
clusterrolebinding.rbac.authorization.k8s.io/kiali created
configmap/kiali created
secret/kiali created
deployment.apps/kiali created
service/kiali created
serviceaccount/kiali-service-account created
clusterrole.rbac.authorization.k8s.io/istio-pilot-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-pilot-istio-system created
configmap/pilot-envoy-config created
configmap/istio created
deployment.apps/istio-pilot created
meshpolicy.authentication.istio.io/default created
poddisruptionbudget.policy/istio-pilot created
service/istio-pilot created
serviceaccount/istio-pilot-service-account created
clusterrole.rbac.authorization.k8s.io/istio-policy created
clusterrolebinding.rbac.authorization.k8s.io/istio-policy-*****-role-binding-istio-system created
destinationrule.networking.istio.io/istio-policy created
deployment.apps/istio-policy created
poddisruptionbudget.policy/istio-policy created
service/istio-policy created
serviceaccount/istio-policy-service-account created
clusterrole.rbac.authorization.k8s.io/prometheus-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/prometheus-istio-system created
configmap/prometheus created
deployment.apps/prometheus created
service/prometheus created
serviceaccount/prometheus created
horizontalpodautoscaler.autoscaling/istio-telemetry created
clusterrole.rbac.authorization.k8s.io/istio-mixer-istio-system created
clusterrolebinding.rbac.authorization.k8s.io/istio-mixer-*****-role-binding-istio-system created
attributemanifest.config.istio.io/istioproxy created
attributemanifest.config.istio.io/kubernetes created
handler.config.istio.io/stdio created
instance.config.istio.io/accesslog created
instance.config.istio.io/tcpaccesslog created
rule.config.istio.io/stdio created
rule.config.istio.io/stdiotcp created
instance.config.istio.io/requestcount created
instance.config.istio.io/requestduration created
instance.config.istio.io/requestsize created
instance.config.istio.io/responsesize created
instance.config.istio.io/tcpbytesent created
instance.config.istio.io/tcpbytereceived created
instance.config.istio.io/tcpconnectionsopened created
instance.config.istio.io/tcpconnectionsclosed created
handler.config.istio.io/prometheus created
rule.config.istio.io/promhttp created
rule.config.istio.io/promtcp created
rule.config.istio.io/promtcpconnectionopen created
rule.config.istio.io/promtcpconnectionclosed created
handler.config.istio.io/kubernetesenv created
rule.config.istio.io/kubeattrgenrulerule created
rule.config.istio.io/tcpkubeattrgenrulerule created
instance.config.istio.io/attributes created
destinationrule.networking.istio.io/istio-telemetry created
configmap/telemetry-envoy-config created
deployment.apps/istio-telemetry created
poddisruptionbudget.policy/istio-telemetry created
service/istio-telemetry created
serviceaccount/istio-mixer-service-account created
deployment.apps/istio-tracing created
service/jaeger-query created
service/jaeger-collector created
service/jaeger-agent created
service/zipkin created
service/tracing created
kubectl rollout status deployment.apps/istio-ingressgateway -n istio-system
Waiting for deployment "istio-ingressgateway" rollout to finish: 0 of 1 updated replicas are available...
deployment "istio-ingressgateway" successfully rolled out
kubectl rollout status deployment.apps/istio-pilot -n istio-system
deployment "istio-pilot" successfully rolled out
kubectl rollout status deployment.apps/istio-citadel -n istio-system
deployment "istio-citadel" successfully rolled out
helm install jaeger-operator \
	jaegertracing/jaeger-operator \
	--set rbac.clusterRole=true \
	--namespace seldon \
	--wait
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
NAME: jaeger-operator
LAST DEPLOYED: Mon Apr  6 20:31:17 2020
NAMESPACE: seldon
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
jaeger-operator is installed.


Check the jaeger-operator logs
  export POD=$(kubectl get pods-l app.kubernetes.io/instance=jaeger-operator -lapp.kubernetes.io/name=jaeger-operator --namespace seldon --output name)
  kubectl logs $POD --namespace=seldon
kubectl apply -f ../resources/jaeger.yaml --namespace seldon
jaeger.jaegertracing.io/jaeger created
mapping.getambassador.io/jaeger created
cd ../../operator && make install-cert-manager
make[1]: Entering directory '/workspace/source/operator'
kubectl create namespace cert-manager || echo "Namespace cert-manager-exists"
namespace/cert-manager created
kubectl label namespace cert-manager cert-manager.io/disable-validation=true || echo "namespace cert-manager-already labelled"
namespace/cert-manager labeled
kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.12.0/cert-manager.yaml
customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/clusterissuers.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/issuers.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/orders.acme.cert-manager.io created
Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
namespace/cert-manager configured
serviceaccount/cert-manager-cainjector created
serviceaccount/cert-manager created
serviceaccount/cert-manager-webhook created
clusterrole.rbac.authorization.k8s.io/cert-manager-cainjector created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-cainjector created
role.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created
rolebinding.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-webhook:auth-delegator created
rolebinding.rbac.authorization.k8s.io/cert-manager-webhook:webhook-authentication-reader created
clusterrole.rbac.authorization.k8s.io/cert-manager-webhook:webhook-requester created
role.rbac.authorization.k8s.io/cert-manager:leaderelection created
rolebinding.rbac.authorization.k8s.io/cert-manager:leaderelection created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-issuers created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificates created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-orders created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-challenges created
clusterrole.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-issuers created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificates created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-orders created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-challenges created
clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created
clusterrole.rbac.authorization.k8s.io/cert-manager-view created
clusterrole.rbac.authorization.k8s.io/cert-manager-edit created
service/cert-manager created
service/cert-manager-webhook created
deployment.apps/cert-manager-cainjector created
deployment.apps/cert-manager created
deployment.apps/cert-manager-webhook created
mutatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created
validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created
kubectl rollout status deployment.apps/cert-manager -n cert-manager
Waiting for deployment "cert-manager" rollout to finish: 0 of 1 updated replicas are available...
deployment "cert-manager" successfully rolled out
kubectl rollout status deployment.apps/cert-manager-cainjector -n cert-manager
deployment "cert-manager-cainjector" successfully rolled out
kubectl rollout status deployment.apps/cert-manager-webhook -n cert-manager
Waiting for deployment "cert-manager-webhook" rollout to finish: 0 of 1 updated replicas are available...
deployment "cert-manager-webhook" successfully rolled out
make[1]: Leaving directory '/workspace/source/operator'
sleep 5 #https://github.com/jetstack/cert-manager/issues/2273
kubectl create namespace seldon-system || echo "namespace seldon-system exists"
namespace/seldon-system created
helm install seldon \
	../../helm-charts/seldon-core-operator \
	--namespace seldon-system \
	--set istio.enabled=true \
	--set istio.gateway=seldon-gateway \
	--set certManager.enabled=false \
	--set executor.enabled=true \
	--wait
NAME: seldon
LAST DEPLOYED: Mon Apr  6 20:32:00 2020
NAMESPACE: seldon-system
STATUS: deployed
REVISION: 1
TEST SUITE: None
kubectl config set-context $(kubectl config current-context) --namespace=seldon
Context "kind-kind" modified.
kubectl apply -f metrics.yaml
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
serviceaccount/metrics-server created
deployment.apps/metrics-server created
service/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
make: Entering directory '/workspace/source/python'
pip install -e . -r requirements-dev.txt
Obtaining file:///workspace/source/python
Collecting Flask<2.0.0
  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)
Collecting Flask-cors<4.0.0
  Downloading Flask_Cors-3.0.8-py2.py3-none-any.whl (14 kB)
Collecting redis<4.0.0
  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)
Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (2.23.0)
Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.18.1)
Collecting flatbuffers<2.0.0
  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)
Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (3.11.3)
Requirement already satisfied: grpcio<2.0.0 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (1.27.2)
Collecting Flask-OpenTracing<1.2.0,>=1.1.0
  Downloading Flask-OpenTracing-1.1.0.tar.gz (8.2 kB)
Collecting opentracing<2.3.0,>=2.2.0
  Downloading opentracing-2.2.0.tar.gz (47 kB)
Collecting jaeger-client<4.2.0,>=4.1.0
  Downloading jaeger-client-4.1.0.tar.gz (80 kB)
Collecting grpcio-opentracing<1.2.0,>=1.1.4
  Downloading grpcio_opentracing-1.1.4-py3-none-any.whl (14 kB)
Collecting pyaml<20.0.0
  Downloading pyaml-19.12.0-py2.py3-none-any.whl (17 kB)
Collecting gunicorn<20.1.0,>=19.9.0
  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)
Collecting minio<6.0.0,>=4.0.9
  Downloading minio-5.0.8-py2.py3-none-any.whl (73 kB)
Collecting azure-storage-blob<3.0.0,>=2.0.1
  Downloading azure_storage_blob-2.1.0-py2.py3-none-any.whl (88 kB)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (45.2.0)
Collecting google-cloud-storage>=1.16.0
  Downloading google_cloud_storage-1.27.0-py2.py3-none-any.whl (79 kB)
Requirement already satisfied: prometheus_client<0.8.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 19)) (0.7.1)
Collecting black==19.10b0
  Downloading black-19.10b0-py36-none-any.whl (97 kB)
Collecting flake8==3.7.9
  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)
Collecting mypy<0.771
  Downloading mypy-0.770-cp36-cp36m-manylinux1_x86_64.whl (21.7 MB)
Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/site-packages (from -r requirements-dev.txt (line 5)) (7.0.0)
Collecting pytest==5.4.1
  Downloading pytest-5.4.1-py3-none-any.whl (246 kB)
Collecting pytest-cov==2.8.1
  Downloading pytest_cov-2.8.1-py2.py3-none-any.whl (18 kB)
Collecting tox<4.0.0
  Downloading tox-3.14.6-py2.py3-none-any.whl (81 kB)
Collecting coverage==4.5.4
  Downloading coverage-4.5.4-cp36-cp36m-manylinux1_x86_64.whl (205 kB)
Requirement already satisfied: pandas==1.0.1 in /usr/local/lib/python3.6/site-packages (from -r requirements-dev.txt (line 14)) (1.0.1)
Collecting pip-licenses==2.1.1
  Downloading pip_licenses-2.1.1-py3-none-any.whl (13 kB)
Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/site-packages (from Flask<2.0.0->-r requirements.txt (line 1)) (2.11.1)
Collecting click>=5.1
  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)
Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/site-packages (from Flask<2.0.0->-r requirements.txt (line 1)) (1.0.0)
Collecting itsdangerous>=0.24
  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: Six in /usr/local/lib/python3.6/site-packages (from Flask-cors<4.0.0->-r requirements.txt (line 2)) (1.14.0)
Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests<3.0.0->-r requirements.txt (line 4)) (2.9)
Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests<3.0.0->-r requirements.txt (line 4)) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests<3.0.0->-r requirements.txt (line 4)) (1.25.8)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests<3.0.0->-r requirements.txt (line 4)) (2019.11.28)
Collecting threadloop<2,>=1
  Downloading threadloop-1.0.2.tar.gz (4.9 kB)
Collecting thrift
  Downloading thrift-0.13.0.tar.gz (59 kB)
Collecting tornado<6,>=4.3
  Downloading tornado-5.1.1.tar.gz (516 kB)
Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/site-packages (from pyaml<20.0.0->-r requirements.txt (line 13)) (5.3)
Collecting configparser
  Downloading configparser-5.0.0-py3-none-any.whl (22 kB)
Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/site-packages (from minio<6.0.0,>=4.0.9->-r requirements.txt (line 15)) (2.8.1)
Requirement already satisfied: pytz in /usr/local/lib/python3.6/site-packages (from minio<6.0.0,>=4.0.9->-r requirements.txt (line 15)) (2019.3)
Collecting azure-storage-common~=2.1
  Downloading azure_storage_common-2.1.0-py2.py3-none-any.whl (47 kB)
Collecting azure-common>=1.1.5
  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)
Collecting google-resumable-media<0.6dev,>=0.5.0
  Downloading google_resumable_media-0.5.0-py2.py3-none-any.whl (38 kB)
Collecting google-auth<2.0dev,>=1.11.0
  Downloading google_auth-1.13.1-py2.py3-none-any.whl (87 kB)
Collecting google-cloud-core<2.0dev,>=1.2.0
  Downloading google_cloud_core-1.3.0-py2.py3-none-any.whl (26 kB)
Collecting regex
  Downloading regex-2020.4.4-cp36-cp36m-manylinux2010_x86_64.whl (679 kB)
Collecting typed-ast>=1.4.0
  Downloading typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737 kB)
Collecting toml>=0.9.4
  Downloading toml-0.10.0-py2.py3-none-any.whl (25 kB)
Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/site-packages (from black==19.10b0->-r requirements-dev.txt (line 2)) (19.3.0)
Collecting appdirs
  Downloading appdirs-1.4.3-py2.py3-none-any.whl (12 kB)
Collecting pathspec<1,>=0.6
  Downloading pathspec-0.7.0-py2.py3-none-any.whl (25 kB)
Collecting pyflakes<2.2.0,>=2.1.0
  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)
Collecting mccabe<0.7.0,>=0.6.0
  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)
Collecting pycodestyle<2.6.0,>=2.5.0
  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)
Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/site-packages (from flake8==3.7.9->-r requirements-dev.txt (line 3)) (0.3)
Collecting mypy-extensions<0.5.0,>=0.4.3
  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)
Collecting typing-extensions>=3.7.4
  Downloading typing_extensions-3.7.4.2-py3-none-any.whl (22 kB)
Requirement already satisfied: importlib-metadata>=0.12; python_version < "3.8" in /usr/local/lib/python3.6/site-packages (from pytest==5.4.1->-r requirements-dev.txt (line 6)) (1.5.0)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/site-packages (from pytest==5.4.1->-r requirements-dev.txt (line 6)) (0.1.8)
Collecting more-itertools>=4.0.0
  Downloading more_itertools-8.2.0-py3-none-any.whl (43 kB)
Collecting py>=1.5.0
  Downloading py-1.8.1-py2.py3-none-any.whl (83 kB)
Collecting pluggy<1.0,>=0.12
  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)
Collecting packaging
  Downloading packaging-20.3-py2.py3-none-any.whl (37 kB)
Collecting filelock<4,>=3.0.0
  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)
Collecting virtualenv!=20.0.0,!=20.0.1,!=20.0.2,!=20.0.3,!=20.0.4,!=20.0.5,!=20.0.6,!=20.0.7,>=16.0.0
  Downloading virtualenv-20.0.16-py2.py3-none-any.whl (4.6 MB)
Collecting PTable
  Downloading PTable-0.9.2.tar.gz (31 kB)
Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/site-packages (from Jinja2>=2.10.1->Flask<2.0.0->-r requirements.txt (line 1)) (1.1.1)
Collecting cryptography
  Downloading cryptography-2.9-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)
Collecting cachetools<5.0,>=2.0.0
  Downloading cachetools-4.0.0-py3-none-any.whl (10 kB)
Collecting pyasn1-modules>=0.2.1
  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
Collecting rsa<4.1,>=3.1.4
  Downloading rsa-4.0-py2.py3-none-any.whl (38 kB)
Collecting google-api-core<2.0.0dev,>=1.16.0
  Downloading google_api_core-1.16.0-py2.py3-none-any.whl (70 kB)
Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata>=0.12; python_version < "3.8"->pytest==5.4.1->-r requirements-dev.txt (line 6)) (3.1.0)
Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/site-packages (from packaging->pytest==5.4.1->-r requirements-dev.txt (line 6)) (2.4.6)
Collecting importlib-resources<2,>=1.0; python_version < "3.7"
  Downloading importlib_resources-1.4.0-py2.py3-none-any.whl (20 kB)
Collecting distlib<1,>=0.3.0
  Downloading distlib-0.3.0.zip (571 kB)
Collecting cffi!=1.11.3,>=1.8
  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)
Collecting pyasn1<0.5.0,>=0.4.6
  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
Collecting googleapis-common-protos<2.0dev,>=1.6.0
  Downloading googleapis-common-protos-1.51.0.tar.gz (35 kB)
Collecting pycparser
  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)
Building wheels for collected packages: Flask-OpenTracing, opentracing, jaeger-client, threadloop, thrift, tornado, PTable, distlib, googleapis-common-protos
  Building wheel for Flask-OpenTracing (setup.py): started
  Building wheel for Flask-OpenTracing (setup.py): finished with status 'done'
  Created wheel for Flask-OpenTracing: filename=Flask_OpenTracing-1.1.0-py3-none-any.whl size=9070 sha256=05df3956c4992a7823e79f656e719e96174dcc08d09d9147939c35ac3be32082
  Stored in directory: /builder/home/.cache/pip/wheels/ad/4b/2d/24ff0da0a0b53c7c77ce59b843bcceaf644c88703241e59615
  Building wheel for opentracing (setup.py): started
  Building wheel for opentracing (setup.py): finished with status 'done'
  Created wheel for opentracing: filename=opentracing-2.2.0-py3-none-any.whl size=49319 sha256=8339549b89af47fce8000e4cfa278062b8fe6fc9c03d4f558f4f8bb99c5c43ff
  Stored in directory: /builder/home/.cache/pip/wheels/39/40/44/8bace79f4514e99786236c31f1df8d1b814ff02c1e08b1d697
  Building wheel for jaeger-client (setup.py): started
  Building wheel for jaeger-client (setup.py): finished with status 'done'
  Created wheel for jaeger-client: filename=jaeger_client-4.1.0-py3-none-any.whl size=64309 sha256=c1605f6f5c5827e99ac96ba51853dcbf3f802608c23d6a1d5a0f0b4501ce750c
  Stored in directory: /builder/home/.cache/pip/wheels/e9/9b/8c/503d0cc13b39a551c054515683ba1d15b40324c863dc442e66
  Building wheel for threadloop (setup.py): started
  Building wheel for threadloop (setup.py): finished with status 'done'
  Created wheel for threadloop: filename=threadloop-1.0.2-py3-none-any.whl size=3423 sha256=2f030818cd2f99bc90dfa02af3c8a2b75be7a888c893f7dad823a7ea8d501ff9
  Stored in directory: /builder/home/.cache/pip/wheels/02/54/65/9f87de48fe8fcaaee30f279973d946ad55f9df56b93b3e78da
  Building wheel for thrift (setup.py): started
  Building wheel for thrift (setup.py): finished with status 'done'
  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=483893 sha256=fead59db3bdaff2c7065df149f37fd923857477a05f0a9bc3958c633bf0b6863
  Stored in directory: /builder/home/.cache/pip/wheels/e0/38/fc/472fe18756b177b42096961f8bd3ff2dc5c5620ac399fce52d
  Building wheel for tornado (setup.py): started
  Building wheel for tornado (setup.py): finished with status 'done'
  Created wheel for tornado: filename=tornado-5.1.1-cp36-cp36m-linux_x86_64.whl size=462650 sha256=18fe0174cb1cfe967bae501ab108cb505145b881a318351b93f45c9bb8e266df
  Stored in directory: /builder/home/.cache/pip/wheels/64/74/71/e7a0d0eb4fc42cb20a17aec36f8f0b5b8c5e1ec19c701fd34a
  Building wheel for PTable (setup.py): started
  Building wheel for PTable (setup.py): finished with status 'done'
  Created wheel for PTable: filename=PTable-0.9.2-py3-none-any.whl size=22907 sha256=e528edbab59a2342f20c8a3f465908f0e614930383fc4ab31aa84a434a494998
  Stored in directory: /builder/home/.cache/pip/wheels/f3/65/67/71f473ec87ea4554d1bdfb1b5128cfe1414c2b113b72a1ee8e
  Building wheel for distlib (setup.py): started
  Building wheel for distlib (setup.py): finished with status 'done'
  Created wheel for distlib: filename=distlib-0.3.0-py3-none-any.whl size=340427 sha256=f614938ec94531160cb2e9677c04d49548a6d5680127793465fca5faff27aafe
  Stored in directory: /builder/home/.cache/pip/wheels/33/d9/71/e4e3cac73529e1947df418af0f140cd7589d5d9ec0e17ecfc2
  Building wheel for googleapis-common-protos (setup.py): started
  Building wheel for googleapis-common-protos (setup.py): finished with status 'done'
  Created wheel for googleapis-common-protos: filename=googleapis_common_protos-1.51.0-py3-none-any.whl size=77592 sha256=3d012605df016e1d3379a7e184e1e63e4cc0f99b94b26bd24ebb93f532967f6c
  Stored in directory: /builder/home/.cache/pip/wheels/35/8d/af/a922cb18800b31fadac3523cadf6c1efdf233b788fe7a4da70
Successfully built Flask-OpenTracing opentracing jaeger-client threadloop thrift tornado PTable distlib googleapis-common-protos
Installing collected packages: click, itsdangerous, Flask, Flask-cors, redis, flatbuffers, opentracing, Flask-OpenTracing, tornado, threadloop, thrift, jaeger-client, grpcio-opentracing, pyaml, gunicorn, configparser, minio, pycparser, cffi, cryptography, azure-common, azure-storage-common, azure-storage-blob, google-resumable-media, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, googleapis-common-protos, google-api-core, google-cloud-core, google-cloud-storage, regex, typed-ast, toml, appdirs, pathspec, black, pyflakes, mccabe, pycodestyle, flake8, mypy-extensions, typing-extensions, mypy, more-itertools, py, pluggy, packaging, pytest, coverage, pytest-cov, filelock, importlib-resources, distlib, virtualenv, tox, PTable, pip-licenses, seldon-core
  Attempting uninstall: tornado
    Found existing installation: tornado 6.0.4
    Uninstalling tornado-6.0.4:
      Successfully uninstalled tornado-6.0.4
  Running setup.py develop for seldon-core
Successfully installed Flask-1.1.2 Flask-OpenTracing-1.1.0 Flask-cors-3.0.8 PTable-0.9.2 appdirs-1.4.3 azure-common-1.1.25 azure-storage-blob-2.1.0 azure-storage-common-2.1.0 black-19.10b0 cachetools-4.0.0 cffi-1.14.0 click-7.1.1 configparser-5.0.0 coverage-4.5.4 cryptography-2.9 distlib-0.3.0 filelock-3.0.12 flake8-3.7.9 flatbuffers-1.12 google-api-core-1.16.0 google-auth-1.13.1 google-cloud-core-1.3.0 google-cloud-storage-1.27.0 google-resumable-media-0.5.0 googleapis-common-protos-1.51.0 grpcio-opentracing-1.1.4 gunicorn-20.0.4 importlib-resources-1.4.0 itsdangerous-1.1.0 jaeger-client-4.1.0 mccabe-0.6.1 minio-5.0.8 more-itertools-8.2.0 mypy-0.770 mypy-extensions-0.4.3 opentracing-2.2.0 packaging-20.3 pathspec-0.7.0 pip-licenses-2.1.1 pluggy-0.13.1 py-1.8.1 pyaml-19.12.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycodestyle-2.5.0 pycparser-2.20 pyflakes-2.1.1 pytest-5.4.1 pytest-cov-2.8.1 redis-3.4.1 regex-2020.4.4 rsa-4.0 seldon-core threadloop-1.0.2 thrift-0.13.0 toml-0.10.0 tornado-5.1.1 tox-3.14.6 typed-ast-1.4.1 typing-extensions-3.7.4.2 virtualenv-20.0.16
make: Leaving directory '/workspace/source/python'
cp ../../proto/prediction.proto ./proto
cd ../../proto/tensorflow && make create_protos
make[1]: Entering directory '/workspace/source/proto/tensorflow'
./create-protos.sh
Downloading proto files for master
make[1]: Leaving directory '/workspace/source/proto/tensorflow'
cp -vr ../../proto/tensorflow/tensorflow .
'../../proto/tensorflow/tensorflow' -> './tensorflow'
'../../proto/tensorflow/tensorflow/core' -> './tensorflow/core'
'../../proto/tensorflow/tensorflow/core/framework' -> './tensorflow/core/framework'
'../../proto/tensorflow/tensorflow/core/framework/types.proto' -> './tensorflow/core/framework/types.proto'
'../../proto/tensorflow/tensorflow/core/framework/resource_handle.proto' -> './tensorflow/core/framework/resource_handle.proto'
'../../proto/tensorflow/tensorflow/core/framework/tensor_shape.proto' -> './tensorflow/core/framework/tensor_shape.proto'
'../../proto/tensorflow/tensorflow/core/framework/tensor.proto' -> './tensorflow/core/framework/tensor.proto'
python -m grpc.tools.protoc -I. --python_out=. --grpc_python_out=. ./proto/prediction.proto
cd ../../notebooks && make build_protos
make[1]: Entering directory '/workspace/source/notebooks'
cd ../proto/tensorflow && make create_protos
make[2]: Entering directory '/workspace/source/proto/tensorflow'
make[2]: Nothing to be done for 'create_protos'.
make[2]: Leaving directory '/workspace/source/proto/tensorflow'
cp -vr ../proto/tensorflow/tensorflow .
'../proto/tensorflow/tensorflow' -> './tensorflow'
'../proto/tensorflow/tensorflow/core' -> './tensorflow/core'
'../proto/tensorflow/tensorflow/core/framework' -> './tensorflow/core/framework'
'../proto/tensorflow/tensorflow/core/framework/types.proto' -> './tensorflow/core/framework/types.proto'
'../proto/tensorflow/tensorflow/core/framework/resource_handle.proto' -> './tensorflow/core/framework/resource_handle.proto'
'../proto/tensorflow/tensorflow/core/framework/tensor_shape.proto' -> './tensorflow/core/framework/tensor_shape.proto'
'../proto/tensorflow/tensorflow/core/framework/tensor.proto' -> './tensorflow/core/framework/tensor.proto'
cp ../proto/prediction.proto ./proto
python -m grpc.tools.protoc -I. --python_out=. --grpc_python_out=. ./proto/prediction.proto
make[1]: Leaving directory '/workspace/source/notebooks'
cd ../../proto/k8s && make create_protos
make[1]: Entering directory '/workspace/source/proto/k8s'
./create-k8s-protos.sh
Downloading proto files for master
Munging proto file packages
sed -i.bak 's|import "k8s.io/apiextensions-apiserver/|//import "k8s.io/apiextensions-apiserver/|' k8s.io/api/core/v1/generated.proto
rm k8s.io/api/core/v1/generated.proto.bak
make[1]: Leaving directory '/workspace/source/proto/k8s'
pip install -r dev_requirements.txt
Collecting pytest==5.3.1
  Downloading pytest-5.3.1-py3-none-any.whl (233 kB)
Collecting pytest-xdist==1.30.0
  Downloading pytest_xdist-1.30.0-py2.py3-none-any.whl (35 kB)
Requirement already satisfied: pytest-cov==2.8.1 in /usr/local/lib/python3.6/site-packages (from -r dev_requirements.txt (line 3)) (2.8.1)
Collecting flaky==3.6.1
  Downloading flaky-3.6.1-py2.py3-none-any.whl (22 kB)
Collecting tenacity==6.0.0
  Downloading tenacity-6.0.0-py2.py3-none-any.whl (24 kB)
Requirement already satisfied: ipython==7.13.0 in /usr/local/lib/python3.6/site-packages (from -r dev_requirements.txt (line 8)) (7.13.0)
Requirement already satisfied: nbconvert==5.6.1 in /usr/local/lib/python3.6/site-packages (from -r dev_requirements.txt (line 9)) (5.6.1)
Requirement already satisfied: alibi==0.3.2 in /usr/local/lib/python3.6/site-packages (from -r dev_requirements.txt (line 10)) (0.3.2)
Collecting matplotlib==3.1.3
  Downloading matplotlib-3.1.3-cp36-cp36m-manylinux1_x86_64.whl (13.1 MB)
Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.6/site-packages (from -r dev_requirements.txt (line 12)) (1.15.2)
Requirement already satisfied: coverage==4.5.4 in /usr/local/lib/python3.6/site-packages (from -r dev_requirements.txt (line 15)) (4.5.4)
Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/site-packages (from pytest==5.3.1->-r dev_requirements.txt (line 1)) (1.8.1)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/site-packages (from pytest==5.3.1->-r dev_requirements.txt (line 1)) (0.1.8)
Requirement already satisfied: importlib-metadata>=0.12; python_version < "3.8" in /usr/local/lib/python3.6/site-packages (from pytest==5.3.1->-r dev_requirements.txt (line 1)) (1.5.0)
Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/site-packages (from pytest==5.3.1->-r dev_requirements.txt (line 1)) (0.13.1)
Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/site-packages (from pytest==5.3.1->-r dev_requirements.txt (line 1)) (19.3.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.6/site-packages (from pytest==5.3.1->-r dev_requirements.txt (line 1)) (20.3)
Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/site-packages (from pytest==5.3.1->-r dev_requirements.txt (line 1)) (8.2.0)
Collecting pytest-forked
  Downloading pytest_forked-1.1.3-py2.py3-none-any.whl (4.5 kB)
Collecting execnet>=1.1
  Downloading execnet-1.7.1-py2.py3-none-any.whl (39 kB)
Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from pytest-xdist==1.30.0->-r dev_requirements.txt (line 2)) (1.14.0)
Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/site-packages (from ipython==7.13.0->-r dev_requirements.txt (line 8)) (0.16.0)
Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/site-packages (from ipython==7.13.0->-r dev_requirements.txt (line 8)) (4.3.3)
Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/site-packages (from ipython==7.13.0->-r dev_requirements.txt (line 8)) (0.7.5)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.6/site-packages (from ipython==7.13.0->-r dev_requirements.txt (line 8)) (3.0.4)
Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/site-packages (from ipython==7.13.0->-r dev_requirements.txt (line 8)) (45.2.0)
Requirement already satisfied: pexpect; sys_platform != "win32" in /usr/local/lib/python3.6/site-packages (from ipython==7.13.0->-r dev_requirements.txt (line 8)) (4.8.0)
Requirement already satisfied: backcall in /usr/local/lib/python3.6/site-packages (from ipython==7.13.0->-r dev_requirements.txt (line 8)) (0.1.0)
Requirement already satisfied: pygments in /usr/local/lib/python3.6/site-packages (from ipython==7.13.0->-r dev_requirements.txt (line 8)) (2.5.2)
Requirement already satisfied: decorator in /usr/local/lib/python3.6/site-packages (from ipython==7.13.0->-r dev_requirements.txt (line 8)) (4.4.2)
Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/site-packages (from nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (1.4.2)
Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/site-packages (from nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (4.6.3)
Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/site-packages (from nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (0.3)
Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/site-packages (from nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (2.11.1)
Requirement already satisfied: bleach in /usr/local/lib/python3.6/site-packages (from nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (3.1.1)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/site-packages (from nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (0.6.0)
Requirement already satisfied: testpath in /usr/local/lib/python3.6/site-packages (from nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (0.4.4)
Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/site-packages (from nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (0.8.4)
Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/site-packages (from nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (5.0.4)
Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/site-packages (from alibi==0.3.2->-r dev_requirements.txt (line 10)) (0.16.2)
Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages (from alibi==0.3.2->-r dev_requirements.txt (line 10)) (1.0.1)
Requirement already satisfied: spacy in /usr/local/lib/python3.6/site-packages (from alibi==0.3.2->-r dev_requirements.txt (line 10)) (2.2.3)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/site-packages (from alibi==0.3.2->-r dev_requirements.txt (line 10)) (4.8.2)
Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from alibi==0.3.2->-r dev_requirements.txt (line 10)) (2.23.0)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/site-packages (from alibi==0.3.2->-r dev_requirements.txt (line 10)) (0.22.2.post1)
Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from alibi==0.3.2->-r dev_requirements.txt (line 10)) (1.18.1)
Requirement already satisfied: Pillow in /usr/local/lib/python3.6/site-packages (from alibi==0.3.2->-r dev_requirements.txt (line 10)) (7.0.0)
Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib==3.1.3->-r dev_requirements.txt (line 11)) (1.1.0)
Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib==3.1.3->-r dev_requirements.txt (line 11)) (2.8.1)
Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib==3.1.3->-r dev_requirements.txt (line 11)) (0.10.0)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib==3.1.3->-r dev_requirements.txt (line 11)) (2.4.6)
Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (1.1.0)
Requirement already satisfied: wheel>=0.26; python_version >= "3" in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (0.34.2)
Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (1.27.2)
Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (0.2.2)
Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (0.1.8)
Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (1.15.1)
Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (0.9.0)
Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (1.0.8)
Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (1.15.0)
Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (3.2.0)
Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (1.12.0)
Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (1.1.0)
Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (3.11.3)
Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (0.8.1)
Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata>=0.12; python_version < "3.8"->pytest==5.3.1->-r dev_requirements.txt (line 1)) (3.1.0)
Collecting apipkg>=1.4
  Downloading apipkg-1.5-py2.py3-none-any.whl (4.9 kB)
Requirement already satisfied: parso>=0.5.2 in /usr/local/lib/python3.6/site-packages (from jedi>=0.10->ipython==7.13.0->-r dev_requirements.txt (line 8)) (0.6.2)
Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/site-packages (from traitlets>=4.2->ipython==7.13.0->-r dev_requirements.txt (line 8)) (0.2.0)
Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/site-packages (from pexpect; sys_platform != "win32"->ipython==7.13.0->-r dev_requirements.txt (line 8)) (0.6.0)
Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/site-packages (from jinja2>=2.4->nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (1.1.1)
Requirement already satisfied: webencodings in /usr/local/lib/python3.6/site-packages (from bleach->nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (0.5.1)
Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/site-packages (from nbformat>=4.4->nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (3.2.0)
Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/site-packages (from scikit-image->alibi==0.3.2->-r dev_requirements.txt (line 10)) (2.8.0)
Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/site-packages (from scikit-image->alibi==0.3.2->-r dev_requirements.txt (line 10)) (1.4.1)
Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/site-packages (from scikit-image->alibi==0.3.2->-r dev_requirements.txt (line 10)) (1.1.1)
Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/site-packages (from scikit-image->alibi==0.3.2->-r dev_requirements.txt (line 10)) (2.4)
Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas->alibi==0.3.2->-r dev_requirements.txt (line 10)) (2019.3)
Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/site-packages (from spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (2.0.3)
Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/site-packages (from spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (1.0.2)
Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/site-packages (from spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (0.4.1)
Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/site-packages (from spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (1.1.3)
Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (3.0.2)
Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/site-packages (from spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (7.3.1)
Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/site-packages (from spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (1.0.0)
Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/site-packages (from spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (1.0.2)
Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/site-packages (from spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (0.6.0)
Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.6/site-packages (from beautifulsoup4->alibi==0.3.2->-r dev_requirements.txt (line 10)) (2.0)
Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->alibi==0.3.2->-r dev_requirements.txt (line 10)) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->alibi==0.3.2->-r dev_requirements.txt (line 10)) (1.25.8)
Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->alibi==0.3.2->-r dev_requirements.txt (line 10)) (2.9)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->alibi==0.3.2->-r dev_requirements.txt (line 10)) (2019.11.28)
Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/site-packages (from scikit-learn->alibi==0.3.2->-r dev_requirements.txt (line 10)) (0.14.1)
Requirement already satisfied: h5py in /usr/local/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (2.10.0)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (3.2.1)
Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->-r dev_requirements.txt (line 12)) (1.0.0)
Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert==5.6.1->-r dev_requirements.txt (line 9)) (0.15.7)
Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy->alibi==0.3.2->-r dev_requirements.txt (line 10)) (4.43.0)
Installing collected packages: pytest, pytest-forked, apipkg, execnet, pytest-xdist, flaky, tenacity, matplotlib
  Attempting uninstall: pytest
    Found existing installation: pytest 5.4.1
    Uninstalling pytest-5.4.1:
      Successfully uninstalled pytest-5.4.1
  Attempting uninstall: matplotlib
    Found existing installation: matplotlib 3.2.0
    Uninstalling matplotlib-3.2.0:
      Successfully uninstalled matplotlib-3.2.0
Successfully installed apipkg-1.5 execnet-1.7.1 flaky-3.6.1 matplotlib-3.1.3 pytest-5.3.1 pytest-forked-1.1.3 pytest-xdist-1.30.0 tenacity-6.0.0
pip install -e ../../python
Obtaining file:///workspace/source/python
Requirement already satisfied: Flask<2.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (1.1.2)
Requirement already satisfied: Flask-cors<4.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (3.0.8)
Requirement already satisfied: redis<4.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (3.4.1)
Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (2.23.0)
Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (1.18.1)
Requirement already satisfied: flatbuffers<2.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (1.12)
Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (3.11.3)
Requirement already satisfied: grpcio<2.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (1.27.2)
Requirement already satisfied: Flask-OpenTracing<1.2.0,>=1.1.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (1.1.0)
Requirement already satisfied: opentracing<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (2.2.0)
Requirement already satisfied: jaeger-client<4.2.0,>=4.1.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (4.1.0)
Requirement already satisfied: grpcio-opentracing<1.2.0,>=1.1.4 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (1.1.4)
Requirement already satisfied: pyaml<20.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (19.12.0)
Requirement already satisfied: gunicorn<20.1.0,>=19.9.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (20.0.4)
Requirement already satisfied: minio<6.0.0,>=4.0.9 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (5.0.8)
Requirement already satisfied: azure-storage-blob<3.0.0,>=2.0.1 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (2.1.0)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (45.2.0)
Requirement already satisfied: prometheus_client<0.8.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from seldon-core==1.0.2) (0.7.1)
Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/site-packages (from Flask<2.0.0->seldon-core==1.0.2) (1.0.0)
Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/site-packages (from Flask<2.0.0->seldon-core==1.0.2) (7.1.1)
Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/site-packages (from Flask<2.0.0->seldon-core==1.0.2) (1.1.0)
Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/site-packages (from Flask<2.0.0->seldon-core==1.0.2) (2.11.1)
Requirement already satisfied: Six in /usr/local/lib/python3.6/site-packages (from Flask-cors<4.0.0->seldon-core==1.0.2) (1.14.0)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests<3.0.0->seldon-core==1.0.2) (2019.11.28)
Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests<3.0.0->seldon-core==1.0.2) (2.9)
Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests<3.0.0->seldon-core==1.0.2) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests<3.0.0->seldon-core==1.0.2) (1.25.8)
Requirement already satisfied: threadloop<2,>=1 in /usr/local/lib/python3.6/site-packages (from jaeger-client<4.2.0,>=4.1.0->seldon-core==1.0.2) (1.0.2)
Requirement already satisfied: thrift in /usr/local/lib/python3.6/site-packages (from jaeger-client<4.2.0,>=4.1.0->seldon-core==1.0.2) (0.13.0)
Requirement already satisfied: tornado<6,>=4.3 in /usr/local/lib/python3.6/site-packages (from jaeger-client<4.2.0,>=4.1.0->seldon-core==1.0.2) (5.1.1)
Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/site-packages (from pyaml<20.0.0->seldon-core==1.0.2) (5.3)
Requirement already satisfied: pytz in /usr/local/lib/python3.6/site-packages (from minio<6.0.0,>=4.0.9->seldon-core==1.0.2) (2019.3)
Requirement already satisfied: configparser in /usr/local/lib/python3.6/site-packages (from minio<6.0.0,>=4.0.9->seldon-core==1.0.2) (5.0.0)
Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/site-packages (from minio<6.0.0,>=4.0.9->seldon-core==1.0.2) (2.8.1)
Requirement already satisfied: azure-common>=1.1.5 in /usr/local/lib/python3.6/site-packages (from azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (1.1.25)
Requirement already satisfied: azure-storage-common~=2.1 in /usr/local/lib/python3.6/site-packages (from azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (2.1.0)
Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/site-packages (from Jinja2>=2.10.1->Flask<2.0.0->seldon-core==1.0.2) (1.1.1)
Requirement already satisfied: cryptography in /usr/local/lib/python3.6/site-packages (from azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (2.9)
Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/site-packages (from cryptography->azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (1.14.0)
Requirement already satisfied: pycparser in /usr/local/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon-core==1.0.2) (2.20)
Installing collected packages: seldon-core
  Attempting uninstall: seldon-core
    Found existing installation: seldon-core 1.0.2
    Uninstalling seldon-core-1.0.2:
      Successfully uninstalled seldon-core-1.0.2
  Running setup.py develop for seldon-core
Successfully installed seldon-core
# Run the core tests in parallel
pytest \
	--verbose \
	-s \
	-W ignore \
	-n "4" \
	-m "not sequential and not notebooks" 2>&1
============================= test session starts ==============================
platform linux -- Python 3.6.10, pytest-5.3.1, py-1.8.1, pluggy-0.13.1 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspace/source/testing/scripts, inifile: setup.cfg
plugins: xdist-1.30.0, forked-1.1.3, flaky-3.6.1, cov-2.8.1
gw0 I / gw1 I / gw2 I / gw3 I
[gw0] linux Python 3.6.10 cwd: /workspace/source/testing/scripts
[gw1] linux Python 3.6.10 cwd: /workspace/source/testing/scripts
[gw2] linux Python 3.6.10 cwd: /workspace/source/testing/scripts
[gw3] linux Python 3.6.10 cwd: /workspace/source/testing/scripts
[gw0] Python 3.6.10 (default, Feb 28 2020, 10:20:25)  -- [GCC 8.3.0]
[gw1] Python 3.6.10 (default, Feb 28 2020, 10:20:25)  -- [GCC 8.3.0]
[gw3] Python 3.6.10 (default, Feb 28 2020, 10:20:25)  -- [GCC 8.3.0]
[gw2] Python 3.6.10 (default, Feb 28 2020, 10:20:25)  -- [GCC 8.3.0]
gw0 [28] / gw1 [28] / gw2 [28] / gw3 [28]

scheduling tests via LoadScheduling

test_bad_graphs.py::TestBadGraphs::test_duplicate_predictor_name 
test_api_version.py::test_api_version[machinelearning.seldon.io/v1alpha3] 
test_api_version.py::test_api_version[machinelearning.seldon.io/v1] 
test_api_version.py::test_api_version[machinelearning.seldon.io/v1alpha2] Error from server (SeldonDeployment.machinelearing.seldon.io "dupname" is invalid: [spec.predictors[1]: Invalid value: "mymodel": Duplicate predictor name, spec: Invalid value: "mymodel": Traffic must sum to 100 for multiple predictors]): error when creating "../resources/bad_duplicate_predictor_name.json": admission webhook "v1alpha2.vseldondeployment.kb.io" denied the request: SeldonDeployment.machinelearing.seldon.io "dupname" is invalid: [spec.predictors[1]: Invalid value: "mymodel": Duplicate predictor name, spec: Invalid value: "mymodel": Traffic must sum to 100 for multiple predictors]

[gw2] PASSED test_bad_graphs.py::TestBadGraphs::test_duplicate_predictor_name 
test_helm_charts_clusterwide.py::TestClusterWide::test_mab_model 
[gw3] FAILED test_api_version.py::test_api_version[machinelearning.seldon.io/v1] 
[gw0] FAILED test_api_version.py::test_api_version[machinelearning.seldon.io/v1alpha2] 
[gw2] FAILED test_helm_charts_clusterwide.py::TestClusterWide::test_mab_model 
[gw1] FAILED test_api_version.py::test_api_version[machinelearning.seldon.io/v1alpha3] 
test_helm_charts_clusterwide.py::TestClusterWide::test_single_model 
test_helm_charts_clusterwide.py::TestClusterWide::test_abtest_model 
test_bad_graphs.py::TestBadGraphs::test_model_name_mismatch Error from server (SeldonDeployment.machinelearing.seldon.io "namemismatch" is invalid: spec.predictors[0].graph: Invalid value: "complex-model_bad_name": Can't find container for Predictive Unit): error when creating "../resources/bad_name_mismatch.json": admission webhook "v1alpha2.vseldondeployment.kb.io" denied the request: SeldonDeployment.machinelearing.seldon.io "namemismatch" is invalid: spec.predictors[0].graph: Invalid value: "complex-model_bad_name": Can't find container for Predictive Unit

[gw0] PASSED test_bad_graphs.py::TestBadGraphs::test_model_name_mismatch 
test_prepackaged_servers.py::TestPrepack::test_tfserving 
test_local_operators.py::TestLocalOperators::test_namespace_operator 
[gw2] FAILED test_local_operators.py::TestLocalOperators::test_namespace_operator 
[gw1] FAILED test_helm_charts_clusterwide.py::TestClusterWide::test_single_model 
[gw3] FAILED test_helm_charts_clusterwide.py::TestClusterWide::test_abtest_model 
test_prepackaged_servers.py::TestPrepack::test_mlflow 
test_local_operators.py::TestLocalOperators::test_labelled_operator 
test_prepackaged_servers.py::TestPrepack::test_sklearn Error from server (InternalError): error when creating "../resources/model_controller_id.yaml": Internal error occurred: failed calling webhook "v1alpha2.mseldondeployment.kb.io": Post https://seldon-webhook-service.test-labelled-operator.svc:443/mutate-machinelearning-seldon-io-v1alpha2-seldondeployment?timeout=30s: dial tcp 10.107.254.206:443: connect: connection refused

[gw0] FAILED test_prepackaged_servers.py::TestPrepack::test_tfserving 
test_prepackaged_servers.py::TestPrepack::test_xgboost 
[gw1] FAILED test_local_operators.py::TestLocalOperators::test_labelled_operator 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph2.json-True-ambas] 
[gw3] FAILED test_prepackaged_servers.py::TestPrepack::test_sklearn 
[gw2] FAILED test_prepackaged_servers.py::TestPrepack::test_mlflow 
[gw0] FAILED test_prepackaged_servers.py::TestPrepack::test_xgboost 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph2.json-True-istio] 
test_prepackaged_servers.py::TestPrepack::test_text_alibi_explainer 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph3.json-True-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph2.json-True-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph2.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph3.json-True-ambas] 
[gw2] FAILED test_prepackaged_servers.py::TestPrepack::test_text_alibi_explainer 
[gw1] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph2.json-True-ambas] 
[gw3] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph2.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph4.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph3.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph4.json-True-ambas] 
[gw0] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph3.json-True-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph5.json-True-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph4.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph3.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph4.json-True-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph5.json-True-ambas] 
[gw2] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph4.json-True-istio] 
[gw1] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph3.json-True-istio] 
[gw3] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph4.json-True-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph8.json-True-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph5.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph8.json-True-istio] 
[gw0] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph5.json-True-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph7.json-graph8.json-False-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph8.json-True-ambas] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph5.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph1.json-graph8.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph7.json-graph8.json-False-ambas] 
[gw1] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph8.json-True-ambas] 
[gw2] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph5.json-True-istio] 
[gw3] FAILED test_rolling_updates.py::test_rolling_deployment[graph1.json-graph8.json-True-istio] 
test_rolling_updates.py::test_rolling_deployment[graph7.json-graph8.json-False-istio] 
test_tracing.py::test_tracing_rest 
[gw0] FAILED test_rolling_updates.py::test_rolling_deployment[graph7.json-graph8.json-False-ambas] 
[gw2] FAILED test_tracing.py::test_tracing_rest 
test_rolling_updates.py::test_rolling_deployment[graph7.json-graph8.json-False-istio] 
[gw1] FAILED test_rolling_updates.py::test_rolling_deployment[graph7.json-graph8.json-False-istio] 

=================================== FAILURES ===================================
________________ test_api_version[machinelearning.seldon.io/v1] ________________
[gw3] linux -- Python 3.6.10 /usr/local/bin/python

self = <urllib3.connection.HTTPConnection object at 0x7f93090487b8>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
>               (self._dns_host, self.port), self.timeout, **extra_kw
            )

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
                sock.connect(sa)
                return sock
    
            except socket.error as e:
                err = e
                if sock is not None:
                    sock.close()
                    sock = None
    
        if err is not None:
>           raise err

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:84: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:74: ConnectionRefusedError

During handling of the above exception, another exception occurred:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9309048a90>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5574196785620934, 0.3757944126834958, 0.5634798840574784, 0.7080818122322483, 0.25490401909537885]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f930906e390>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f9309048908>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
>               chunked=chunked,
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:672: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9309048a90>
conn = <urllib3.connection.HTTPConnection object at 0x7f93090487b8>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions'
timeout = <urllib3.util.timeout.Timeout object at 0x7f9309048908>
chunked = False
httplib_request_kw = {'body': b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5574196785620934, 0.3757944126834958, 0.5634798840574784...p, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}}
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f93090489b0>

    def _make_request(
        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw
    ):
        """
        Perform a request on a given urllib connection object taken from our
        pool.
    
        :param conn:
            a connection from one of our connection pools
    
        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        """
        self.num_requests += 1
    
        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = timeout_obj.connect_timeout
    
        # Trigger any extra validation we need to do.
        try:
            self._validate_conn(conn)
        except (SocketTimeout, BaseSSLError) as e:
            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.
            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
            raise
    
        # conn.request() calls httplib.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        if chunked:
            conn.request_chunked(method, url, **httplib_request_kw)
        else:
>           conn.request(method, url, **httplib_request_kw)

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f93090487b8>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5574196785620934, 0.3757944126834958, 0.5634798840574784, 0.7080818122322483, 0.25490401909537885]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}

    def request(self, method, url, body=None, headers={}, *,
                encode_chunked=False):
        """Send a complete request to the server."""
>       self._send_request(method, url, body, headers, encode_chunked)

/usr/local/lib/python3.6/http/client.py:1262: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f93090487b8>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5574196785620934, 0.3757944126834958, 0.5634798840574784, 0.7080818122322483, 0.25490401909537885]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}
encode_chunked = False

    def _send_request(self, method, url, body, headers, encode_chunked):
        # Honor explicitly requested Host: and Accept-Encoding: headers.
        header_names = frozenset(k.lower() for k in headers)
        skips = {}
        if 'host' in header_names:
            skips['skip_host'] = 1
        if 'accept-encoding' in header_names:
            skips['skip_accept_encoding'] = 1
    
        self.putrequest(method, url, **skips)
    
        # chunked encoding will happen if HTTP/1.1 is used and either
        # the caller passes encode_chunked=True or the following
        # conditions hold:
        # 1. content-length has not been explicitly set
        # 2. the body is a file or iterable, but not a str or bytes-like
        # 3. Transfer-Encoding has NOT been explicitly set by the caller
    
        if 'content-length' not in header_names:
            # only chunk body if not explicitly set for backwards
            # compatibility, assuming the client code is already handling the
            # chunking
            if 'transfer-encoding' not in header_names:
                # if content-length cannot be automatically determined, fall
                # back to chunked encoding
                encode_chunked = False
                content_length = self._get_content_length(body, method)
                if content_length is None:
                    if body is not None:
                        if self.debuglevel > 0:
                            print('Unable to determine size of %r' % body)
                        encode_chunked = True
                        self.putheader('Transfer-Encoding', 'chunked')
                else:
                    self.putheader('Content-Length', str(content_length))
        else:
            encode_chunked = False
    
        for hdr, value in headers.items():
            self.putheader(hdr, value)
        if isinstance(body, str):
            # RFC 2616 Section 3.7.1 says that text default has a
            # default charset of iso-8859-1.
            body = _encode(body, 'body')
>       self.endheaders(body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1308: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f93090487b8>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5574196785620934, 0.3757944126834958, 0.5634798840574784, 0.7080818122322483, 0.25490401909537885]}}}'

    def endheaders(self, message_body=None, *, encode_chunked=False):
        """Indicate that the last header line has been sent to the server.
    
        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        """
        if self.__state == _CS_REQ_STARTED:
            self.__state = _CS_REQ_SENT
        else:
            raise CannotSendHeader()
>       self._send_output(message_body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f93090487b8>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5574196785620934, 0.3757944126834958, 0.5634798840574784, 0.7080818122322483, 0.25490401909537885]}}}'
encode_chunked = False

    def _send_output(self, message_body=None, encode_chunked=False):
        """Send the currently buffered request and clear the buffer.
    
        Appends an extra \\r\\n to the buffer.
        A message_body may be specified, to be appended to the request.
        """
        self._buffer.extend((b"", b""))
        msg = b"\r\n".join(self._buffer)
        del self._buffer[:]
>       self.send(msg)

/usr/local/lib/python3.6/http/client.py:1036: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f93090487b8>
data = b'POST /seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions HTTP/1.1\r\nHost: localhost\...zip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 152\r\nContent-Type: application/json\r\n\r\n'

    def send(self, data):
        """Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        """
    
        if self.sock is None:
            if self.auto_open:
>               self.connect()

/usr/local/lib/python3.6/http/client.py:974: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f93090487b8>

    def connect(self):
>       conn = self._new_conn()

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f93090487b8>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
                (self._dns_host, self.port), self.timeout, **extra_kw
            )
    
        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                "Connection to %s timed out. (connect timeout=%s)"
                % (self.host, self.timeout),
            )
    
        except SocketError as e:
            raise NewConnectionError(
>               self, "Failed to establish a new connection: %s" % e
            )
E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f93090487b8>: Failed to establish a new connection: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:169: NewConnectionError

During handling of the above exception, another exception occurred:

self = <requests.adapters.HTTPAdapter object at 0x7f930906ea90>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f930906e390>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
>                   timeout=timeout
                )

/usr/local/lib/python3.6/site-packages/requests/adapters.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9309048a90>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5574196785620934, 0.3757944126834958, 0.5634798840574784, 0.7080818122322483, 0.25490401909537885]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f930906e390>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f9309048908>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
            )
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Pass method to Response for length checking
            response_kw["request_method"] = method
    
            # Import httplib's response into our own wrapper object
            response = self.ResponseCls.from_httplib(
                httplib_response,
                pool=self,
                connection=response_conn,
                retries=retries,
                **response_kw
            )
    
            # Everything went great!
            clean_exit = True
    
        except queue.Empty:
            # Timed out by queue.
            raise EmptyPoolError(self, "No pool connections are available.")
    
        except (
            TimeoutError,
            HTTPException,
            SocketError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
        ) as e:
            # Discard the connection for these exceptions. It will be
            # replaced during the next _get_conn() call.
            clean_exit = False
            if isinstance(e, (BaseSSLError, CertificateError)):
                e = SSLError(e)
            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
                e = ProxyError("Cannot connect to proxy.", e)
            elif isinstance(e, (SocketError, HTTPException)):
                e = ProtocolError("Connection aborted.", e)
    
            retries = retries.increment(
>               method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=None, read=False, redirect=None, status=None)
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions'
response = None
error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f93090487b8>: Failed to establish a new connection: [Errno 111] Connection refused',)
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f9309048a90>
_stacktrace = <traceback object at 0x7f930906cf08>

    def increment(
        self,
        method=None,
        url=None,
        response=None,
        error=None,
        _pool=None,
        _stacktrace=None,
    ):
        """ Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.HTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise six.reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise six.reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or not self._is_method_retryable(method):
                raise six.reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            redirect_location = response.get_redirect_location()
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and a the given method is in the whitelist
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            history=history,
        )
    
        if new_retry.is_exhausted():
>           raise MaxRetryError(_pool, url, error or ResponseError(cause))
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f93090487b8>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:436: MaxRetryError

During handling of the above exception, another exception occurred:

self = <Retrying object at 0x7f934fdb0438 (stop=<tenacity.stop.stop_after_attempt object at 0x7f934fdb00b8>, wait=<tenacity.w...0x7f9324d07e48>, before=<function before_nothing at 0x7f9324d09510>, after=<function after_nothing at 0x7f9324d096a8>)>
fn = <function rest_request_ambassador at 0x7f93091a9d08>
args = ('mymodel', 'test-api-version-machinelearning-seldon-io-v1', 'localhost:80')
kwargs = {}, retry_state = <tenacity.RetryCallState object at 0x7f9309063fd0>
do = <tenacity.DoAttempt object at 0x7f9309063b38>

    def call(self, fn, *args, **kwargs):
        self.begin(fn)
    
        retry_state = RetryCallState(
            retry_object=self, fn=fn, args=args, kwargs=kwargs)
        while True:
            do = self.iter(retry_state=retry_state)
            if isinstance(do, DoAttempt):
                try:
>                   result = fn(*args, **kwargs)

/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

deployment_name = 'mymodel'
namespace = 'test-api-version-machinelearning-seldon-io-v1'
endpoint = 'localhost:80', data_size = 5, rows = 1, data = None
dtype = 'tensor', names = None, method = 'predict', predictor_name = 'default'

    @retry(wait=wait_exponential(max=10), stop=stop_after_attempt(5))
    def rest_request_ambassador(
        deployment_name,
        namespace,
        endpoint=API_AMBASSADOR,
        data_size=5,
        rows=1,
        data=None,
        dtype="tensor",
        names=None,
        method="predict",
        predictor_name="default",
    ):
        if data is None:
            shape, arr = create_random_data(data_size, rows)
        elif dtype == "tensor":
            shape = data.shape
            arr = data.flatten()
        else:
            arr = data
    
        if dtype == "tensor":
            payload = {"data": {"tensor": {"shape": shape, "values": arr.tolist()}}}
        else:
            payload = {"data": {"ndarray": arr}}
    
        if names is not None:
            payload["data"]["names"] = names
    
        if method == "predict":
            response = requests.post(
                "http://"
                + endpoint
                + "/seldon/"
                + namespace
                + "/"
                + deployment_name
                + "/api/v0.1/predictions",
>               json=payload,

seldon_e2e_utils.py:368: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

url = 'http://localhost:80/seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions'
data = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.5574196785620934, 0.3757944126834958, 0.5634798840574784, 0.7080818122322483, 0.25490401909537885]}}}
kwargs = {}

    def post(url, data=None, json=None, **kwargs):
        r"""Sends a POST request.
    
        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json data to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
        """
    
>       return request('post', url, data=data, json=json, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

method = 'post'
url = 'http://localhost:80/seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions'
kwargs = {'data': None, 'json': {'data': {'tensor': {'shape': [1, 5], 'values': [0.5574196785620934, 0.3757944126834958, 0.5634798840574784, 0.7080818122322483, 0.25490401909537885]}}}}
session = <requests.sessions.Session object at 0x7f930906e2b0>

    def request(method, url, **kwargs):
        """Constructs and sends a :class:`Request <Request>`.
    
        :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary, list of tuples or bytes to send
            in the query string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
        :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
            ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
            or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
            defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
            to add for the file.
        :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How many seconds to wait for the server to send data
            before giving up, as a float, or a :ref:`(connect timeout, read
            timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
                the server's TLS certificate, or a string, in which case it must be a path
                to a CA bundle to use. Defaults to ``True``.
        :param stream: (optional) if ``False``, the response content will be immediately downloaded.
        :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
    
        Usage::
    
          >>> import requests
          >>> req = requests.request('GET', 'https://httpbin.org/get')
          >>> req
          <Response [200]>
        """
    
        # By using the 'with' statement we are sure the session is closed, thus we
        # avoid leaving sockets open which can trigger a ResourceWarning in some
        # cases, and look like a memory leak in others.
        with sessions.Session() as session:
>           return session.request(method=method, url=url, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f930906e2b0>, method = 'post'
url = 'http://localhost:80/seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions'
params = None, data = None, headers = None, cookies = None, files = None
auth = None, timeout = None, allow_redirects = True, proxies = {}, hooks = None
stream = None, verify = None, cert = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.5574196785620934, 0.3757944126834958, 0.5634798840574784, 0.7080818122322483, 0.25490401909537885]}}}

    def request(self, method, url,
            params=None, data=None, headers=None, cookies=None, files=None,
            auth=None, timeout=None, allow_redirects=True, proxies=None,
            hooks=None, stream=None, verify=None, cert=None, json=None):
        """Constructs a :class:`Request <Request>`, prepares it and sends it.
        Returns :class:`Response <Response>` object.
    
        :param method: method for the new :class:`Request` object.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary or bytes to be sent in the query
            string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the
            :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the
            :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the
            :class:`Request`.
        :param files: (optional) Dictionary of ``'filename': file-like-objects``
            for multipart encoding upload.
        :param auth: (optional) Auth tuple or callable to enable
            Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Set to True by default.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol or protocol and
            hostname to the URL of the proxy.
        :param stream: (optional) whether to immediately download the response
            content. Defaults to ``False``.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
        :param cert: (optional) if String, path to ssl client cert file (.pem).
            If Tuple, ('cert', 'key') pair.
        :rtype: requests.Response
        """
        # Create the Request.
        req = Request(
            method=method.upper(),
            url=url,
            headers=headers,
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
    
        proxies = proxies or {}
    
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
    
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
>       resp = self.send(prep, **send_kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:530: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f930906e2b0>
request = <PreparedRequest [POST]>
kwargs = {'cert': None, 'proxies': OrderedDict(), 'stream': False, 'timeout': None, ...}
allow_redirects = True, stream = False, hooks = {'response': []}
adapter = <requests.adapters.HTTPAdapter object at 0x7f930906ea90>
start = 1586205405.6545925

    def send(self, request, **kwargs):
        """Send a given PreparedRequest.
    
        :rtype: requests.Response
        """
        # Set defaults that the hooks can utilize to ensure they always have
        # the correct parameters to reproduce the previous request.
        kwargs.setdefault('stream', self.stream)
        kwargs.setdefault('verify', self.verify)
        kwargs.setdefault('cert', self.cert)
        kwargs.setdefault('proxies', self.proxies)
    
        # It's possible that users might accidentally send a Request object.
        # Guard against that specific failure case.
        if isinstance(request, Request):
            raise ValueError('You can only send PreparedRequests.')
    
        # Set up variables needed for resolve_redirects and dispatching of hooks
        allow_redirects = kwargs.pop('allow_redirects', True)
        stream = kwargs.get('stream')
        hooks = request.hooks
    
        # Get the appropriate adapter to use
        adapter = self.get_adapter(url=request.url)
    
        # Start time (approximately) of the request
        start = preferred_clock()
    
        # Send the request
>       r = adapter.send(request, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x7f930906ea90>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f930906e390>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
                    timeout=timeout
                )
    
            # Send the request.
            else:
                if hasattr(conn, 'proxy_pool'):
                    conn = conn.proxy_pool
    
                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
    
                try:
                    low_conn.putrequest(request.method,
                                        url,
                                        skip_accept_encoding=True)
    
                    for header, value in request.headers.items():
                        low_conn.putheader(header, value)
    
                    low_conn.endheaders()
    
                    for i in request.body:
                        low_conn.send(hex(len(i))[2:].encode('utf-8'))
                        low_conn.send(b'\r\n')
                        low_conn.send(i)
                        low_conn.send(b'\r\n')
                    low_conn.send(b'0\r\n\r\n')
    
                    # Receive the response from the server
                    try:
                        # For Python 2.7, use buffering of HTTP responses
                        r = low_conn.getresponse(buffering=True)
                    except TypeError:
                        # For compatibility with Python 3.3+
                        r = low_conn.getresponse()
    
                    resp = HTTPResponse.from_httplib(
                        r,
                        pool=conn,
                        connection=low_conn,
                        preload_content=False,
                        decode_content=False
                    )
                except:
                    # If we hit any problems here, clean up the connection.
                    # Then, reraise so that we can handle the actual exception.
                    low_conn.close()
                    raise
    
        except (ProtocolError, socket.error) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-api-version-machinelearning-seldon-io-v1/mymodel/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f93090487b8>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/requests/adapters.py:516: ConnectionError

The above exception was the direct cause of the following exception:

namespace = 'test-api-version-machinelearning-seldon-io-v1'
apiVersion = 'machinelearning.seldon.io/v1'

    @pytest.mark.parametrize(
        "apiVersion",
        [
            "machinelearning.seldon.io/v1alpha2",
            "machinelearning.seldon.io/v1alpha3",
            "machinelearning.seldon.io/v1",
        ],
    )
    def test_api_version(namespace, apiVersion):
        command = (
            "helm install mymodel ../../helm-charts/seldon-single-model "
            f"--set apiVersion={apiVersion} "
            f"--namespace {namespace}"
        )
        run(command, shell=True, check=True)
    
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
        initial_rest_request("mymodel", namespace)
    
>       r = rest_request_ambassador("mymodel", namespace, API_AMBASSADOR)

test_api_version.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:311: in wrapped_f
    return self.call(f, *args, **kw)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:391: in call
    do = self.iter(retry_state=retry_state)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:351: in iter
    six.raise_from(retry_exc, fut.exception())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None
from_value = ConnectionError(MaxRetryError("HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/t...HTTPConnection object at 0x7f93090487b8>: Failed to establish a new connection: [Errno 111] Connection refused',))",),)

>   ???
E   tenacity.RetryError: RetryError[<Future at 0x7f9309048cf8 state=finished raised ConnectionError>]

<string>:3: RetryError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f9309032ac8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f93090324e0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f930906eba8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f9309063588 state=finished raised ConnectionError>]
_____________ test_api_version[machinelearning.seldon.io/v1alpha2] _____________
[gw0] linux -- Python 3.6.10 /usr/local/bin/python

self = <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
>               (self._dns_host, self.port), self.timeout, **extra_kw
            )

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
                sock.connect(sa)
                return sock
    
            except socket.error as e:
                err = e
                if sock is not None:
                    sock.close()
                    sock = None
    
        if err is not None:
>           raise err

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:84: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:74: ConnectionRefusedError

During handling of the above exception, another exception occurred:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f33a7baa9e8>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.24726988413924955, 0.7360572359348247, 0.8470741807698406, 0.8857391777427697, 0.2385864568699566]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f33a7baa240>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f33a7baa588>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
>               chunked=chunked,
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:672: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f33a7baa9e8>
conn = <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions'
timeout = <urllib3.util.timeout.Timeout object at 0x7f33a7baa588>
chunked = False
httplib_request_kw = {'body': b'{"data": {"tensor": {"shape": [1, 5], "values": [0.24726988413924955, 0.7360572359348247, 0.847074180769840...p, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}}
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f33a7baa470>

    def _make_request(
        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw
    ):
        """
        Perform a request on a given urllib connection object taken from our
        pool.
    
        :param conn:
            a connection from one of our connection pools
    
        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        """
        self.num_requests += 1
    
        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = timeout_obj.connect_timeout
    
        # Trigger any extra validation we need to do.
        try:
            self._validate_conn(conn)
        except (SocketTimeout, BaseSSLError) as e:
            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.
            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
            raise
    
        # conn.request() calls httplib.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        if chunked:
            conn.request_chunked(method, url, **httplib_request_kw)
        else:
>           conn.request(method, url, **httplib_request_kw)

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.24726988413924955, 0.7360572359348247, 0.8470741807698406, 0.8857391777427697, 0.2385864568699566]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}

    def request(self, method, url, body=None, headers={}, *,
                encode_chunked=False):
        """Send a complete request to the server."""
>       self._send_request(method, url, body, headers, encode_chunked)

/usr/local/lib/python3.6/http/client.py:1262: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.24726988413924955, 0.7360572359348247, 0.8470741807698406, 0.8857391777427697, 0.2385864568699566]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}
encode_chunked = False

    def _send_request(self, method, url, body, headers, encode_chunked):
        # Honor explicitly requested Host: and Accept-Encoding: headers.
        header_names = frozenset(k.lower() for k in headers)
        skips = {}
        if 'host' in header_names:
            skips['skip_host'] = 1
        if 'accept-encoding' in header_names:
            skips['skip_accept_encoding'] = 1
    
        self.putrequest(method, url, **skips)
    
        # chunked encoding will happen if HTTP/1.1 is used and either
        # the caller passes encode_chunked=True or the following
        # conditions hold:
        # 1. content-length has not been explicitly set
        # 2. the body is a file or iterable, but not a str or bytes-like
        # 3. Transfer-Encoding has NOT been explicitly set by the caller
    
        if 'content-length' not in header_names:
            # only chunk body if not explicitly set for backwards
            # compatibility, assuming the client code is already handling the
            # chunking
            if 'transfer-encoding' not in header_names:
                # if content-length cannot be automatically determined, fall
                # back to chunked encoding
                encode_chunked = False
                content_length = self._get_content_length(body, method)
                if content_length is None:
                    if body is not None:
                        if self.debuglevel > 0:
                            print('Unable to determine size of %r' % body)
                        encode_chunked = True
                        self.putheader('Transfer-Encoding', 'chunked')
                else:
                    self.putheader('Content-Length', str(content_length))
        else:
            encode_chunked = False
    
        for hdr, value in headers.items():
            self.putheader(hdr, value)
        if isinstance(body, str):
            # RFC 2616 Section 3.7.1 says that text default has a
            # default charset of iso-8859-1.
            body = _encode(body, 'body')
>       self.endheaders(body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1308: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.24726988413924955, 0.7360572359348247, 0.8470741807698406, 0.8857391777427697, 0.2385864568699566]}}}'

    def endheaders(self, message_body=None, *, encode_chunked=False):
        """Indicate that the last header line has been sent to the server.
    
        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        """
        if self.__state == _CS_REQ_STARTED:
            self.__state = _CS_REQ_SENT
        else:
            raise CannotSendHeader()
>       self._send_output(message_body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.24726988413924955, 0.7360572359348247, 0.8470741807698406, 0.8857391777427697, 0.2385864568699566]}}}'
encode_chunked = False

    def _send_output(self, message_body=None, encode_chunked=False):
        """Send the currently buffered request and clear the buffer.
    
        Appends an extra \\r\\n to the buffer.
        A message_body may be specified, to be appended to the request.
        """
        self._buffer.extend((b"", b""))
        msg = b"\r\n".join(self._buffer)
        del self._buffer[:]
>       self.send(msg)

/usr/local/lib/python3.6/http/client.py:1036: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>
data = b'POST /seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions HTTP/1.1\r\nHost: loca...zip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 152\r\nContent-Type: application/json\r\n\r\n'

    def send(self, data):
        """Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        """
    
        if self.sock is None:
            if self.auto_open:
>               self.connect()

/usr/local/lib/python3.6/http/client.py:974: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>

    def connect(self):
>       conn = self._new_conn()

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
                (self._dns_host, self.port), self.timeout, **extra_kw
            )
    
        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                "Connection to %s timed out. (connect timeout=%s)"
                % (self.host, self.timeout),
            )
    
        except SocketError as e:
            raise NewConnectionError(
>               self, "Failed to establish a new connection: %s" % e
            )
E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>: Failed to establish a new connection: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:169: NewConnectionError

During handling of the above exception, another exception occurred:

self = <requests.adapters.HTTPAdapter object at 0x7f33a7baac88>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f33a7baa240>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
>                   timeout=timeout
                )

/usr/local/lib/python3.6/site-packages/requests/adapters.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f33a7baa9e8>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.24726988413924955, 0.7360572359348247, 0.8470741807698406, 0.8857391777427697, 0.2385864568699566]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f33a7baa240>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f33a7baa588>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
            )
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Pass method to Response for length checking
            response_kw["request_method"] = method
    
            # Import httplib's response into our own wrapper object
            response = self.ResponseCls.from_httplib(
                httplib_response,
                pool=self,
                connection=response_conn,
                retries=retries,
                **response_kw
            )
    
            # Everything went great!
            clean_exit = True
    
        except queue.Empty:
            # Timed out by queue.
            raise EmptyPoolError(self, "No pool connections are available.")
    
        except (
            TimeoutError,
            HTTPException,
            SocketError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
        ) as e:
            # Discard the connection for these exceptions. It will be
            # replaced during the next _get_conn() call.
            clean_exit = False
            if isinstance(e, (BaseSSLError, CertificateError)):
                e = SSLError(e)
            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
                e = ProxyError("Cannot connect to proxy.", e)
            elif isinstance(e, (SocketError, HTTPException)):
                e = ProtocolError("Connection aborted.", e)
    
            retries = retries.increment(
>               method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=None, read=False, redirect=None, status=None)
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions'
response = None
error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>: Failed to establish a new connection: [Errno 111] Connection refused',)
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f33a7baa9e8>
_stacktrace = <traceback object at 0x7f33a7ba2048>

    def increment(
        self,
        method=None,
        url=None,
        response=None,
        error=None,
        _pool=None,
        _stacktrace=None,
    ):
        """ Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.HTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise six.reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise six.reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or not self._is_method_retryable(method):
                raise six.reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            redirect_location = response.get_redirect_location()
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and a the given method is in the whitelist
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            history=history,
        )
    
        if new_retry.is_exhausted():
>           raise MaxRetryError(_pool, url, error or ResponseError(cause))
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:436: MaxRetryError

During handling of the above exception, another exception occurred:

self = <Retrying object at 0x7f33f29b61d0 (stop=<tenacity.stop.stop_after_attempt object at 0x7f33f29b6390>, wait=<tenacity.w...0x7f33c38f8e10>, before=<function before_nothing at 0x7f33c38fa510>, after=<function after_nothing at 0x7f33c38fa6a8>)>
fn = <function rest_request_ambassador at 0x7f33a7d46d08>
args = ('mymodel', 'test-api-version-machinelearning-seldon-io-v1alpha2', 'localhost:80')
kwargs = {}, retry_state = <tenacity.RetryCallState object at 0x7f33a7cad748>
do = <tenacity.DoAttempt object at 0x7f33a7baa860>

    def call(self, fn, *args, **kwargs):
        self.begin(fn)
    
        retry_state = RetryCallState(
            retry_object=self, fn=fn, args=args, kwargs=kwargs)
        while True:
            do = self.iter(retry_state=retry_state)
            if isinstance(do, DoAttempt):
                try:
>                   result = fn(*args, **kwargs)

/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

deployment_name = 'mymodel'
namespace = 'test-api-version-machinelearning-seldon-io-v1alpha2'
endpoint = 'localhost:80', data_size = 5, rows = 1, data = None
dtype = 'tensor', names = None, method = 'predict', predictor_name = 'default'

    @retry(wait=wait_exponential(max=10), stop=stop_after_attempt(5))
    def rest_request_ambassador(
        deployment_name,
        namespace,
        endpoint=API_AMBASSADOR,
        data_size=5,
        rows=1,
        data=None,
        dtype="tensor",
        names=None,
        method="predict",
        predictor_name="default",
    ):
        if data is None:
            shape, arr = create_random_data(data_size, rows)
        elif dtype == "tensor":
            shape = data.shape
            arr = data.flatten()
        else:
            arr = data
    
        if dtype == "tensor":
            payload = {"data": {"tensor": {"shape": shape, "values": arr.tolist()}}}
        else:
            payload = {"data": {"ndarray": arr}}
    
        if names is not None:
            payload["data"]["names"] = names
    
        if method == "predict":
            response = requests.post(
                "http://"
                + endpoint
                + "/seldon/"
                + namespace
                + "/"
                + deployment_name
                + "/api/v0.1/predictions",
>               json=payload,

seldon_e2e_utils.py:368: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

url = 'http://localhost:80/seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions'
data = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.24726988413924955, 0.7360572359348247, 0.8470741807698406, 0.8857391777427697, 0.2385864568699566]}}}
kwargs = {}

    def post(url, data=None, json=None, **kwargs):
        r"""Sends a POST request.
    
        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json data to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
        """
    
>       return request('post', url, data=data, json=json, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

method = 'post'
url = 'http://localhost:80/seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions'
kwargs = {'data': None, 'json': {'data': {'tensor': {'shape': [1, 5], 'values': [0.24726988413924955, 0.7360572359348247, 0.8470741807698406, 0.8857391777427697, 0.2385864568699566]}}}}
session = <requests.sessions.Session object at 0x7f33a7baa710>

    def request(method, url, **kwargs):
        """Constructs and sends a :class:`Request <Request>`.
    
        :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary, list of tuples or bytes to send
            in the query string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
        :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
            ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
            or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
            defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
            to add for the file.
        :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How many seconds to wait for the server to send data
            before giving up, as a float, or a :ref:`(connect timeout, read
            timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
                the server's TLS certificate, or a string, in which case it must be a path
                to a CA bundle to use. Defaults to ``True``.
        :param stream: (optional) if ``False``, the response content will be immediately downloaded.
        :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
    
        Usage::
    
          >>> import requests
          >>> req = requests.request('GET', 'https://httpbin.org/get')
          >>> req
          <Response [200]>
        """
    
        # By using the 'with' statement we are sure the session is closed, thus we
        # avoid leaving sockets open which can trigger a ResourceWarning in some
        # cases, and look like a memory leak in others.
        with sessions.Session() as session:
>           return session.request(method=method, url=url, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f33a7baa710>, method = 'post'
url = 'http://localhost:80/seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions'
params = None, data = None, headers = None, cookies = None, files = None
auth = None, timeout = None, allow_redirects = True, proxies = {}, hooks = None
stream = None, verify = None, cert = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.24726988413924955, 0.7360572359348247, 0.8470741807698406, 0.8857391777427697, 0.2385864568699566]}}}

    def request(self, method, url,
            params=None, data=None, headers=None, cookies=None, files=None,
            auth=None, timeout=None, allow_redirects=True, proxies=None,
            hooks=None, stream=None, verify=None, cert=None, json=None):
        """Constructs a :class:`Request <Request>`, prepares it and sends it.
        Returns :class:`Response <Response>` object.
    
        :param method: method for the new :class:`Request` object.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary or bytes to be sent in the query
            string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the
            :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the
            :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the
            :class:`Request`.
        :param files: (optional) Dictionary of ``'filename': file-like-objects``
            for multipart encoding upload.
        :param auth: (optional) Auth tuple or callable to enable
            Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Set to True by default.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol or protocol and
            hostname to the URL of the proxy.
        :param stream: (optional) whether to immediately download the response
            content. Defaults to ``False``.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
        :param cert: (optional) if String, path to ssl client cert file (.pem).
            If Tuple, ('cert', 'key') pair.
        :rtype: requests.Response
        """
        # Create the Request.
        req = Request(
            method=method.upper(),
            url=url,
            headers=headers,
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
    
        proxies = proxies or {}
    
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
    
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
>       resp = self.send(prep, **send_kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:530: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f33a7baa710>
request = <PreparedRequest [POST]>
kwargs = {'cert': None, 'proxies': OrderedDict(), 'stream': False, 'timeout': None, ...}
allow_redirects = True, stream = False, hooks = {'response': []}
adapter = <requests.adapters.HTTPAdapter object at 0x7f33a7baac88>
start = 1586205405.6062052

    def send(self, request, **kwargs):
        """Send a given PreparedRequest.
    
        :rtype: requests.Response
        """
        # Set defaults that the hooks can utilize to ensure they always have
        # the correct parameters to reproduce the previous request.
        kwargs.setdefault('stream', self.stream)
        kwargs.setdefault('verify', self.verify)
        kwargs.setdefault('cert', self.cert)
        kwargs.setdefault('proxies', self.proxies)
    
        # It's possible that users might accidentally send a Request object.
        # Guard against that specific failure case.
        if isinstance(request, Request):
            raise ValueError('You can only send PreparedRequests.')
    
        # Set up variables needed for resolve_redirects and dispatching of hooks
        allow_redirects = kwargs.pop('allow_redirects', True)
        stream = kwargs.get('stream')
        hooks = request.hooks
    
        # Get the appropriate adapter to use
        adapter = self.get_adapter(url=request.url)
    
        # Start time (approximately) of the request
        start = preferred_clock()
    
        # Send the request
>       r = adapter.send(request, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x7f33a7baac88>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f33a7baa240>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
                    timeout=timeout
                )
    
            # Send the request.
            else:
                if hasattr(conn, 'proxy_pool'):
                    conn = conn.proxy_pool
    
                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
    
                try:
                    low_conn.putrequest(request.method,
                                        url,
                                        skip_accept_encoding=True)
    
                    for header, value in request.headers.items():
                        low_conn.putheader(header, value)
    
                    low_conn.endheaders()
    
                    for i in request.body:
                        low_conn.send(hex(len(i))[2:].encode('utf-8'))
                        low_conn.send(b'\r\n')
                        low_conn.send(i)
                        low_conn.send(b'\r\n')
                    low_conn.send(b'0\r\n\r\n')
    
                    # Receive the response from the server
                    try:
                        # For Python 2.7, use buffering of HTTP responses
                        r = low_conn.getresponse(buffering=True)
                    except TypeError:
                        # For compatibility with Python 3.3+
                        r = low_conn.getresponse()
    
                    resp = HTTPResponse.from_httplib(
                        r,
                        pool=conn,
                        connection=low_conn,
                        preload_content=False,
                        decode_content=False
                    )
                except:
                    # If we hit any problems here, clean up the connection.
                    # Then, reraise so that we can handle the actual exception.
                    low_conn.close()
                    raise
    
        except (ProtocolError, socket.error) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-api-version-machinelearning-seldon-io-v1alpha2/mymodel/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f33a7baa3c8>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/requests/adapters.py:516: ConnectionError

The above exception was the direct cause of the following exception:

namespace = 'test-api-version-machinelearning-seldon-io-v1alpha2'
apiVersion = 'machinelearning.seldon.io/v1alpha2'

    @pytest.mark.parametrize(
        "apiVersion",
        [
            "machinelearning.seldon.io/v1alpha2",
            "machinelearning.seldon.io/v1alpha3",
            "machinelearning.seldon.io/v1",
        ],
    )
    def test_api_version(namespace, apiVersion):
        command = (
            "helm install mymodel ../../helm-charts/seldon-single-model "
            f"--set apiVersion={apiVersion} "
            f"--namespace {namespace}"
        )
        run(command, shell=True, check=True)
    
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
        initial_rest_request("mymodel", namespace)
    
>       r = rest_request_ambassador("mymodel", namespace, API_AMBASSADOR)

test_api_version.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:311: in wrapped_f
    return self.call(f, *args, **kw)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:391: in call
    do = self.iter(retry_state=retry_state)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:351: in iter
    six.raise_from(retry_exc, fut.exception())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None
from_value = ConnectionError(MaxRetryError("HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/t...HTTPConnection object at 0x7f33a7baa3c8>: Failed to establish a new connection: [Errno 111] Connection refused',))",),)

>   ???
E   tenacity.RetryError: RetryError[<Future at 0x7f33a7baaa90 state=finished raised ConnectionError>]

<string>:3: RetryError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f33a7bbfbe0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f33a7bbfd68 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f33a7cad9b0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f33a7cad7f0 state=finished raised ConnectionError>]
________________________ TestClusterWide.test_mab_model ________________________
[gw2] linux -- Python 3.6.10 /usr/local/bin/python

self = <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
>               (self._dns_host, self.port), self.timeout, **extra_kw
            )

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
                sock.connect(sa)
                return sock
    
            except socket.error as e:
                err = e
                if sock is not None:
                    sock.close()
                    sock = None
    
        if err is not None:
>           raise err

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:84: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:74: ConnectionRefusedError

During handling of the above exception, another exception occurred:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6bcea876a0>
method = 'POST', url = '/seldon/test-mab-model/mymab/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5200723906989133, 0.7297219812314438, 0.9195557517742929, 0.012946596464821214, 0.5235269295753088]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bcea87438>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f6bcea87940>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
>               chunked=chunked,
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:672: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6bcea876a0>
conn = <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>
method = 'POST', url = '/seldon/test-mab-model/mymab/api/v0.1/predictions'
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bcea87940>
chunked = False
httplib_request_kw = {'body': b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5200723906989133, 0.7297219812314438, 0.9195557517742929...p, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}}
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f6bcea87cf8>

    def _make_request(
        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw
    ):
        """
        Perform a request on a given urllib connection object taken from our
        pool.
    
        :param conn:
            a connection from one of our connection pools
    
        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        """
        self.num_requests += 1
    
        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = timeout_obj.connect_timeout
    
        # Trigger any extra validation we need to do.
        try:
            self._validate_conn(conn)
        except (SocketTimeout, BaseSSLError) as e:
            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.
            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
            raise
    
        # conn.request() calls httplib.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        if chunked:
            conn.request_chunked(method, url, **httplib_request_kw)
        else:
>           conn.request(method, url, **httplib_request_kw)

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>
method = 'POST', url = '/seldon/test-mab-model/mymab/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5200723906989133, 0.7297219812314438, 0.9195557517742929, 0.012946596464821214, 0.5235269295753088]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}

    def request(self, method, url, body=None, headers={}, *,
                encode_chunked=False):
        """Send a complete request to the server."""
>       self._send_request(method, url, body, headers, encode_chunked)

/usr/local/lib/python3.6/http/client.py:1262: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>
method = 'POST', url = '/seldon/test-mab-model/mymab/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5200723906989133, 0.7297219812314438, 0.9195557517742929, 0.012946596464821214, 0.5235269295753088]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}
encode_chunked = False

    def _send_request(self, method, url, body, headers, encode_chunked):
        # Honor explicitly requested Host: and Accept-Encoding: headers.
        header_names = frozenset(k.lower() for k in headers)
        skips = {}
        if 'host' in header_names:
            skips['skip_host'] = 1
        if 'accept-encoding' in header_names:
            skips['skip_accept_encoding'] = 1
    
        self.putrequest(method, url, **skips)
    
        # chunked encoding will happen if HTTP/1.1 is used and either
        # the caller passes encode_chunked=True or the following
        # conditions hold:
        # 1. content-length has not been explicitly set
        # 2. the body is a file or iterable, but not a str or bytes-like
        # 3. Transfer-Encoding has NOT been explicitly set by the caller
    
        if 'content-length' not in header_names:
            # only chunk body if not explicitly set for backwards
            # compatibility, assuming the client code is already handling the
            # chunking
            if 'transfer-encoding' not in header_names:
                # if content-length cannot be automatically determined, fall
                # back to chunked encoding
                encode_chunked = False
                content_length = self._get_content_length(body, method)
                if content_length is None:
                    if body is not None:
                        if self.debuglevel > 0:
                            print('Unable to determine size of %r' % body)
                        encode_chunked = True
                        self.putheader('Transfer-Encoding', 'chunked')
                else:
                    self.putheader('Content-Length', str(content_length))
        else:
            encode_chunked = False
    
        for hdr, value in headers.items():
            self.putheader(hdr, value)
        if isinstance(body, str):
            # RFC 2616 Section 3.7.1 says that text default has a
            # default charset of iso-8859-1.
            body = _encode(body, 'body')
>       self.endheaders(body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1308: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5200723906989133, 0.7297219812314438, 0.9195557517742929, 0.012946596464821214, 0.5235269295753088]}}}'

    def endheaders(self, message_body=None, *, encode_chunked=False):
        """Indicate that the last header line has been sent to the server.
    
        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        """
        if self.__state == _CS_REQ_STARTED:
            self.__state = _CS_REQ_SENT
        else:
            raise CannotSendHeader()
>       self._send_output(message_body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5200723906989133, 0.7297219812314438, 0.9195557517742929, 0.012946596464821214, 0.5235269295753088]}}}'
encode_chunked = False

    def _send_output(self, message_body=None, encode_chunked=False):
        """Send the currently buffered request and clear the buffer.
    
        Appends an extra \\r\\n to the buffer.
        A message_body may be specified, to be appended to the request.
        """
        self._buffer.extend((b"", b""))
        msg = b"\r\n".join(self._buffer)
        del self._buffer[:]
>       self.send(msg)

/usr/local/lib/python3.6/http/client.py:1036: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>
data = b'POST /seldon/test-mab-model/mymab/api/v0.1/predictions HTTP/1.1\r\nHost: localhost\r\nUser-Agent: python-requests/2....zip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 153\r\nContent-Type: application/json\r\n\r\n'

    def send(self, data):
        """Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        """
    
        if self.sock is None:
            if self.auto_open:
>               self.connect()

/usr/local/lib/python3.6/http/client.py:974: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>

    def connect(self):
>       conn = self._new_conn()

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
                (self._dns_host, self.port), self.timeout, **extra_kw
            )
    
        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                "Connection to %s timed out. (connect timeout=%s)"
                % (self.host, self.timeout),
            )
    
        except SocketError as e:
            raise NewConnectionError(
>               self, "Failed to establish a new connection: %s" % e
            )
E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f6bcea87908>: Failed to establish a new connection: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:169: NewConnectionError

During handling of the above exception, another exception occurred:

self = <requests.adapters.HTTPAdapter object at 0x7f6bcea87400>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bcea87438>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
>                   timeout=timeout
                )

/usr/local/lib/python3.6/site-packages/requests/adapters.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6bcea876a0>
method = 'POST', url = '/seldon/test-mab-model/mymab/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5200723906989133, 0.7297219812314438, 0.9195557517742929, 0.012946596464821214, 0.5235269295753088]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bcea87438>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f6bcea87940>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
            )
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Pass method to Response for length checking
            response_kw["request_method"] = method
    
            # Import httplib's response into our own wrapper object
            response = self.ResponseCls.from_httplib(
                httplib_response,
                pool=self,
                connection=response_conn,
                retries=retries,
                **response_kw
            )
    
            # Everything went great!
            clean_exit = True
    
        except queue.Empty:
            # Timed out by queue.
            raise EmptyPoolError(self, "No pool connections are available.")
    
        except (
            TimeoutError,
            HTTPException,
            SocketError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
        ) as e:
            # Discard the connection for these exceptions. It will be
            # replaced during the next _get_conn() call.
            clean_exit = False
            if isinstance(e, (BaseSSLError, CertificateError)):
                e = SSLError(e)
            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
                e = ProxyError("Cannot connect to proxy.", e)
            elif isinstance(e, (SocketError, HTTPException)):
                e = ProtocolError("Connection aborted.", e)
    
            retries = retries.increment(
>               method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=None, read=False, redirect=None, status=None)
method = 'POST', url = '/seldon/test-mab-model/mymab/api/v0.1/predictions'
response = None
error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6bcea87908>: Failed to establish a new connection: [Errno 111] Connection refused',)
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6bcea876a0>
_stacktrace = <traceback object at 0x7f6bceae7f48>

    def increment(
        self,
        method=None,
        url=None,
        response=None,
        error=None,
        _pool=None,
        _stacktrace=None,
    ):
        """ Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.HTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise six.reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise six.reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or not self._is_method_retryable(method):
                raise six.reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            redirect_location = response.get_redirect_location()
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and a the given method is in the whitelist
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            history=history,
        )
    
        if new_retry.is_exhausted():
>           raise MaxRetryError(_pool, url, error or ResponseError(cause))
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-mab-model/mymab/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6bcea87908>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:436: MaxRetryError

During handling of the above exception, another exception occurred:

self = <Retrying object at 0x7f6c197c1470 (stop=<tenacity.stop.stop_after_attempt object at 0x7f6c197c1080>, wait=<tenacity.w...0x7f6bea6d5e10>, before=<function before_nothing at 0x7f6bea6d7510>, after=<function after_nothing at 0x7f6bea6d76a8>)>
fn = <function rest_request_ambassador at 0x7f6bcebc3d08>
args = ('mymab', 'test-mab-model', 'localhost:80'), kwargs = {}
retry_state = <tenacity.RetryCallState object at 0x7f6bcea55550>
do = <tenacity.DoAttempt object at 0x7f6bceac3fd0>

    def call(self, fn, *args, **kwargs):
        self.begin(fn)
    
        retry_state = RetryCallState(
            retry_object=self, fn=fn, args=args, kwargs=kwargs)
        while True:
            do = self.iter(retry_state=retry_state)
            if isinstance(do, DoAttempt):
                try:
>                   result = fn(*args, **kwargs)

/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

deployment_name = 'mymab', namespace = 'test-mab-model'
endpoint = 'localhost:80', data_size = 5, rows = 1, data = None
dtype = 'tensor', names = None, method = 'predict', predictor_name = 'default'

    @retry(wait=wait_exponential(max=10), stop=stop_after_attempt(5))
    def rest_request_ambassador(
        deployment_name,
        namespace,
        endpoint=API_AMBASSADOR,
        data_size=5,
        rows=1,
        data=None,
        dtype="tensor",
        names=None,
        method="predict",
        predictor_name="default",
    ):
        if data is None:
            shape, arr = create_random_data(data_size, rows)
        elif dtype == "tensor":
            shape = data.shape
            arr = data.flatten()
        else:
            arr = data
    
        if dtype == "tensor":
            payload = {"data": {"tensor": {"shape": shape, "values": arr.tolist()}}}
        else:
            payload = {"data": {"ndarray": arr}}
    
        if names is not None:
            payload["data"]["names"] = names
    
        if method == "predict":
            response = requests.post(
                "http://"
                + endpoint
                + "/seldon/"
                + namespace
                + "/"
                + deployment_name
                + "/api/v0.1/predictions",
>               json=payload,

seldon_e2e_utils.py:368: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

url = 'http://localhost:80/seldon/test-mab-model/mymab/api/v0.1/predictions'
data = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.5200723906989133, 0.7297219812314438, 0.9195557517742929, 0.012946596464821214, 0.5235269295753088]}}}
kwargs = {}

    def post(url, data=None, json=None, **kwargs):
        r"""Sends a POST request.
    
        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json data to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
        """
    
>       return request('post', url, data=data, json=json, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

method = 'post'
url = 'http://localhost:80/seldon/test-mab-model/mymab/api/v0.1/predictions'
kwargs = {'data': None, 'json': {'data': {'tensor': {'shape': [1, 5], 'values': [0.5200723906989133, 0.7297219812314438, 0.9195557517742929, 0.012946596464821214, 0.5235269295753088]}}}}
session = <requests.sessions.Session object at 0x7f6bcea9ffd0>

    def request(method, url, **kwargs):
        """Constructs and sends a :class:`Request <Request>`.
    
        :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary, list of tuples or bytes to send
            in the query string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
        :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
            ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
            or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
            defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
            to add for the file.
        :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How many seconds to wait for the server to send data
            before giving up, as a float, or a :ref:`(connect timeout, read
            timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
                the server's TLS certificate, or a string, in which case it must be a path
                to a CA bundle to use. Defaults to ``True``.
        :param stream: (optional) if ``False``, the response content will be immediately downloaded.
        :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
    
        Usage::
    
          >>> import requests
          >>> req = requests.request('GET', 'https://httpbin.org/get')
          >>> req
          <Response [200]>
        """
    
        # By using the 'with' statement we are sure the session is closed, thus we
        # avoid leaving sockets open which can trigger a ResourceWarning in some
        # cases, and look like a memory leak in others.
        with sessions.Session() as session:
>           return session.request(method=method, url=url, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f6bcea9ffd0>, method = 'post'
url = 'http://localhost:80/seldon/test-mab-model/mymab/api/v0.1/predictions'
params = None, data = None, headers = None, cookies = None, files = None
auth = None, timeout = None, allow_redirects = True, proxies = {}, hooks = None
stream = None, verify = None, cert = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.5200723906989133, 0.7297219812314438, 0.9195557517742929, 0.012946596464821214, 0.5235269295753088]}}}

    def request(self, method, url,
            params=None, data=None, headers=None, cookies=None, files=None,
            auth=None, timeout=None, allow_redirects=True, proxies=None,
            hooks=None, stream=None, verify=None, cert=None, json=None):
        """Constructs a :class:`Request <Request>`, prepares it and sends it.
        Returns :class:`Response <Response>` object.
    
        :param method: method for the new :class:`Request` object.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary or bytes to be sent in the query
            string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the
            :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the
            :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the
            :class:`Request`.
        :param files: (optional) Dictionary of ``'filename': file-like-objects``
            for multipart encoding upload.
        :param auth: (optional) Auth tuple or callable to enable
            Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Set to True by default.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol or protocol and
            hostname to the URL of the proxy.
        :param stream: (optional) whether to immediately download the response
            content. Defaults to ``False``.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
        :param cert: (optional) if String, path to ssl client cert file (.pem).
            If Tuple, ('cert', 'key') pair.
        :rtype: requests.Response
        """
        # Create the Request.
        req = Request(
            method=method.upper(),
            url=url,
            headers=headers,
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
    
        proxies = proxies or {}
    
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
    
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
>       resp = self.send(prep, **send_kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:530: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f6bcea9ffd0>
request = <PreparedRequest [POST]>
kwargs = {'cert': None, 'proxies': OrderedDict(), 'stream': False, 'timeout': None, ...}
allow_redirects = True, stream = False, hooks = {'response': []}
adapter = <requests.adapters.HTTPAdapter object at 0x7f6bcea87400>
start = 1586205407.1216364

    def send(self, request, **kwargs):
        """Send a given PreparedRequest.
    
        :rtype: requests.Response
        """
        # Set defaults that the hooks can utilize to ensure they always have
        # the correct parameters to reproduce the previous request.
        kwargs.setdefault('stream', self.stream)
        kwargs.setdefault('verify', self.verify)
        kwargs.setdefault('cert', self.cert)
        kwargs.setdefault('proxies', self.proxies)
    
        # It's possible that users might accidentally send a Request object.
        # Guard against that specific failure case.
        if isinstance(request, Request):
            raise ValueError('You can only send PreparedRequests.')
    
        # Set up variables needed for resolve_redirects and dispatching of hooks
        allow_redirects = kwargs.pop('allow_redirects', True)
        stream = kwargs.get('stream')
        hooks = request.hooks
    
        # Get the appropriate adapter to use
        adapter = self.get_adapter(url=request.url)
    
        # Start time (approximately) of the request
        start = preferred_clock()
    
        # Send the request
>       r = adapter.send(request, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x7f6bcea87400>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bcea87438>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
                    timeout=timeout
                )
    
            # Send the request.
            else:
                if hasattr(conn, 'proxy_pool'):
                    conn = conn.proxy_pool
    
                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
    
                try:
                    low_conn.putrequest(request.method,
                                        url,
                                        skip_accept_encoding=True)
    
                    for header, value in request.headers.items():
                        low_conn.putheader(header, value)
    
                    low_conn.endheaders()
    
                    for i in request.body:
                        low_conn.send(hex(len(i))[2:].encode('utf-8'))
                        low_conn.send(b'\r\n')
                        low_conn.send(i)
                        low_conn.send(b'\r\n')
                    low_conn.send(b'0\r\n\r\n')
    
                    # Receive the response from the server
                    try:
                        # For Python 2.7, use buffering of HTTP responses
                        r = low_conn.getresponse(buffering=True)
                    except TypeError:
                        # For compatibility with Python 3.3+
                        r = low_conn.getresponse()
    
                    resp = HTTPResponse.from_httplib(
                        r,
                        pool=conn,
                        connection=low_conn,
                        preload_content=False,
                        decode_content=False
                    )
                except:
                    # If we hit any problems here, clean up the connection.
                    # Then, reraise so that we can handle the actual exception.
                    low_conn.close()
                    raise
    
        except (ProtocolError, socket.error) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-mab-model/mymab/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6bcea87908>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/requests/adapters.py:516: ConnectionError

The above exception was the direct cause of the following exception:

self = <test_helm_charts_clusterwide.TestClusterWide object at 0x7f6bcea9f160>
namespace = 'test-mab-model'

    def test_mab_model(self, namespace):
        run(
            f"helm install mymab ../../helm-charts/seldon-mab --namespace {namespace}",
            shell=True,
            check=True,
        )
        wait_for_status("mymab", namespace)
        wait_for_rollout("mymab", namespace, expected_deployments=3)
        initial_rest_request("mymab", namespace)
        logging.warning("Test Ambassador REST gateway")
>       r = rest_request_ambassador("mymab", namespace, API_AMBASSADOR)

test_helm_charts_clusterwide.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:311: in wrapped_f
    return self.call(f, *args, **kw)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:391: in call
    do = self.iter(retry_state=retry_state)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:351: in iter
    six.raise_from(retry_exc, fut.exception())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None
from_value = ConnectionError(MaxRetryError("HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/t...HTTPConnection object at 0x7f6bcea87908>: Failed to establish a new connection: [Errno 111] Connection refused',))",),)

>   ???
E   tenacity.RetryError: RetryError[<Future at 0x7f6bcea87668 state=finished raised ConnectionError>]

<string>:3: RetryError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea4ac18 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea55320 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea4a7f0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea55e10 state=finished raised ConnectionError>]
WARNING  root:test_helm_charts_clusterwide.py:65 Test Ambassador REST gateway
_____________ test_api_version[machinelearning.seldon.io/v1alpha3] _____________
[gw1] linux -- Python 3.6.10 /usr/local/bin/python

self = <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
>               (self._dns_host, self.port), self.timeout, **extra_kw
            )

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
                sock.connect(sa)
                return sock
    
            except socket.error as e:
                err = e
                if sock is not None:
                    sock.close()
                    sock = None
    
        if err is not None:
>           raise err

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:84: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:74: ConnectionRefusedError

During handling of the above exception, another exception occurred:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fe10c6a8b38>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.7775628451768273, 0.9595809954400708, 0.222932807796415, 0.31813562165575604, 0.07184389180684436]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7fe10c6a8f60>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7fe10c7f4c18>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
>               chunked=chunked,
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:672: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fe10c6a8b38>
conn = <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions'
timeout = <urllib3.util.timeout.Timeout object at 0x7fe10c7f4c18>
chunked = False
httplib_request_kw = {'body': b'{"data": {"tensor": {"shape": [1, 5], "values": [0.7775628451768273, 0.9595809954400708, 0.222932807796415,...p, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}}
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7fe10c7f4eb8>

    def _make_request(
        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw
    ):
        """
        Perform a request on a given urllib connection object taken from our
        pool.
    
        :param conn:
            a connection from one of our connection pools
    
        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        """
        self.num_requests += 1
    
        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = timeout_obj.connect_timeout
    
        # Trigger any extra validation we need to do.
        try:
            self._validate_conn(conn)
        except (SocketTimeout, BaseSSLError) as e:
            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.
            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
            raise
    
        # conn.request() calls httplib.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        if chunked:
            conn.request_chunked(method, url, **httplib_request_kw)
        else:
>           conn.request(method, url, **httplib_request_kw)

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.7775628451768273, 0.9595809954400708, 0.222932807796415, 0.31813562165575604, 0.07184389180684436]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}

    def request(self, method, url, body=None, headers={}, *,
                encode_chunked=False):
        """Send a complete request to the server."""
>       self._send_request(method, url, body, headers, encode_chunked)

/usr/local/lib/python3.6/http/client.py:1262: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.7775628451768273, 0.9595809954400708, 0.222932807796415, 0.31813562165575604, 0.07184389180684436]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}
encode_chunked = False

    def _send_request(self, method, url, body, headers, encode_chunked):
        # Honor explicitly requested Host: and Accept-Encoding: headers.
        header_names = frozenset(k.lower() for k in headers)
        skips = {}
        if 'host' in header_names:
            skips['skip_host'] = 1
        if 'accept-encoding' in header_names:
            skips['skip_accept_encoding'] = 1
    
        self.putrequest(method, url, **skips)
    
        # chunked encoding will happen if HTTP/1.1 is used and either
        # the caller passes encode_chunked=True or the following
        # conditions hold:
        # 1. content-length has not been explicitly set
        # 2. the body is a file or iterable, but not a str or bytes-like
        # 3. Transfer-Encoding has NOT been explicitly set by the caller
    
        if 'content-length' not in header_names:
            # only chunk body if not explicitly set for backwards
            # compatibility, assuming the client code is already handling the
            # chunking
            if 'transfer-encoding' not in header_names:
                # if content-length cannot be automatically determined, fall
                # back to chunked encoding
                encode_chunked = False
                content_length = self._get_content_length(body, method)
                if content_length is None:
                    if body is not None:
                        if self.debuglevel > 0:
                            print('Unable to determine size of %r' % body)
                        encode_chunked = True
                        self.putheader('Transfer-Encoding', 'chunked')
                else:
                    self.putheader('Content-Length', str(content_length))
        else:
            encode_chunked = False
    
        for hdr, value in headers.items():
            self.putheader(hdr, value)
        if isinstance(body, str):
            # RFC 2616 Section 3.7.1 says that text default has a
            # default charset of iso-8859-1.
            body = _encode(body, 'body')
>       self.endheaders(body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1308: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.7775628451768273, 0.9595809954400708, 0.222932807796415, 0.31813562165575604, 0.07184389180684436]}}}'

    def endheaders(self, message_body=None, *, encode_chunked=False):
        """Indicate that the last header line has been sent to the server.
    
        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        """
        if self.__state == _CS_REQ_STARTED:
            self.__state = _CS_REQ_SENT
        else:
            raise CannotSendHeader()
>       self._send_output(message_body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.7775628451768273, 0.9595809954400708, 0.222932807796415, 0.31813562165575604, 0.07184389180684436]}}}'
encode_chunked = False

    def _send_output(self, message_body=None, encode_chunked=False):
        """Send the currently buffered request and clear the buffer.
    
        Appends an extra \\r\\n to the buffer.
        A message_body may be specified, to be appended to the request.
        """
        self._buffer.extend((b"", b""))
        msg = b"\r\n".join(self._buffer)
        del self._buffer[:]
>       self.send(msg)

/usr/local/lib/python3.6/http/client.py:1036: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>
data = b'POST /seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions HTTP/1.1\r\nHost: loca...zip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 152\r\nContent-Type: application/json\r\n\r\n'

    def send(self, data):
        """Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        """
    
        if self.sock is None:
            if self.auto_open:
>               self.connect()

/usr/local/lib/python3.6/http/client.py:974: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>

    def connect(self):
>       conn = self._new_conn()

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
                (self._dns_host, self.port), self.timeout, **extra_kw
            )
    
        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                "Connection to %s timed out. (connect timeout=%s)"
                % (self.host, self.timeout),
            )
    
        except SocketError as e:
            raise NewConnectionError(
>               self, "Failed to establish a new connection: %s" % e
            )
E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>: Failed to establish a new connection: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:169: NewConnectionError

During handling of the above exception, another exception occurred:

self = <requests.adapters.HTTPAdapter object at 0x7fe10c6a8cf8>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7fe10c6a8f60>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
>                   timeout=timeout
                )

/usr/local/lib/python3.6/site-packages/requests/adapters.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fe10c6a8b38>
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.7775628451768273, 0.9595809954400708, 0.222932807796415, 0.31813562165575604, 0.07184389180684436]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '152', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7fe10c6a8f60>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7fe10c7f4c18>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
            )
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Pass method to Response for length checking
            response_kw["request_method"] = method
    
            # Import httplib's response into our own wrapper object
            response = self.ResponseCls.from_httplib(
                httplib_response,
                pool=self,
                connection=response_conn,
                retries=retries,
                **response_kw
            )
    
            # Everything went great!
            clean_exit = True
    
        except queue.Empty:
            # Timed out by queue.
            raise EmptyPoolError(self, "No pool connections are available.")
    
        except (
            TimeoutError,
            HTTPException,
            SocketError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
        ) as e:
            # Discard the connection for these exceptions. It will be
            # replaced during the next _get_conn() call.
            clean_exit = False
            if isinstance(e, (BaseSSLError, CertificateError)):
                e = SSLError(e)
            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
                e = ProxyError("Cannot connect to proxy.", e)
            elif isinstance(e, (SocketError, HTTPException)):
                e = ProtocolError("Connection aborted.", e)
    
            retries = retries.increment(
>               method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=None, read=False, redirect=None, status=None)
method = 'POST'
url = '/seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions'
response = None
error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>: Failed to establish a new connection: [Errno 111] Connection refused',)
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fe10c6a8b38>
_stacktrace = <traceback object at 0x7fe10c781608>

    def increment(
        self,
        method=None,
        url=None,
        response=None,
        error=None,
        _pool=None,
        _stacktrace=None,
    ):
        """ Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.HTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise six.reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise six.reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or not self._is_method_retryable(method):
                raise six.reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            redirect_location = response.get_redirect_location()
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and a the given method is in the whitelist
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            history=history,
        )
    
        if new_retry.is_exhausted():
>           raise MaxRetryError(_pool, url, error or ResponseError(cause))
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:436: MaxRetryError

During handling of the above exception, another exception occurred:

self = <Retrying object at 0x7fe1534ad1d0 (stop=<tenacity.stop.stop_after_attempt object at 0x7fe1534ad240>, wait=<tenacity.w...0x7fe128405e48>, before=<function before_nothing at 0x7fe128407510>, after=<function after_nothing at 0x7fe1284076a8>)>
fn = <function rest_request_ambassador at 0x7fe10c8a7d08>
args = ('mymodel', 'test-api-version-machinelearning-seldon-io-v1alpha3', 'localhost:80')
kwargs = {}, retry_state = <tenacity.RetryCallState object at 0x7fe10c7f4a20>
do = <tenacity.DoAttempt object at 0x7fe10c6a8eb8>

    def call(self, fn, *args, **kwargs):
        self.begin(fn)
    
        retry_state = RetryCallState(
            retry_object=self, fn=fn, args=args, kwargs=kwargs)
        while True:
            do = self.iter(retry_state=retry_state)
            if isinstance(do, DoAttempt):
                try:
>                   result = fn(*args, **kwargs)

/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

deployment_name = 'mymodel'
namespace = 'test-api-version-machinelearning-seldon-io-v1alpha3'
endpoint = 'localhost:80', data_size = 5, rows = 1, data = None
dtype = 'tensor', names = None, method = 'predict', predictor_name = 'default'

    @retry(wait=wait_exponential(max=10), stop=stop_after_attempt(5))
    def rest_request_ambassador(
        deployment_name,
        namespace,
        endpoint=API_AMBASSADOR,
        data_size=5,
        rows=1,
        data=None,
        dtype="tensor",
        names=None,
        method="predict",
        predictor_name="default",
    ):
        if data is None:
            shape, arr = create_random_data(data_size, rows)
        elif dtype == "tensor":
            shape = data.shape
            arr = data.flatten()
        else:
            arr = data
    
        if dtype == "tensor":
            payload = {"data": {"tensor": {"shape": shape, "values": arr.tolist()}}}
        else:
            payload = {"data": {"ndarray": arr}}
    
        if names is not None:
            payload["data"]["names"] = names
    
        if method == "predict":
            response = requests.post(
                "http://"
                + endpoint
                + "/seldon/"
                + namespace
                + "/"
                + deployment_name
                + "/api/v0.1/predictions",
>               json=payload,

seldon_e2e_utils.py:368: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

url = 'http://localhost:80/seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions'
data = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.7775628451768273, 0.9595809954400708, 0.222932807796415, 0.31813562165575604, 0.07184389180684436]}}}
kwargs = {}

    def post(url, data=None, json=None, **kwargs):
        r"""Sends a POST request.
    
        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json data to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
        """
    
>       return request('post', url, data=data, json=json, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

method = 'post'
url = 'http://localhost:80/seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions'
kwargs = {'data': None, 'json': {'data': {'tensor': {'shape': [1, 5], 'values': [0.7775628451768273, 0.9595809954400708, 0.222932807796415, 0.31813562165575604, 0.07184389180684436]}}}}
session = <requests.sessions.Session object at 0x7fe10c6a8dd8>

    def request(method, url, **kwargs):
        """Constructs and sends a :class:`Request <Request>`.
    
        :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary, list of tuples or bytes to send
            in the query string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
        :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
            ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
            or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
            defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
            to add for the file.
        :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How many seconds to wait for the server to send data
            before giving up, as a float, or a :ref:`(connect timeout, read
            timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
                the server's TLS certificate, or a string, in which case it must be a path
                to a CA bundle to use. Defaults to ``True``.
        :param stream: (optional) if ``False``, the response content will be immediately downloaded.
        :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
    
        Usage::
    
          >>> import requests
          >>> req = requests.request('GET', 'https://httpbin.org/get')
          >>> req
          <Response [200]>
        """
    
        # By using the 'with' statement we are sure the session is closed, thus we
        # avoid leaving sockets open which can trigger a ResourceWarning in some
        # cases, and look like a memory leak in others.
        with sessions.Session() as session:
>           return session.request(method=method, url=url, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7fe10c6a8dd8>, method = 'post'
url = 'http://localhost:80/seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions'
params = None, data = None, headers = None, cookies = None, files = None
auth = None, timeout = None, allow_redirects = True, proxies = {}, hooks = None
stream = None, verify = None, cert = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.7775628451768273, 0.9595809954400708, 0.222932807796415, 0.31813562165575604, 0.07184389180684436]}}}

    def request(self, method, url,
            params=None, data=None, headers=None, cookies=None, files=None,
            auth=None, timeout=None, allow_redirects=True, proxies=None,
            hooks=None, stream=None, verify=None, cert=None, json=None):
        """Constructs a :class:`Request <Request>`, prepares it and sends it.
        Returns :class:`Response <Response>` object.
    
        :param method: method for the new :class:`Request` object.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary or bytes to be sent in the query
            string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the
            :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the
            :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the
            :class:`Request`.
        :param files: (optional) Dictionary of ``'filename': file-like-objects``
            for multipart encoding upload.
        :param auth: (optional) Auth tuple or callable to enable
            Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Set to True by default.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol or protocol and
            hostname to the URL of the proxy.
        :param stream: (optional) whether to immediately download the response
            content. Defaults to ``False``.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
        :param cert: (optional) if String, path to ssl client cert file (.pem).
            If Tuple, ('cert', 'key') pair.
        :rtype: requests.Response
        """
        # Create the Request.
        req = Request(
            method=method.upper(),
            url=url,
            headers=headers,
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
    
        proxies = proxies or {}
    
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
    
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
>       resp = self.send(prep, **send_kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:530: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7fe10c6a8dd8>
request = <PreparedRequest [POST]>
kwargs = {'cert': None, 'proxies': OrderedDict(), 'stream': False, 'timeout': None, ...}
allow_redirects = True, stream = False, hooks = {'response': []}
adapter = <requests.adapters.HTTPAdapter object at 0x7fe10c6a8cf8>
start = 1586205407.8816123

    def send(self, request, **kwargs):
        """Send a given PreparedRequest.
    
        :rtype: requests.Response
        """
        # Set defaults that the hooks can utilize to ensure they always have
        # the correct parameters to reproduce the previous request.
        kwargs.setdefault('stream', self.stream)
        kwargs.setdefault('verify', self.verify)
        kwargs.setdefault('cert', self.cert)
        kwargs.setdefault('proxies', self.proxies)
    
        # It's possible that users might accidentally send a Request object.
        # Guard against that specific failure case.
        if isinstance(request, Request):
            raise ValueError('You can only send PreparedRequests.')
    
        # Set up variables needed for resolve_redirects and dispatching of hooks
        allow_redirects = kwargs.pop('allow_redirects', True)
        stream = kwargs.get('stream')
        hooks = request.hooks
    
        # Get the appropriate adapter to use
        adapter = self.get_adapter(url=request.url)
    
        # Start time (approximately) of the request
        start = preferred_clock()
    
        # Send the request
>       r = adapter.send(request, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x7fe10c6a8cf8>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7fe10c6a8f60>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
                    timeout=timeout
                )
    
            # Send the request.
            else:
                if hasattr(conn, 'proxy_pool'):
                    conn = conn.proxy_pool
    
                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
    
                try:
                    low_conn.putrequest(request.method,
                                        url,
                                        skip_accept_encoding=True)
    
                    for header, value in request.headers.items():
                        low_conn.putheader(header, value)
    
                    low_conn.endheaders()
    
                    for i in request.body:
                        low_conn.send(hex(len(i))[2:].encode('utf-8'))
                        low_conn.send(b'\r\n')
                        low_conn.send(i)
                        low_conn.send(b'\r\n')
                    low_conn.send(b'0\r\n\r\n')
    
                    # Receive the response from the server
                    try:
                        # For Python 2.7, use buffering of HTTP responses
                        r = low_conn.getresponse(buffering=True)
                    except TypeError:
                        # For compatibility with Python 3.3+
                        r = low_conn.getresponse()
    
                    resp = HTTPResponse.from_httplib(
                        r,
                        pool=conn,
                        connection=low_conn,
                        preload_content=False,
                        decode_content=False
                    )
                except:
                    # If we hit any problems here, clean up the connection.
                    # Then, reraise so that we can handle the actual exception.
                    low_conn.close()
                    raise
    
        except (ProtocolError, socket.error) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-api-version-machinelearning-seldon-io-v1alpha3/mymodel/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe10c7f4358>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/requests/adapters.py:516: ConnectionError

The above exception was the direct cause of the following exception:

namespace = 'test-api-version-machinelearning-seldon-io-v1alpha3'
apiVersion = 'machinelearning.seldon.io/v1alpha3'

    @pytest.mark.parametrize(
        "apiVersion",
        [
            "machinelearning.seldon.io/v1alpha2",
            "machinelearning.seldon.io/v1alpha3",
            "machinelearning.seldon.io/v1",
        ],
    )
    def test_api_version(namespace, apiVersion):
        command = (
            "helm install mymodel ../../helm-charts/seldon-single-model "
            f"--set apiVersion={apiVersion} "
            f"--namespace {namespace}"
        )
        run(command, shell=True, check=True)
    
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
        initial_rest_request("mymodel", namespace)
    
>       r = rest_request_ambassador("mymodel", namespace, API_AMBASSADOR)

test_api_version.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:311: in wrapped_f
    return self.call(f, *args, **kw)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:391: in call
    do = self.iter(retry_state=retry_state)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:351: in iter
    six.raise_from(retry_exc, fut.exception())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None
from_value = ConnectionError(MaxRetryError("HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/t...HTTPConnection object at 0x7fe10c7f4358>: Failed to establish a new connection: [Errno 111] Connection refused',))",),)

>   ???
E   tenacity.RetryError: RetryError[<Future at 0x7fe10c6a8ba8 state=finished raised ConnectionError>]

<string>:3: RetryError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c703240 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c703a20 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c795e10 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c7f4cf8 state=finished raised ConnectionError>]
__________________ TestLocalOperators.test_namespace_operator __________________
[gw2] linux -- Python 3.6.10 /usr/local/bin/python

self = <test_local_operators.TestLocalOperators object at 0x7f6bcea55b00>
namespace = 'test-namespace-operator'

    def test_namespace_operator(self, namespace):
        retry_run(
            f"helm install seldon ../../helm-charts/seldon-core-operator --namespace {namespace} --set executor.enabled=true --set istio.enabled=true --set istio.gateway=seldon-gateway --set certManager.enabled=false --set crd.create=false --set singleNamespace=true"
        )
        retry_run(f"kubectl apply -f ../resources/graph1.json -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
        logging.warning("Initial request")
        r = initial_rest_request("mymodel", namespace, endpoint=API_AMBASSADOR)
>       assert r.status_code == 200
E       AttributeError: 'NoneType' object has no attribute 'status_code'

test_local_operators.py:23: AttributeError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:test_local_operators.py:21 Initial request
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc30e58d0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3169ba8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc30e52e8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc327d978 state=finished raised ConnectionError>]
______________________ TestClusterWide.test_single_model _______________________
[gw1] linux -- Python 3.6.10 /usr/local/bin/python

self = <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
>               (self._dns_host, self.port), self.timeout, **extra_kw
            )

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
                sock.connect(sa)
                return sock
    
            except socket.error as e:
                err = e
                if sock is not None:
                    sock.close()
                    sock = None
    
        if err is not None:
>           raise err

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:84: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:74: ConnectionRefusedError

During handling of the above exception, another exception occurred:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fe101037e80>
method = 'POST', url = '/seldon/test-single-model/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5637596792676798, 0.04786007889340116, 0.5732820683295226, 0.07736556182206544, 0.5659573164689461]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7fe1010379b0>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7fe100dd8cf8>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
>               chunked=chunked,
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:672: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fe101037e80>
conn = <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>
method = 'POST', url = '/seldon/test-single-model/mymodel/api/v0.1/predictions'
timeout = <urllib3.util.timeout.Timeout object at 0x7fe100dd8cf8>
chunked = False
httplib_request_kw = {'body': b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5637596792676798, 0.04786007889340116, 0.573282068329522...p, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}}
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7fe100dd89e8>

    def _make_request(
        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw
    ):
        """
        Perform a request on a given urllib connection object taken from our
        pool.
    
        :param conn:
            a connection from one of our connection pools
    
        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        """
        self.num_requests += 1
    
        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = timeout_obj.connect_timeout
    
        # Trigger any extra validation we need to do.
        try:
            self._validate_conn(conn)
        except (SocketTimeout, BaseSSLError) as e:
            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.
            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
            raise
    
        # conn.request() calls httplib.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        if chunked:
            conn.request_chunked(method, url, **httplib_request_kw)
        else:
>           conn.request(method, url, **httplib_request_kw)

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>
method = 'POST', url = '/seldon/test-single-model/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5637596792676798, 0.04786007889340116, 0.5732820683295226, 0.07736556182206544, 0.5659573164689461]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}

    def request(self, method, url, body=None, headers={}, *,
                encode_chunked=False):
        """Send a complete request to the server."""
>       self._send_request(method, url, body, headers, encode_chunked)

/usr/local/lib/python3.6/http/client.py:1262: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>
method = 'POST', url = '/seldon/test-single-model/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5637596792676798, 0.04786007889340116, 0.5732820683295226, 0.07736556182206544, 0.5659573164689461]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}
encode_chunked = False

    def _send_request(self, method, url, body, headers, encode_chunked):
        # Honor explicitly requested Host: and Accept-Encoding: headers.
        header_names = frozenset(k.lower() for k in headers)
        skips = {}
        if 'host' in header_names:
            skips['skip_host'] = 1
        if 'accept-encoding' in header_names:
            skips['skip_accept_encoding'] = 1
    
        self.putrequest(method, url, **skips)
    
        # chunked encoding will happen if HTTP/1.1 is used and either
        # the caller passes encode_chunked=True or the following
        # conditions hold:
        # 1. content-length has not been explicitly set
        # 2. the body is a file or iterable, but not a str or bytes-like
        # 3. Transfer-Encoding has NOT been explicitly set by the caller
    
        if 'content-length' not in header_names:
            # only chunk body if not explicitly set for backwards
            # compatibility, assuming the client code is already handling the
            # chunking
            if 'transfer-encoding' not in header_names:
                # if content-length cannot be automatically determined, fall
                # back to chunked encoding
                encode_chunked = False
                content_length = self._get_content_length(body, method)
                if content_length is None:
                    if body is not None:
                        if self.debuglevel > 0:
                            print('Unable to determine size of %r' % body)
                        encode_chunked = True
                        self.putheader('Transfer-Encoding', 'chunked')
                else:
                    self.putheader('Content-Length', str(content_length))
        else:
            encode_chunked = False
    
        for hdr, value in headers.items():
            self.putheader(hdr, value)
        if isinstance(body, str):
            # RFC 2616 Section 3.7.1 says that text default has a
            # default charset of iso-8859-1.
            body = _encode(body, 'body')
>       self.endheaders(body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1308: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5637596792676798, 0.04786007889340116, 0.5732820683295226, 0.07736556182206544, 0.5659573164689461]}}}'

    def endheaders(self, message_body=None, *, encode_chunked=False):
        """Indicate that the last header line has been sent to the server.
    
        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        """
        if self.__state == _CS_REQ_STARTED:
            self.__state = _CS_REQ_SENT
        else:
            raise CannotSendHeader()
>       self._send_output(message_body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5637596792676798, 0.04786007889340116, 0.5732820683295226, 0.07736556182206544, 0.5659573164689461]}}}'
encode_chunked = False

    def _send_output(self, message_body=None, encode_chunked=False):
        """Send the currently buffered request and clear the buffer.
    
        Appends an extra \\r\\n to the buffer.
        A message_body may be specified, to be appended to the request.
        """
        self._buffer.extend((b"", b""))
        msg = b"\r\n".join(self._buffer)
        del self._buffer[:]
>       self.send(msg)

/usr/local/lib/python3.6/http/client.py:1036: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>
data = b'POST /seldon/test-single-model/mymodel/api/v0.1/predictions HTTP/1.1\r\nHost: localhost\r\nUser-Agent: python-reques...zip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 153\r\nContent-Type: application/json\r\n\r\n'

    def send(self, data):
        """Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        """
    
        if self.sock is None:
            if self.auto_open:
>               self.connect()

/usr/local/lib/python3.6/http/client.py:974: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>

    def connect(self):
>       conn = self._new_conn()

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
                (self._dns_host, self.port), self.timeout, **extra_kw
            )
    
        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                "Connection to %s timed out. (connect timeout=%s)"
                % (self.host, self.timeout),
            )
    
        except SocketError as e:
            raise NewConnectionError(
>               self, "Failed to establish a new connection: %s" % e
            )
E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>: Failed to establish a new connection: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:169: NewConnectionError

During handling of the above exception, another exception occurred:

self = <requests.adapters.HTTPAdapter object at 0x7fe101037f98>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7fe1010379b0>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
>                   timeout=timeout
                )

/usr/local/lib/python3.6/site-packages/requests/adapters.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fe101037e80>
method = 'POST', url = '/seldon/test-single-model/mymodel/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.5637596792676798, 0.04786007889340116, 0.5732820683295226, 0.07736556182206544, 0.5659573164689461]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7fe1010379b0>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7fe100dd8cf8>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
            )
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Pass method to Response for length checking
            response_kw["request_method"] = method
    
            # Import httplib's response into our own wrapper object
            response = self.ResponseCls.from_httplib(
                httplib_response,
                pool=self,
                connection=response_conn,
                retries=retries,
                **response_kw
            )
    
            # Everything went great!
            clean_exit = True
    
        except queue.Empty:
            # Timed out by queue.
            raise EmptyPoolError(self, "No pool connections are available.")
    
        except (
            TimeoutError,
            HTTPException,
            SocketError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
        ) as e:
            # Discard the connection for these exceptions. It will be
            # replaced during the next _get_conn() call.
            clean_exit = False
            if isinstance(e, (BaseSSLError, CertificateError)):
                e = SSLError(e)
            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
                e = ProxyError("Cannot connect to proxy.", e)
            elif isinstance(e, (SocketError, HTTPException)):
                e = ProtocolError("Connection aborted.", e)
    
            retries = retries.increment(
>               method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=None, read=False, redirect=None, status=None)
method = 'POST', url = '/seldon/test-single-model/mymodel/api/v0.1/predictions'
response = None
error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>: Failed to establish a new connection: [Errno 111] Connection refused',)
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fe101037e80>
_stacktrace = <traceback object at 0x7fe100d36508>

    def increment(
        self,
        method=None,
        url=None,
        response=None,
        error=None,
        _pool=None,
        _stacktrace=None,
    ):
        """ Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.HTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise six.reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise six.reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or not self._is_method_retryable(method):
                raise six.reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            redirect_location = response.get_redirect_location()
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and a the given method is in the whitelist
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            history=history,
        )
    
        if new_retry.is_exhausted():
>           raise MaxRetryError(_pool, url, error or ResponseError(cause))
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-single-model/mymodel/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:436: MaxRetryError

During handling of the above exception, another exception occurred:

self = <Retrying object at 0x7fe1534ad1d0 (stop=<tenacity.stop.stop_after_attempt object at 0x7fe1534ad240>, wait=<tenacity.w...0x7fe128405e48>, before=<function before_nothing at 0x7fe128407510>, after=<function after_nothing at 0x7fe1284076a8>)>
fn = <function rest_request_ambassador at 0x7fe10c8a7d08>
args = ('mymodel', 'test-single-model', 'localhost:80'), kwargs = {}
retry_state = <tenacity.RetryCallState object at 0x7fe101037240>
do = <tenacity.DoAttempt object at 0x7fe100ef6cc0>

    def call(self, fn, *args, **kwargs):
        self.begin(fn)
    
        retry_state = RetryCallState(
            retry_object=self, fn=fn, args=args, kwargs=kwargs)
        while True:
            do = self.iter(retry_state=retry_state)
            if isinstance(do, DoAttempt):
                try:
>                   result = fn(*args, **kwargs)

/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

deployment_name = 'mymodel', namespace = 'test-single-model'
endpoint = 'localhost:80', data_size = 5, rows = 1, data = None
dtype = 'tensor', names = None, method = 'predict', predictor_name = 'default'

    @retry(wait=wait_exponential(max=10), stop=stop_after_attempt(5))
    def rest_request_ambassador(
        deployment_name,
        namespace,
        endpoint=API_AMBASSADOR,
        data_size=5,
        rows=1,
        data=None,
        dtype="tensor",
        names=None,
        method="predict",
        predictor_name="default",
    ):
        if data is None:
            shape, arr = create_random_data(data_size, rows)
        elif dtype == "tensor":
            shape = data.shape
            arr = data.flatten()
        else:
            arr = data
    
        if dtype == "tensor":
            payload = {"data": {"tensor": {"shape": shape, "values": arr.tolist()}}}
        else:
            payload = {"data": {"ndarray": arr}}
    
        if names is not None:
            payload["data"]["names"] = names
    
        if method == "predict":
            response = requests.post(
                "http://"
                + endpoint
                + "/seldon/"
                + namespace
                + "/"
                + deployment_name
                + "/api/v0.1/predictions",
>               json=payload,

seldon_e2e_utils.py:368: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

url = 'http://localhost:80/seldon/test-single-model/mymodel/api/v0.1/predictions'
data = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.5637596792676798, 0.04786007889340116, 0.5732820683295226, 0.07736556182206544, 0.5659573164689461]}}}
kwargs = {}

    def post(url, data=None, json=None, **kwargs):
        r"""Sends a POST request.
    
        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json data to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
        """
    
>       return request('post', url, data=data, json=json, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

method = 'post'
url = 'http://localhost:80/seldon/test-single-model/mymodel/api/v0.1/predictions'
kwargs = {'data': None, 'json': {'data': {'tensor': {'shape': [1, 5], 'values': [0.5637596792676798, 0.04786007889340116, 0.5732820683295226, 0.07736556182206544, 0.5659573164689461]}}}}
session = <requests.sessions.Session object at 0x7fe100ef65f8>

    def request(method, url, **kwargs):
        """Constructs and sends a :class:`Request <Request>`.
    
        :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary, list of tuples or bytes to send
            in the query string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
        :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
            ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
            or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
            defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
            to add for the file.
        :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How many seconds to wait for the server to send data
            before giving up, as a float, or a :ref:`(connect timeout, read
            timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
                the server's TLS certificate, or a string, in which case it must be a path
                to a CA bundle to use. Defaults to ``True``.
        :param stream: (optional) if ``False``, the response content will be immediately downloaded.
        :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
    
        Usage::
    
          >>> import requests
          >>> req = requests.request('GET', 'https://httpbin.org/get')
          >>> req
          <Response [200]>
        """
    
        # By using the 'with' statement we are sure the session is closed, thus we
        # avoid leaving sockets open which can trigger a ResourceWarning in some
        # cases, and look like a memory leak in others.
        with sessions.Session() as session:
>           return session.request(method=method, url=url, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7fe100ef65f8>, method = 'post'
url = 'http://localhost:80/seldon/test-single-model/mymodel/api/v0.1/predictions'
params = None, data = None, headers = None, cookies = None, files = None
auth = None, timeout = None, allow_redirects = True, proxies = {}, hooks = None
stream = None, verify = None, cert = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.5637596792676798, 0.04786007889340116, 0.5732820683295226, 0.07736556182206544, 0.5659573164689461]}}}

    def request(self, method, url,
            params=None, data=None, headers=None, cookies=None, files=None,
            auth=None, timeout=None, allow_redirects=True, proxies=None,
            hooks=None, stream=None, verify=None, cert=None, json=None):
        """Constructs a :class:`Request <Request>`, prepares it and sends it.
        Returns :class:`Response <Response>` object.
    
        :param method: method for the new :class:`Request` object.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary or bytes to be sent in the query
            string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the
            :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the
            :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the
            :class:`Request`.
        :param files: (optional) Dictionary of ``'filename': file-like-objects``
            for multipart encoding upload.
        :param auth: (optional) Auth tuple or callable to enable
            Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Set to True by default.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol or protocol and
            hostname to the URL of the proxy.
        :param stream: (optional) whether to immediately download the response
            content. Defaults to ``False``.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
        :param cert: (optional) if String, path to ssl client cert file (.pem).
            If Tuple, ('cert', 'key') pair.
        :rtype: requests.Response
        """
        # Create the Request.
        req = Request(
            method=method.upper(),
            url=url,
            headers=headers,
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
    
        proxies = proxies or {}
    
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
    
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
>       resp = self.send(prep, **send_kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:530: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7fe100ef65f8>
request = <PreparedRequest [POST]>
kwargs = {'cert': None, 'proxies': OrderedDict(), 'stream': False, 'timeout': None, ...}
allow_redirects = True, stream = False, hooks = {'response': []}
adapter = <requests.adapters.HTTPAdapter object at 0x7fe101037f98>
start = 1586205558.336674

    def send(self, request, **kwargs):
        """Send a given PreparedRequest.
    
        :rtype: requests.Response
        """
        # Set defaults that the hooks can utilize to ensure they always have
        # the correct parameters to reproduce the previous request.
        kwargs.setdefault('stream', self.stream)
        kwargs.setdefault('verify', self.verify)
        kwargs.setdefault('cert', self.cert)
        kwargs.setdefault('proxies', self.proxies)
    
        # It's possible that users might accidentally send a Request object.
        # Guard against that specific failure case.
        if isinstance(request, Request):
            raise ValueError('You can only send PreparedRequests.')
    
        # Set up variables needed for resolve_redirects and dispatching of hooks
        allow_redirects = kwargs.pop('allow_redirects', True)
        stream = kwargs.get('stream')
        hooks = request.hooks
    
        # Get the appropriate adapter to use
        adapter = self.get_adapter(url=request.url)
    
        # Start time (approximately) of the request
        start = preferred_clock()
    
        # Send the request
>       r = adapter.send(request, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x7fe101037f98>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7fe1010379b0>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
                    timeout=timeout
                )
    
            # Send the request.
            else:
                if hasattr(conn, 'proxy_pool'):
                    conn = conn.proxy_pool
    
                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
    
                try:
                    low_conn.putrequest(request.method,
                                        url,
                                        skip_accept_encoding=True)
    
                    for header, value in request.headers.items():
                        low_conn.putheader(header, value)
    
                    low_conn.endheaders()
    
                    for i in request.body:
                        low_conn.send(hex(len(i))[2:].encode('utf-8'))
                        low_conn.send(b'\r\n')
                        low_conn.send(i)
                        low_conn.send(b'\r\n')
                    low_conn.send(b'0\r\n\r\n')
    
                    # Receive the response from the server
                    try:
                        # For Python 2.7, use buffering of HTTP responses
                        r = low_conn.getresponse(buffering=True)
                    except TypeError:
                        # For compatibility with Python 3.3+
                        r = low_conn.getresponse()
    
                    resp = HTTPResponse.from_httplib(
                        r,
                        pool=conn,
                        connection=low_conn,
                        preload_content=False,
                        decode_content=False
                    )
                except:
                    # If we hit any problems here, clean up the connection.
                    # Then, reraise so that we can handle the actual exception.
                    low_conn.close()
                    raise
    
        except (ProtocolError, socket.error) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-single-model/mymodel/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe100dd8c18>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/requests/adapters.py:516: ConnectionError

The above exception was the direct cause of the following exception:

self = <test_helm_charts_clusterwide.TestClusterWide object at 0x7fe10c7a0fd0>
namespace = 'test-single-model'

    def test_single_model(self, namespace):
        run(
            f"helm install mymodel ../../helm-charts/seldon-single-model --namespace {namespace}",
            shell=True,
            check=True,
        )
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
        initial_rest_request("mymodel", namespace)
        logging.warning("Test Ambassador REST gateway")
>       r = rest_request_ambassador("mymodel", namespace, API_AMBASSADOR)

test_helm_charts_clusterwide.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:311: in wrapped_f
    return self.call(f, *args, **kw)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:391: in call
    do = self.iter(retry_state=retry_state)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:351: in iter
    six.raise_from(retry_exc, fut.exception())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None
from_value = ConnectionError(MaxRetryError("HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/t...HTTPConnection object at 0x7fe100dd8c18>: Failed to establish a new connection: [Errno 111] Connection refused',))",),)

>   ???
E   tenacity.RetryError: RetryError[<Future at 0x7fe101037e48 state=finished raised ConnectionError>]

<string>:3: RetryError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100dd8080 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100ef63c8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100e2fbe0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c7484a8 state=finished raised ConnectionError>]
WARNING  root:test_helm_charts_clusterwide.py:27 Test Ambassador REST gateway
______________________ TestClusterWide.test_abtest_model _______________________
[gw3] linux -- Python 3.6.10 /usr/local/bin/python

self = <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
>               (self._dns_host, self.port), self.timeout, **extra_kw
            )

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
                sock.connect(sa)
                return sock
    
            except socket.error as e:
                err = e
                if sock is not None:
                    sock.close()
                    sock = None
    
        if err is not None:
>           raise err

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:84: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:74: ConnectionRefusedError

During handling of the above exception, another exception occurred:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f92fd93dda0>
method = 'POST', url = '/seldon/test-abtest-model/myabtest/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.45374078884234037, 0.8550023229301761, 0.1839679725961596, 0.43088993775912776, 0.9114337759278456]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f92fd93d940>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f92fd6db048>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
>               chunked=chunked,
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:672: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f92fd93dda0>
conn = <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>
method = 'POST', url = '/seldon/test-abtest-model/myabtest/api/v0.1/predictions'
timeout = <urllib3.util.timeout.Timeout object at 0x7f92fd6db048>
chunked = False
httplib_request_kw = {'body': b'{"data": {"tensor": {"shape": [1, 5], "values": [0.45374078884234037, 0.8550023229301761, 0.183967972596159...p, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}}
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f92fd6dbf60>

    def _make_request(
        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw
    ):
        """
        Perform a request on a given urllib connection object taken from our
        pool.
    
        :param conn:
            a connection from one of our connection pools
    
        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        """
        self.num_requests += 1
    
        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = timeout_obj.connect_timeout
    
        # Trigger any extra validation we need to do.
        try:
            self._validate_conn(conn)
        except (SocketTimeout, BaseSSLError) as e:
            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.
            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
            raise
    
        # conn.request() calls httplib.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        if chunked:
            conn.request_chunked(method, url, **httplib_request_kw)
        else:
>           conn.request(method, url, **httplib_request_kw)

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>
method = 'POST', url = '/seldon/test-abtest-model/myabtest/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.45374078884234037, 0.8550023229301761, 0.1839679725961596, 0.43088993775912776, 0.9114337759278456]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}

    def request(self, method, url, body=None, headers={}, *,
                encode_chunked=False):
        """Send a complete request to the server."""
>       self._send_request(method, url, body, headers, encode_chunked)

/usr/local/lib/python3.6/http/client.py:1262: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>
method = 'POST', url = '/seldon/test-abtest-model/myabtest/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.45374078884234037, 0.8550023229301761, 0.1839679725961596, 0.43088993775912776, 0.9114337759278456]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}
encode_chunked = False

    def _send_request(self, method, url, body, headers, encode_chunked):
        # Honor explicitly requested Host: and Accept-Encoding: headers.
        header_names = frozenset(k.lower() for k in headers)
        skips = {}
        if 'host' in header_names:
            skips['skip_host'] = 1
        if 'accept-encoding' in header_names:
            skips['skip_accept_encoding'] = 1
    
        self.putrequest(method, url, **skips)
    
        # chunked encoding will happen if HTTP/1.1 is used and either
        # the caller passes encode_chunked=True or the following
        # conditions hold:
        # 1. content-length has not been explicitly set
        # 2. the body is a file or iterable, but not a str or bytes-like
        # 3. Transfer-Encoding has NOT been explicitly set by the caller
    
        if 'content-length' not in header_names:
            # only chunk body if not explicitly set for backwards
            # compatibility, assuming the client code is already handling the
            # chunking
            if 'transfer-encoding' not in header_names:
                # if content-length cannot be automatically determined, fall
                # back to chunked encoding
                encode_chunked = False
                content_length = self._get_content_length(body, method)
                if content_length is None:
                    if body is not None:
                        if self.debuglevel > 0:
                            print('Unable to determine size of %r' % body)
                        encode_chunked = True
                        self.putheader('Transfer-Encoding', 'chunked')
                else:
                    self.putheader('Content-Length', str(content_length))
        else:
            encode_chunked = False
    
        for hdr, value in headers.items():
            self.putheader(hdr, value)
        if isinstance(body, str):
            # RFC 2616 Section 3.7.1 says that text default has a
            # default charset of iso-8859-1.
            body = _encode(body, 'body')
>       self.endheaders(body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1308: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.45374078884234037, 0.8550023229301761, 0.1839679725961596, 0.43088993775912776, 0.9114337759278456]}}}'

    def endheaders(self, message_body=None, *, encode_chunked=False):
        """Indicate that the last header line has been sent to the server.
    
        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        """
        if self.__state == _CS_REQ_STARTED:
            self.__state = _CS_REQ_SENT
        else:
            raise CannotSendHeader()
>       self._send_output(message_body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>
message_body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.45374078884234037, 0.8550023229301761, 0.1839679725961596, 0.43088993775912776, 0.9114337759278456]}}}'
encode_chunked = False

    def _send_output(self, message_body=None, encode_chunked=False):
        """Send the currently buffered request and clear the buffer.
    
        Appends an extra \\r\\n to the buffer.
        A message_body may be specified, to be appended to the request.
        """
        self._buffer.extend((b"", b""))
        msg = b"\r\n".join(self._buffer)
        del self._buffer[:]
>       self.send(msg)

/usr/local/lib/python3.6/http/client.py:1036: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>
data = b'POST /seldon/test-abtest-model/myabtest/api/v0.1/predictions HTTP/1.1\r\nHost: localhost\r\nUser-Agent: python-reque...zip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 153\r\nContent-Type: application/json\r\n\r\n'

    def send(self, data):
        """Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        """
    
        if self.sock is None:
            if self.auto_open:
>               self.connect()

/usr/local/lib/python3.6/http/client.py:974: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>

    def connect(self):
>       conn = self._new_conn()

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
                (self._dns_host, self.port), self.timeout, **extra_kw
            )
    
        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                "Connection to %s timed out. (connect timeout=%s)"
                % (self.host, self.timeout),
            )
    
        except SocketError as e:
            raise NewConnectionError(
>               self, "Failed to establish a new connection: %s" % e
            )
E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>: Failed to establish a new connection: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:169: NewConnectionError

During handling of the above exception, another exception occurred:

self = <requests.adapters.HTTPAdapter object at 0x7f92fd93deb8>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f92fd93d940>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
>                   timeout=timeout
                )

/usr/local/lib/python3.6/site-packages/requests/adapters.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f92fd93dda0>
method = 'POST', url = '/seldon/test-abtest-model/myabtest/api/v0.1/predictions'
body = b'{"data": {"tensor": {"shape": [1, 5], "values": [0.45374078884234037, 0.8550023229301761, 0.1839679725961596, 0.43088993775912776, 0.9114337759278456]}}}'
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '153', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f92fd93d940>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f92fd6db048>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
            )
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Pass method to Response for length checking
            response_kw["request_method"] = method
    
            # Import httplib's response into our own wrapper object
            response = self.ResponseCls.from_httplib(
                httplib_response,
                pool=self,
                connection=response_conn,
                retries=retries,
                **response_kw
            )
    
            # Everything went great!
            clean_exit = True
    
        except queue.Empty:
            # Timed out by queue.
            raise EmptyPoolError(self, "No pool connections are available.")
    
        except (
            TimeoutError,
            HTTPException,
            SocketError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
        ) as e:
            # Discard the connection for these exceptions. It will be
            # replaced during the next _get_conn() call.
            clean_exit = False
            if isinstance(e, (BaseSSLError, CertificateError)):
                e = SSLError(e)
            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
                e = ProxyError("Cannot connect to proxy.", e)
            elif isinstance(e, (SocketError, HTTPException)):
                e = ProtocolError("Connection aborted.", e)
    
            retries = retries.increment(
>               method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=None, read=False, redirect=None, status=None)
method = 'POST', url = '/seldon/test-abtest-model/myabtest/api/v0.1/predictions'
response = None
error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>: Failed to establish a new connection: [Errno 111] Connection refused',)
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f92fd93dda0>
_stacktrace = <traceback object at 0x7f92fd63a288>

    def increment(
        self,
        method=None,
        url=None,
        response=None,
        error=None,
        _pool=None,
        _stacktrace=None,
    ):
        """ Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.HTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise six.reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise six.reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or not self._is_method_retryable(method):
                raise six.reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            redirect_location = response.get_redirect_location()
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and a the given method is in the whitelist
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            history=history,
        )
    
        if new_retry.is_exhausted():
>           raise MaxRetryError(_pool, url, error or ResponseError(cause))
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-abtest-model/myabtest/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:436: MaxRetryError

During handling of the above exception, another exception occurred:

self = <Retrying object at 0x7f934fdb0438 (stop=<tenacity.stop.stop_after_attempt object at 0x7f934fdb00b8>, wait=<tenacity.w...0x7f9324d07e48>, before=<function before_nothing at 0x7f9324d09510>, after=<function after_nothing at 0x7f9324d096a8>)>
fn = <function rest_request_ambassador at 0x7f93091a9d08>
args = ('myabtest', 'test-abtest-model', 'localhost:80'), kwargs = {}
retry_state = <tenacity.RetryCallState object at 0x7f92fd93d160>
do = <tenacity.DoAttempt object at 0x7f92fd7fcbe0>

    def call(self, fn, *args, **kwargs):
        self.begin(fn)
    
        retry_state = RetryCallState(
            retry_object=self, fn=fn, args=args, kwargs=kwargs)
        while True:
            do = self.iter(retry_state=retry_state)
            if isinstance(do, DoAttempt):
                try:
>                   result = fn(*args, **kwargs)

/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

deployment_name = 'myabtest', namespace = 'test-abtest-model'
endpoint = 'localhost:80', data_size = 5, rows = 1, data = None
dtype = 'tensor', names = None, method = 'predict', predictor_name = 'default'

    @retry(wait=wait_exponential(max=10), stop=stop_after_attempt(5))
    def rest_request_ambassador(
        deployment_name,
        namespace,
        endpoint=API_AMBASSADOR,
        data_size=5,
        rows=1,
        data=None,
        dtype="tensor",
        names=None,
        method="predict",
        predictor_name="default",
    ):
        if data is None:
            shape, arr = create_random_data(data_size, rows)
        elif dtype == "tensor":
            shape = data.shape
            arr = data.flatten()
        else:
            arr = data
    
        if dtype == "tensor":
            payload = {"data": {"tensor": {"shape": shape, "values": arr.tolist()}}}
        else:
            payload = {"data": {"ndarray": arr}}
    
        if names is not None:
            payload["data"]["names"] = names
    
        if method == "predict":
            response = requests.post(
                "http://"
                + endpoint
                + "/seldon/"
                + namespace
                + "/"
                + deployment_name
                + "/api/v0.1/predictions",
>               json=payload,

seldon_e2e_utils.py:368: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

url = 'http://localhost:80/seldon/test-abtest-model/myabtest/api/v0.1/predictions'
data = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.45374078884234037, 0.8550023229301761, 0.1839679725961596, 0.43088993775912776, 0.9114337759278456]}}}
kwargs = {}

    def post(url, data=None, json=None, **kwargs):
        r"""Sends a POST request.
    
        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json data to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
        """
    
>       return request('post', url, data=data, json=json, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

method = 'post'
url = 'http://localhost:80/seldon/test-abtest-model/myabtest/api/v0.1/predictions'
kwargs = {'data': None, 'json': {'data': {'tensor': {'shape': [1, 5], 'values': [0.45374078884234037, 0.8550023229301761, 0.1839679725961596, 0.43088993775912776, 0.9114337759278456]}}}}
session = <requests.sessions.Session object at 0x7f92fd7fc518>

    def request(method, url, **kwargs):
        """Constructs and sends a :class:`Request <Request>`.
    
        :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary, list of tuples or bytes to send
            in the query string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
        :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
            ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
            or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
            defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
            to add for the file.
        :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How many seconds to wait for the server to send data
            before giving up, as a float, or a :ref:`(connect timeout, read
            timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
                the server's TLS certificate, or a string, in which case it must be a path
                to a CA bundle to use. Defaults to ``True``.
        :param stream: (optional) if ``False``, the response content will be immediately downloaded.
        :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
    
        Usage::
    
          >>> import requests
          >>> req = requests.request('GET', 'https://httpbin.org/get')
          >>> req
          <Response [200]>
        """
    
        # By using the 'with' statement we are sure the session is closed, thus we
        # avoid leaving sockets open which can trigger a ResourceWarning in some
        # cases, and look like a memory leak in others.
        with sessions.Session() as session:
>           return session.request(method=method, url=url, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/api.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f92fd7fc518>, method = 'post'
url = 'http://localhost:80/seldon/test-abtest-model/myabtest/api/v0.1/predictions'
params = None, data = None, headers = None, cookies = None, files = None
auth = None, timeout = None, allow_redirects = True, proxies = {}, hooks = None
stream = None, verify = None, cert = None
json = {'data': {'tensor': {'shape': [1, 5], 'values': [0.45374078884234037, 0.8550023229301761, 0.1839679725961596, 0.43088993775912776, 0.9114337759278456]}}}

    def request(self, method, url,
            params=None, data=None, headers=None, cookies=None, files=None,
            auth=None, timeout=None, allow_redirects=True, proxies=None,
            hooks=None, stream=None, verify=None, cert=None, json=None):
        """Constructs a :class:`Request <Request>`, prepares it and sends it.
        Returns :class:`Response <Response>` object.
    
        :param method: method for the new :class:`Request` object.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary or bytes to be sent in the query
            string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the
            :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the
            :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the
            :class:`Request`.
        :param files: (optional) Dictionary of ``'filename': file-like-objects``
            for multipart encoding upload.
        :param auth: (optional) Auth tuple or callable to enable
            Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Set to True by default.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol or protocol and
            hostname to the URL of the proxy.
        :param stream: (optional) whether to immediately download the response
            content. Defaults to ``False``.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
        :param cert: (optional) if String, path to ssl client cert file (.pem).
            If Tuple, ('cert', 'key') pair.
        :rtype: requests.Response
        """
        # Create the Request.
        req = Request(
            method=method.upper(),
            url=url,
            headers=headers,
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
    
        proxies = proxies or {}
    
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
    
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
>       resp = self.send(prep, **send_kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:530: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f92fd7fc518>
request = <PreparedRequest [POST]>
kwargs = {'cert': None, 'proxies': OrderedDict(), 'stream': False, 'timeout': None, ...}
allow_redirects = True, stream = False, hooks = {'response': []}
adapter = <requests.adapters.HTTPAdapter object at 0x7f92fd93deb8>
start = 1586205561.503776

    def send(self, request, **kwargs):
        """Send a given PreparedRequest.
    
        :rtype: requests.Response
        """
        # Set defaults that the hooks can utilize to ensure they always have
        # the correct parameters to reproduce the previous request.
        kwargs.setdefault('stream', self.stream)
        kwargs.setdefault('verify', self.verify)
        kwargs.setdefault('cert', self.cert)
        kwargs.setdefault('proxies', self.proxies)
    
        # It's possible that users might accidentally send a Request object.
        # Guard against that specific failure case.
        if isinstance(request, Request):
            raise ValueError('You can only send PreparedRequests.')
    
        # Set up variables needed for resolve_redirects and dispatching of hooks
        allow_redirects = kwargs.pop('allow_redirects', True)
        stream = kwargs.get('stream')
        hooks = request.hooks
    
        # Get the appropriate adapter to use
        adapter = self.get_adapter(url=request.url)
    
        # Start time (approximately) of the request
        start = preferred_clock()
    
        # Send the request
>       r = adapter.send(request, **kwargs)

/usr/local/lib/python3.6/site-packages/requests/sessions.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x7f92fd93deb8>
request = <PreparedRequest [POST]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f92fd93d940>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
                    timeout=timeout
                )
    
            # Send the request.
            else:
                if hasattr(conn, 'proxy_pool'):
                    conn = conn.proxy_pool
    
                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
    
                try:
                    low_conn.putrequest(request.method,
                                        url,
                                        skip_accept_encoding=True)
    
                    for header, value in request.headers.items():
                        low_conn.putheader(header, value)
    
                    low_conn.endheaders()
    
                    for i in request.body:
                        low_conn.send(hex(len(i))[2:].encode('utf-8'))
                        low_conn.send(b'\r\n')
                        low_conn.send(i)
                        low_conn.send(b'\r\n')
                    low_conn.send(b'0\r\n\r\n')
    
                    # Receive the response from the server
                    try:
                        # For Python 2.7, use buffering of HTTP responses
                        r = low_conn.getresponse(buffering=True)
                    except TypeError:
                        # For compatibility with Python 3.3+
                        r = low_conn.getresponse()
    
                    resp = HTTPResponse.from_httplib(
                        r,
                        pool=conn,
                        connection=low_conn,
                        preload_content=False,
                        decode_content=False
                    )
                except:
                    # If we hit any problems here, clean up the connection.
                    # Then, reraise so that we can handle the actual exception.
                    low_conn.close()
                    raise
    
        except (ProtocolError, socket.error) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/test-abtest-model/myabtest/api/v0.1/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f92fd6db9b0>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/requests/adapters.py:516: ConnectionError

The above exception was the direct cause of the following exception:

self = <test_helm_charts_clusterwide.TestClusterWide object at 0x7f93090862e8>
namespace = 'test-abtest-model'

    def test_abtest_model(self, namespace):
        run(
            f"helm install myabtest ../../helm-charts/seldon-abtest --namespace {namespace}",
            shell=True,
            check=True,
        )
        wait_for_status("myabtest", namespace)
        wait_for_rollout("myabtest", namespace, expected_deployments=2)
        initial_rest_request("myabtest", namespace)
        logging.warning("Test Ambassador REST gateway")
>       r = rest_request_ambassador("myabtest", namespace, API_AMBASSADOR)

test_helm_charts_clusterwide.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:311: in wrapped_f
    return self.call(f, *args, **kw)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:391: in call
    do = self.iter(retry_state=retry_state)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:351: in iter
    six.raise_from(retry_exc, fut.exception())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = None
from_value = ConnectionError(MaxRetryError("HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /seldon/t...HTTPConnection object at 0x7f92fd6db9b0>: Failed to establish a new connection: [Errno 111] Connection refused',))",),)

>   ???
E   tenacity.RetryError: RetryError[<Future at 0x7f92fd93dd68 state=finished raised ConnectionError>]

<string>:3: RetryError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd6db860 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd7fc2e8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd835f28 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f9309086240 state=finished raised ConnectionError>]
WARNING  root:test_helm_charts_clusterwide.py:44 Test Ambassador REST gateway
__________________________ TestPrepack.test_tfserving __________________________
[gw0] linux -- Python 3.6.10 /usr/local/bin/python

self = <test_prepackaged_servers.TestPrepack object at 0x7f33a7c00f60>
namespace = 'test-tfserving'

    def test_tfserving(self, namespace):
        spec = "../../servers/tfserving/samples/mnist_rest.yaml"
        retry_run(f"kubectl apply -f {spec}  -n {namespace}")
        wait_for_status("tfserving", namespace)
        wait_for_rollout("tfserving", namespace)
        time.sleep(1)
        logging.warning("Initial request")
        r = initial_rest_request(
            "tfserving",
            namespace,
            data=[create_random_data(784)[1].tolist()],
            dtype="ndarray",
        )
>       assert r.status_code == 200
E       AttributeError: 'NoneType' object has no attribute 'status_code'

test_prepackaged_servers.py:45: AttributeError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:test_prepackaged_servers.py:38 Initial request
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c274278 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4d5cc0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c274240 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4d5c88 state=finished raised ConnectionError>]
__________________ TestLocalOperators.test_labelled_operator ___________________
[gw1] linux -- Python 3.6.10 /usr/local/bin/python

self = <test_local_operators.TestLocalOperators object at 0x7fe100e91eb8>
namespace = 'test-labelled-operator'

    def test_labelled_operator(self, namespace):
        retry_run(
            f"helm install seldon ../../helm-charts/seldon-core-operator --namespace {namespace} --set executor.enabled=true --set istio.enabled=true --set istio.gateway=seldon-gateway --set certManager.enabled=false --set crd.create=false --set controllerId=seldon-id1"
        )
        retry_run(
            f"kubectl apply -f ../resources/model_controller_id.yaml -n {namespace}"
        )
        wait_for_status("test-c1", namespace)
        wait_for_rollout("test-c1", namespace)
        logging.warning("Initial request")
        r = initial_rest_request("test-c1", namespace, endpoint=API_AMBASSADOR)
>       assert r.status_code == 200
E       AttributeError: 'NoneType' object has no attribute 'status_code'

test_local_operators.py:40: AttributeError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:155 Unsuccessful command but retrying: kubectl apply -f ../resources/model_controller_id.yaml -n test-labelled-operator
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:test_local_operators.py:38 Initial request
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10226f438 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c7f4978 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c7bdb38 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100f40c88 state=finished raised ConnectionError>]
___________________________ TestPrepack.test_sklearn ___________________________
[gw3] linux -- Python 3.6.10 /usr/local/bin/python

self = <test_prepackaged_servers.TestPrepack object at 0x7f92fd75f6d8>
namespace = 'test-sklearn'

    def test_sklearn(self, namespace):
        spec = "../../servers/sklearnserver/samples/iris.yaml"
        retry_run(f"kubectl apply -f {spec} -n {namespace}")
        wait_for_status("sklearn", namespace)
        wait_for_rollout("sklearn", namespace)
        time.sleep(1)
        logging.warning("Initial request")
        r = initial_rest_request(
            "sklearn", namespace, data=[[0.1, 0.2, 0.3, 0.4]], dtype="ndarray"
        )
>       assert r.status_code == 200
E       AttributeError: 'NoneType' object has no attribute 'status_code'

test_prepackaged_servers.py:27: AttributeError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:test_prepackaged_servers.py:23 Initial request
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd6305c0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd75fa90 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd77d128 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd630cc0 state=finished raised ConnectionError>]
___________________________ TestPrepack.test_mlflow ____________________________
[gw2] linux -- Python 3.6.10 /usr/local/bin/python

self = <test_prepackaged_servers.TestPrepack object at 0x7f6bc33467b8>
namespace = 'test-mlflow'

    def test_mlflow(self, namespace):
        spec = "../../servers/mlflowserver/samples/elasticnet_wine.yaml"
        retry_run(f"kubectl apply -f {spec} -n {namespace}")
        wait_for_status("mlflow", namespace)
        wait_for_rollout("mlflow", namespace)
        time.sleep(1)
    
        r = initial_rest_request(
            "mlflow",
            namespace,
            data=[[6.3, 0.3, 0.34, 1.6, 0.049, 14, 132, 0.994, 3.3, 0.49, 9.5]],
            dtype="ndarray",
            names=[
                "fixed acidity",
                "volatile acidity",
                "citric acid",
                "residual sugar",
                "chlorides",
                "free sulfur dioxide",
                "total sulfur dioxide",
                "density",
                "pH",
                "sulphates",
                "alcohol",
            ],
        )
>       assert r.status_code == 200
E       AttributeError: 'NoneType' object has no attribute 'status_code'

test_prepackaged_servers.py:91: AttributeError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc327d1d0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc30449b0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3169a20 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc30e57b8 state=finished raised ConnectionError>]
___________________________ TestPrepack.test_xgboost ___________________________
[gw0] linux -- Python 3.6.10 /usr/local/bin/python

self = <test_prepackaged_servers.TestPrepack object at 0x7f339c552080>
namespace = 'test-xgboost'

    def test_xgboost(self, namespace):
        spec = "../../servers/xgboostserver/samples/iris.yaml"
        retry_run(f"kubectl apply -f {spec}  -n {namespace}")
        wait_for_status("xgboost", namespace)
        wait_for_rollout("xgboost", namespace)
        time.sleep(1)
        logging.warning("Initial request")
        r = initial_rest_request(
            "xgboost", namespace, data=[[0.1, 0.2, 0.3, 0.4]], dtype="ndarray"
        )
>       assert r.status_code == 200
E       AttributeError: 'NoneType' object has no attribute 'status_code'

test_prepackaged_servers.py:60: AttributeError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:test_prepackaged_servers.py:56 Initial request
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c28e860 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c28e7b8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c28e5c0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c421198 state=finished raised ConnectionError>]
____________________ TestPrepack.test_text_alibi_explainer _____________________
[gw2] linux -- Python 3.6.10 /usr/local/bin/python

self = <test_prepackaged_servers.TestPrepack object at 0x7f6bcea9f588>
namespace = 'test-text-alibi-explainer'

    def test_text_alibi_explainer(self, namespace):
        spec = "../resources/movies-text-explainer.yaml"
        retry_run(f"kubectl apply -f {spec} -n {namespace}")
        wait_for_status("movie", namespace)
        wait_for_rollout("movie", namespace, expected_deployments=2)
        time.sleep(1)
        logging.warning("Initial request")
        r = initial_rest_request(
            "movie", namespace, data=["This is test data"], dtype="ndarray"
        )
>       assert r.status_code == 200
E       AttributeError: 'NoneType' object has no attribute 'status_code'

test_prepackaged_servers.py:106: AttributeError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:test_prepackaged_servers.py:102 Initial request
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3346d30 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3211128 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3346b38 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea61160 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph2.json-True-ambas] __________
[gw1] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph2-json-true-ambas'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph2.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph2-json-true-ambas'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100f402e8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c7bdeb8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100d2cac8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c7bda90 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100d2cac8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100e91860 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100f409e8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100f40da0 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph2.json-True-istio] __________
[gw3] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph2-json-true-istio'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph2.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph2-json-true-istio'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd7ed0b8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd645cf8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd7edb38 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd7f8780 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd9c3cf8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd7fc6d8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd884cf8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd8847b8 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph3.json-True-ambas] __________
[gw0] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph3-json-true-ambas'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph3.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph3-json-true-ambas'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339d69a358 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c2b7b00 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c391320 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c274dd8 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c1d0160 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c28e0f0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c552cf8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c1d00b8 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph4.json-True-istio] __________
[gw2] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph4-json-true-istio'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph4.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph4-json-true-istio'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea61208 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea61668 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc324e4e0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea614a8 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3169240 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea612b0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc327de80 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc31691d0 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph3.json-True-istio] __________
[gw1] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph3-json-true-istio'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph3.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph3-json-true-istio'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100e5a160 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100f84518 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe101037278 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe101037c88 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100eee668 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100e75320 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c7481d0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe102200da0 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph4.json-True-ambas] __________
[gw3] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph4-json-true-ambas'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph4.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph4-json-true-ambas'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd645ba8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd645a90 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f930904ba90 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd645cf8 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd630a58 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd835320 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd7f8f60 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd7f8908 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph5.json-True-ambas] __________
[gw0] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph5-json-true-ambas'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph5.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph5-json-true-ambas'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c391a20 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c391b00 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c3910b8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c428198 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339d61b940 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c28e128 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c1def28 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339d61b0b8 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph8.json-True-ambas] __________
[gw1] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph8-json-true-ambas'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph8.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph8-json-true-ambas'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100d37e10 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100ef0a20 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100e91358 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100e91b70 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe101018e80 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe10c754128 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe1010181d0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100e45898 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph5.json-True-istio] __________
[gw2] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph5-json-true-istio'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph5.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph5-json-true-istio'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc33469e8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3346d68 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc324e0f0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc304dd68 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3264a90 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3264cf8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3264470 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bcea613c8 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph1.json-graph8.json-True-istio] __________
[gw3] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph1-json-graph8-json-true-istio'
api_gateway = 'localhost:80', from_deployment = 'graph1.json'
to_deployment = 'graph8.json', change = True

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph1-json-graph8-json-true-istio'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd7fc7f0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd7fc7f0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd5b0898 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd91c668 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd91c550 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd63bb38 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92feb02ef0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f92fd876c50 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph7.json-graph8.json-False-ambas] _________
[gw0] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph7-json-graph8-json-false-ambas'
api_gateway = 'localhost:80', from_deployment = 'graph7.json'
to_deployment = 'graph8.json', change = False

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph7-json-graph8-json-false-ambas'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4d5780 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4d5550 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4210f0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4d55c0 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4080b8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4217f0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4d5278 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f339c4d5198 state=finished raised ConnectionError>]
______________________________ test_tracing_rest _______________________________
[gw2] linux -- Python 3.6.10 /usr/local/bin/python

self = <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
>               (self._dns_host, self.port), self.timeout, **extra_kw
            )

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
                sock.connect(sa)
                return sock
    
            except socket.error as e:
                err = e
                if sock is not None:
                    sock.close()
                    sock = None
    
        if err is not None:
>           raise err

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:84: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 80), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        source_address=None,
        socket_options=None,
    ):
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:74: ConnectionRefusedError

During handling of the above exception, another exception occurred:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6bc3169400>
method = 'GET'
url = '/jaeger/api/traces?service=executor&operation=predictions&tag=hostname%3Amymodel-mymodel-0-complex-model-6b654c5845-xxt8t'
body = None
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bc3169048>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f6bc3169b70>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
>               chunked=chunked,
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:672: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6bc3169400>
conn = <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>
method = 'GET'
url = '/jaeger/api/traces?service=executor&operation=predictions&tag=hostname%3Amymodel-mymodel-0-complex-model-6b654c5845-xxt8t'
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bc3169b70>
chunked = False
httplib_request_kw = {'body': None, 'headers': {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}}
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f6bc31699b0>

    def _make_request(
        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw
    ):
        """
        Perform a request on a given urllib connection object taken from our
        pool.
    
        :param conn:
            a connection from one of our connection pools
    
        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        """
        self.num_requests += 1
    
        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = timeout_obj.connect_timeout
    
        # Trigger any extra validation we need to do.
        try:
            self._validate_conn(conn)
        except (SocketTimeout, BaseSSLError) as e:
            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.
            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
            raise
    
        # conn.request() calls httplib.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        if chunked:
            conn.request_chunked(method, url, **httplib_request_kw)
        else:
>           conn.request(method, url, **httplib_request_kw)

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>
method = 'GET'
url = '/jaeger/api/traces?service=executor&operation=predictions&tag=hostname%3Amymodel-mymodel-0-complex-model-6b654c5845-xxt8t'
body = None
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}

    def request(self, method, url, body=None, headers={}, *,
                encode_chunked=False):
        """Send a complete request to the server."""
>       self._send_request(method, url, body, headers, encode_chunked)

/usr/local/lib/python3.6/http/client.py:1262: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>
method = 'GET'
url = '/jaeger/api/traces?service=executor&operation=predictions&tag=hostname%3Amymodel-mymodel-0-complex-model-6b654c5845-xxt8t'
body = None
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
encode_chunked = False

    def _send_request(self, method, url, body, headers, encode_chunked):
        # Honor explicitly requested Host: and Accept-Encoding: headers.
        header_names = frozenset(k.lower() for k in headers)
        skips = {}
        if 'host' in header_names:
            skips['skip_host'] = 1
        if 'accept-encoding' in header_names:
            skips['skip_accept_encoding'] = 1
    
        self.putrequest(method, url, **skips)
    
        # chunked encoding will happen if HTTP/1.1 is used and either
        # the caller passes encode_chunked=True or the following
        # conditions hold:
        # 1. content-length has not been explicitly set
        # 2. the body is a file or iterable, but not a str or bytes-like
        # 3. Transfer-Encoding has NOT been explicitly set by the caller
    
        if 'content-length' not in header_names:
            # only chunk body if not explicitly set for backwards
            # compatibility, assuming the client code is already handling the
            # chunking
            if 'transfer-encoding' not in header_names:
                # if content-length cannot be automatically determined, fall
                # back to chunked encoding
                encode_chunked = False
                content_length = self._get_content_length(body, method)
                if content_length is None:
                    if body is not None:
                        if self.debuglevel > 0:
                            print('Unable to determine size of %r' % body)
                        encode_chunked = True
                        self.putheader('Transfer-Encoding', 'chunked')
                else:
                    self.putheader('Content-Length', str(content_length))
        else:
            encode_chunked = False
    
        for hdr, value in headers.items():
            self.putheader(hdr, value)
        if isinstance(body, str):
            # RFC 2616 Section 3.7.1 says that text default has a
            # default charset of iso-8859-1.
            body = _encode(body, 'body')
>       self.endheaders(body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1308: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>
message_body = None

    def endheaders(self, message_body=None, *, encode_chunked=False):
        """Indicate that the last header line has been sent to the server.
    
        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        """
        if self.__state == _CS_REQ_STARTED:
            self.__state = _CS_REQ_SENT
        else:
            raise CannotSendHeader()
>       self._send_output(message_body, encode_chunked=encode_chunked)

/usr/local/lib/python3.6/http/client.py:1257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>
message_body = None, encode_chunked = False

    def _send_output(self, message_body=None, encode_chunked=False):
        """Send the currently buffered request and clear the buffer.
    
        Appends an extra \\r\\n to the buffer.
        A message_body may be specified, to be appended to the request.
        """
        self._buffer.extend((b"", b""))
        msg = b"\r\n".join(self._buffer)
        del self._buffer[:]
>       self.send(msg)

/usr/local/lib/python3.6/http/client.py:1036: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>
data = b'GET /jaeger/api/traces?service=executor&operation=predictions&tag=hostname%3Amymodel-mymodel-0-complex-model-6b654c5...nUser-Agent: python-requests/2.23.0\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n'

    def send(self, data):
        """Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        """
    
        if self.sock is None:
            if self.auto_open:
>               self.connect()

/usr/local/lib/python3.6/http/client.py:974: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>

    def connect(self):
>       conn = self._new_conn()

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>

    def _new_conn(self):
        """ Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address
    
        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options
    
        try:
            conn = connection.create_connection(
                (self._dns_host, self.port), self.timeout, **extra_kw
            )
    
        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                "Connection to %s timed out. (connect timeout=%s)"
                % (self.host, self.timeout),
            )
    
        except SocketError as e:
            raise NewConnectionError(
>               self, "Failed to establish a new connection: %s" % e
            )
E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f6bc3169550>: Failed to establish a new connection: [Errno 111] Connection refused

/usr/local/lib/python3.6/site-packages/urllib3/connection.py:169: NewConnectionError

During handling of the above exception, another exception occurred:

self = <requests.adapters.HTTPAdapter object at 0x7f6bc3169438>
request = <PreparedRequest [GET]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bc3169048>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
>                   timeout=timeout
                )

/usr/local/lib/python3.6/site-packages/requests/adapters.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6bc3169400>
method = 'GET'
url = '/jaeger/api/traces?service=executor&operation=predictions&tag=hostname%3Amymodel-mymodel-0-complex-model-6b654c5845-xxt8t'
body = None
headers = {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bc3169048>
pool_timeout = None, release_conn = False, chunked = False, body_pos = None
response_kw = {'decode_content': False, 'preload_content': False}, conn = None
release_this_conn = True, err = None, clean_exit = False
timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f6bc3169b70>
is_new_proxy_conn = False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param body:
            Data to send in the request body (useful for creating
            POST requests, see HTTPConnectionPool.post_url for
            more convenience).
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When False, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
    
        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parse_url(url).url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        # Merge the proxy headers. Only do this in HTTP. We have to copy the
        # headers dict so we can safely change it without those changes being
        # reflected in anyone else's copy.
        if self.scheme == "http":
            headers = headers.copy()
            headers.update(self.proxy_headers)
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout
    
            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn:
                self._prepare_proxy(conn)
    
            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
            )
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Pass method to Response for length checking
            response_kw["request_method"] = method
    
            # Import httplib's response into our own wrapper object
            response = self.ResponseCls.from_httplib(
                httplib_response,
                pool=self,
                connection=response_conn,
                retries=retries,
                **response_kw
            )
    
            # Everything went great!
            clean_exit = True
    
        except queue.Empty:
            # Timed out by queue.
            raise EmptyPoolError(self, "No pool connections are available.")
    
        except (
            TimeoutError,
            HTTPException,
            SocketError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
        ) as e:
            # Discard the connection for these exceptions. It will be
            # replaced during the next _get_conn() call.
            clean_exit = False
            if isinstance(e, (BaseSSLError, CertificateError)):
                e = SSLError(e)
            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
                e = ProxyError("Cannot connect to proxy.", e)
            elif isinstance(e, (SocketError, HTTPException)):
                e = ProtocolError("Connection aborted.", e)
    
            retries = retries.increment(
>               method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
            )

/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=None, read=False, redirect=None, status=None)
method = 'GET'
url = '/jaeger/api/traces?service=executor&operation=predictions&tag=hostname%3Amymodel-mymodel-0-complex-model-6b654c5845-xxt8t'
response = None
error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6bc3169550>: Failed to establish a new connection: [Errno 111] Connection refused',)
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6bc3169400>
_stacktrace = <traceback object at 0x7f6bc3214b08>

    def increment(
        self,
        method=None,
        url=None,
        response=None,
        error=None,
        _pool=None,
        _stacktrace=None,
    ):
        """ Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.HTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise six.reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise six.reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or not self._is_method_retryable(method):
                raise six.reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            redirect_location = response.get_redirect_location()
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and a the given method is in the whitelist
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            history=history,
        )
    
        if new_retry.is_exhausted():
>           raise MaxRetryError(_pool, url, error or ResponseError(cause))
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /jaeger/api/traces?service=executor&operation=predictions&tag=hostname%3Amymodel-mymodel-0-complex-model-6b654c5845-xxt8t (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6bc3169550>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:436: MaxRetryError

During handling of the above exception, another exception occurred:

namespace = 'test-tracing-rest'

    def test_tracing_rest(namespace):
        # Deploy model and check that is running
        retry_run(f"kubectl apply -f ../resources/graph-tracing.json -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
        initial_rest_request("mymodel", namespace)
    
        # We need the current pod name to find the right traces
        deployment_names = get_deployment_names("mymodel", namespace)
        deployment_name = deployment_names[0]
        pod_names = get_pod_names(deployment_name, namespace)
        pod_name = pod_names[0]
    
        # Get traces and assert their content
        traces = get_traces(
>           pod_name, "executor", "predictions", _should_retry=_is_jaeger_syncing
        )

test_tracing.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:311: in wrapped_f
    return self.call(f, *args, **kw)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:391: in call
    do = self.iter(retry_state=retry_state)
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:338: in iter
    return fut.result()
/usr/local/lib/python3.6/concurrent/futures/_base.py:425: in result
    return self.__get_result()
/usr/local/lib/python3.6/concurrent/futures/_base.py:384: in __get_result
    raise self._exception
/usr/local/lib/python3.6/site-packages/tenacity/__init__.py:394: in call
    result = fn(*args, **kwargs)
jaeger_utils.py:51: in get_traces
    response = requests.get(endpoint, params=params)
/usr/local/lib/python3.6/site-packages/requests/api.py:76: in get
    return request('get', url, params=params, **kwargs)
/usr/local/lib/python3.6/site-packages/requests/api.py:61: in request
    return session.request(method=method, url=url, **kwargs)
/usr/local/lib/python3.6/site-packages/requests/sessions.py:530: in request
    resp = self.send(prep, **send_kwargs)
/usr/local/lib/python3.6/site-packages/requests/sessions.py:643: in send
    r = adapter.send(request, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x7f6bc3169438>
request = <PreparedRequest [GET]>, stream = False
timeout = <urllib3.util.timeout.Timeout object at 0x7f6bc3169048>, verify = True
cert = None, proxies = OrderedDict()

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
    
        chunked = not (request.body is None or 'Content-Length' in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
                    timeout=timeout
                )
    
            # Send the request.
            else:
                if hasattr(conn, 'proxy_pool'):
                    conn = conn.proxy_pool
    
                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
    
                try:
                    low_conn.putrequest(request.method,
                                        url,
                                        skip_accept_encoding=True)
    
                    for header, value in request.headers.items():
                        low_conn.putheader(header, value)
    
                    low_conn.endheaders()
    
                    for i in request.body:
                        low_conn.send(hex(len(i))[2:].encode('utf-8'))
                        low_conn.send(b'\r\n')
                        low_conn.send(i)
                        low_conn.send(b'\r\n')
                    low_conn.send(b'0\r\n\r\n')
    
                    # Receive the response from the server
                    try:
                        # For Python 2.7, use buffering of HTTP responses
                        r = low_conn.getresponse(buffering=True)
                    except TypeError:
                        # For compatibility with Python 3.3+
                        r = low_conn.getresponse()
    
                    resp = HTTPResponse.from_httplib(
                        r,
                        pool=conn,
                        connection=low_conn,
                        preload_content=False,
                        decode_content=False
                    )
                except:
                    # If we hit any problems here, clean up the connection.
                    # Then, reraise so that we can handle the actual exception.
                    low_conn.close()
                    raise
    
        except (ProtocolError, socket.error) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /jaeger/api/traces?service=executor&operation=predictions&tag=hostname%3Amymodel-mymodel-0-complex-model-6b654c5845-xxt8t (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6bc3169550>: Failed to establish a new connection: [Errno 111] Connection refused',))

/usr/local/lib/python3.6/site-packages/requests/adapters.py:516: ConnectionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc32641d0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc3257cf8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc32646a0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7f6bc31830b8 state=finished raised ConnectionError>]
_________ test_rolling_deployment[graph7.json-graph8.json-False-istio] _________
[gw1] linux -- Python 3.6.10 /usr/local/bin/python

namespace = 'test-rolling-deployment-graph7-json-graph8-json-false-istio'
api_gateway = 'localhost:80', from_deployment = 'graph7.json'
to_deployment = 'graph8.json', change = False

    @pytest.mark.flaky(max_runs=2)
    @with_api_gateways
    @pytest.mark.parametrize(
        "from_deployment,to_deployment,change",
        [
            ("graph1.json", "graph2.json", True),  # New image version
            (
                "graph1.json",
                "graph3.json",
                True,
            ),  # New image version and new name of container
            ("graph1.json", "graph4.json", True),  # New resource request but same image
            ("graph1.json", "graph5.json", True),  # Update with multi-deployment new model
            ("graph1.json", "graph8.json", True),  # From v1alpha2 to v1
            ("graph7.json", "graph8.json", False),  # From v1alpha3 to v1
        ],
    )
    def test_rolling_deployment(
        namespace, api_gateway, from_deployment, to_deployment, change
    ):
        if api_gateway == API_ISTIO_GATEWAY:
            retry_run(f"kubectl create -f ../resources/seldon-gateway.yaml -n {namespace}")
    
        from_file_path = to_resources_path(from_deployment)
        retry_run(f"kubectl apply -f {from_file_path} -n {namespace}")
        wait_for_status("mymodel", namespace)
        wait_for_rollout("mymodel", namespace)
>       assert_model("mymodel", namespace, initial=True, endpoint=api_gateway)

test_rolling_updates.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

sdep_name = 'mymodel'
namespace = 'test-rolling-deployment-graph7-json-graph8-json-false-istio'
initial = True, endpoint = 'localhost:80'

    def assert_model(sdep_name, namespace, initial=False, endpoint=API_AMBASSADOR):
        _request = initial_rest_request if initial else rest_request
        r = _request(sdep_name, namespace, endpoint=endpoint)
    
>       assert r is not None
E       AssertionError

seldon_e2e_utils.py:527: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100ef0cc0 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100d4d2e8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100ef0710 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100ef0a58 state=finished raised ConnectionError>]
------------------------------ Captured log call -------------------------------
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:173 Failed to find status - sleeping
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100ef6780 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100ef6278 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe1022000b8 state=finished raised ConnectionError>]
WARNING  root:seldon_e2e_utils.py:222 Failed on REST request RetryError[<Future at 0x7fe100eeeb00 state=finished raised ConnectionError>]
===Flaky Test Report===

test_rolling_deployment[graph1.json-graph2.json-True-istio] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph2.json-True-istio] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph4.json-True-ambas] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph4.json-True-ambas] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph8.json-True-istio] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph8.json-True-istio] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph3.json-True-ambas] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph3.json-True-ambas] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph5.json-True-ambas] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph5.json-True-ambas] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph7.json-graph8.json-False-ambas] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph7.json-graph8.json-False-ambas] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph4.json-True-istio] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph4.json-True-istio] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph5.json-True-istio] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph5.json-True-istio] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph2.json-True-ambas] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph2.json-True-ambas] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph3.json-True-istio] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph3.json-True-istio] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph8.json-True-ambas] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph1.json-graph8.json-True-ambas] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph7.json-graph8.json-False-istio] failed (1 runs remaining out of 2).
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]
test_rolling_deployment[graph7.json-graph8.json-False-istio] failed; it passed 0 out of the required 1 times.
	<class 'AssertionError'>
	
	[<TracebackEntry /workspace/source/testing/scripts/test_rolling_updates.py:257>, <TracebackEntry /workspace/source/testing/scripts/seldon_e2e_utils.py:527>]

===End Flaky Test Report===
================== 26 failed, 2 passed in 1658.74s (0:27:38) ===================
make: *** [Makefile:109: test_parallel] Error 1
Test returned errors
kind delete cluster
Deleting cluster "kind" ...
Stopping Docker: dockerProgram process in pidfile '/var/run/docker-ssd.pid', 1 process(es), refused to die.
[31m
Pipeline failed on stage 'end-to-end' : container 'step-test-end-to-end'. The execution of the pipeline has stopped.[0m
