syntax = "proto3";

package seldon.mlops.scheduler;

option go_package = "github.com/seldonio/seldon-core/scheduler/apis/mlops/scheduler";

import "google/protobuf/timestamp.proto";

// [START Messages]

/* ServerReference represents a unique server
*/
message ServerReference {
  string name = 1;
}

message LoadModelRequest {
  Model model = 1;
}

message Model {
  MetaData meta = 1;
  ModelSpec modelSpec = 2;
  DeploymentSpec deploymentSpec = 3;
}

message MetaData {
  string name = 1;
  optional string kind = 2;
  optional string version = 3;
  optional KubernetesMeta kubernetesMeta = 4; // Kubernetes specific config
}

message DeploymentSpec {
  uint32 replicas = 1;
  uint32 minReplicas = 2;
  uint32 maxReplicas = 3;
  bool logPayloads = 4;
}

/* ModelDetails
*/
message ModelSpec {
  string uri = 1; // storage uri from where to download the artifacts
  optional uint32 artifactVersion = 2; // Optional v2 version folder to select
  optional StorageConfig storageConfig = 3; // Storage auth configuration
  repeated string requirements = 4; // list of capabilities the server must satisfy to run this model
  optional uint64 memoryBytes = 5; // Requested memory
  optional string server = 6; // the particular model server to load the model. If unspecified will be chosen.
}

message KubernetesMeta {
  string namespace = 1;
  int64 generation = 2;
}

message StorageConfig {
  oneof config {
    string storageSecretName = 1;
    string storageRcloneConfig = 2;
  }
}

message LoadModelResponse {

}

/* ModelReference represents a unique model
*/
message ModelReference {
  string name = 1;
  optional uint32 version = 2;
}

message UnloadModelRequest {
  ModelReference model = 1;
  optional KubernetesMeta kubernetesMeta = 2;
}

message UnloadModelResponse {
}

/* ModelStatusResponse provides the current assignment of the model onto a server
*/
message ModelStatusResponse {
  string modelName = 1;
  repeated ModelVersionStatus versions = 2;
}

message ModelVersionStatus {
  uint32 version = 2;
  string serverName = 3;
  optional KubernetesMeta kubernetesMeta = 4;
  map<int32,ModelReplicaStatus> modelReplicaState = 5;
  ModelStatus state = 6;
}

message ModelStatus {
  enum ModelState {
      ModelStateUnknown = 0;
      ModelProgressing = 1;
      ModelAvailable = 2;
      ModelFailed = 3;
      ModelTerminating = 4;
      ModelTerminated = 5;
      ModelTerminateFailed = 6;
  }
  ModelState state = 1;
  string reason = 2;
  uint32 availableReplicas = 3;
  uint32 unavailableReplicas = 4;
  google.protobuf.Timestamp lastChangeTimestamp = 5;
}

message ModelReplicaStatus {
  enum ModelReplicaState {
      ModelReplicaStateUnknown = 0;
      LoadRequested = 1;
      Loading = 2;
      Loaded = 3;
      LoadFailed = 4;
      UnloadRequested = 5;
      Unloading = 6;
      Unloaded = 7;
      UnloadFailed = 8;
      Available = 9;
      LoadedUnavailable = 10;
  }
  ModelReplicaState state = 1;
  string reason = 2;
  google.protobuf.Timestamp lastChangeTimestamp = 3;
}

/* ServerStatusResponse provides details of current server status
*/
message ServerStatusResponse {
  string serverName = 1;
  repeated ServerResources resources = 2;
}

message ServerResources {
  uint32 replicaIdx = 1;
  map<string,string> loadedModels = 2;
  uint64 memory = 3;
  uint64 availableMemoryBytes = 4;
}

message ModelSubscriptionRequest {
  string name = 1; //Name of the subscription caller
}

message ModelStatusRequest {
  ModelReference model = 1;
  bool allVersions = 2;
}

// [END Messages]


// [START Services]

service Scheduler {
  rpc ServerStatus(ServerReference) returns (ServerStatusResponse) {}
  rpc LoadModel(LoadModelRequest) returns (LoadModelResponse) {};
  rpc UnloadModel(UnloadModelRequest) returns (UnloadModelResponse) {};
  rpc ModelStatus(ModelStatusRequest) returns (ModelStatusResponse) {}
  rpc SubscribeModelStatus(ModelSubscriptionRequest) returns (stream ModelStatusResponse) {};
}

// [END Services]
